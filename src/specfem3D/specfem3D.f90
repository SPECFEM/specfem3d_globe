!=====================================================================
!
!          S p e c f e m 3 D  G l o b e  V e r s i o n  5 . 1
!          --------------------------------------------------
!
!          Main authors: Dimitri Komatitsch and Jeroen Tromp
!                        Princeton University, USA
!             and University of Pau / CNRS / INRIA, France
! (c) Princeton University / California Institute of Technology and University of Pau / CNRS / INRIA
!                            February 2011
!
! This program is free software; you can redistribute it and/or modify
! it under the terms of the GNU General Public License as published by
! the Free Software Foundation; either version 2 of the License, or
! (at your option) any later version.
!
! This program is distributed in the hope that it will be useful,
! but WITHOUT ANY WARRANTY; without even the implied warranty of
! MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
! GNU General Public License for more details.
!
! You should have received a copy of the GNU General Public License along
! with this program; if not, write to the Free Software Foundation, Inc.,
! 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
!
!=====================================================================
!
! United States and French Government Sponsorship Acknowledged.

  program xspecfem3D

  implicit none

! standard include of the MPI library
  include 'mpif.h'

  include "constants.h"
  include "precision.h"

! include values created by the mesher
  include "OUTPUT_FILES/values_from_mesher.h"

!=======================================================================!
!                                                                       !
!   specfem3D is a 3-D spectral-element solver for the Earth.           !
!   It uses a mesh generated by program meshfem3D                       !
!                                                                       !
!=======================================================================!
!
! If you use this code for your own research, please cite at least one article
! written by the developers of the package, for instance:
!
! @ARTICLE{TrKoLi08,
! author = {Jeroen Tromp and Dimitri Komatitsch and Qinya Liu},
! title = {Spectral-Element and Adjoint Methods in Seismology},
! journal = {Communications in Computational Physics},
! year = {2008},
! volume = {3},
! pages = {1-32},
! number = {1}}
!
! or
!
! @ARTICLE{VaCaSaKoVi99,
! author = {R. Vai and J. M. Castillo-Covarrubias and F. J. S\'anchez-Sesma and
! D. Komatitsch and J. P. Vilotte},
! title = {Elastic wave propagation in an irregularly layered medium},
! journal = {Soil Dynamics and Earthquake Engineering},
! year = {1999},
! volume = {18},
! pages = {11-18},
! number = {1},
! doi = {10.1016/S0267-7261(98)00027-X}}
!
! @ARTICLE{LeChKoHuTr09,
! author = {Shiann Jong Lee and Yu Chang Chan and Dimitri Komatitsch and Bor
! Shouh Huang and Jeroen Tromp},
! title = {Effects of realistic surface topography on seismic ground motion
! in the {Y}angminshan region of {T}aiwan based upon the spectral-element
! method and {LiDAR DTM}},
! journal = {Bull. Seismol. Soc. Am.},
! year = {2009},
! volume = {99},
! pages = {681-693},
! number = {2A},
! doi = {10.1785/0120080264}}
!
! @ARTICLE{LeChLiKoHuTr08,
! author = {Shiann Jong Lee and How Wei Chen and Qinya Liu and Dimitri Komatitsch
! and Bor Shouh Huang and Jeroen Tromp},
! title = {Three-Dimensional Simulations of Seismic Wave Propagation in the
! {T}aipei Basin with Realistic Topography Based upon the Spectral-Element Method},
! journal = {Bull. Seismol. Soc. Am.},
! year = {2008},
! volume = {98},
! pages = {253-264},
! number = {1},
! doi = {10.1785/0120070033}}
!
! @ARTICLE{LeKoHuTr09,
! author = {S. J. Lee and Dimitri Komatitsch and B. S. Huang and J. Tromp},
! title = {Effects of topography on seismic wave propagation: An example from
! northern {T}aiwan},
! journal = {Bull. Seismol. Soc. Am.},
! year = {2009},
! volume = {99},
! pages = {314-325},
! number = {1},
! doi = {10.1785/0120080020}}
!
! @ARTICLE{KoErGoMi10,
! author = {Dimitri Komatitsch and Gordon Erlebacher and Dominik G\"oddeke and
! David Mich\'ea},
! title = {High-order finite-element seismic wave propagation modeling with
! {MPI} on a large {GPU} cluster},
! journal = {J. Comput. Phys.},
! year = {2010},
! volume = {229},
! pages = {7692-7714},
! number = {20},
! doi = {10.1016/j.jcp.2010.06.024}}
!
! @ARTICLE{KoGoErMi10,
! author = {Dimitri Komatitsch and Dominik G\"oddeke and Gordon Erlebacher and
! David Mich\'ea},
! title = {Modeling the propagation of elastic waves using spectral elements
! on a cluster of 192 {GPU}s},
! journal = {Computer Science Research and Development},
! year = {2010},
! volume = {25},
! pages = {75-82},
! number = {1-2},
! doi = {10.1007/s00450-010-0109-1}}
!
! @ARTICLE{KoMiEr09,
! author = {Dimitri Komatitsch and David Mich\'ea and Gordon Erlebacher},
! title = {Porting a high-order finite-element earthquake modeling application
! to {NVIDIA} graphics cards using {CUDA}},
! journal = {Journal of Parallel and Distributed Computing},
! year = {2009},
! volume = {69},
! pages = {451-460},
! number = {5},
! doi = {10.1016/j.jpdc.2009.01.006}}
!
! @INCOLLECTION{ChKoViCaVaFe07,
! author = {Emmanuel Chaljub and Dimitri Komatitsch and Jean-Pierre Vilotte and
! Yann Capdeville and Bernard Valette and Gaetano Festa},
! title = {Spectral Element Analysis in Seismology},
! booktitle = {Advances in Wave Propagation in Heterogeneous Media},
! publisher = {Elsevier - Academic Press},
! year = {2007},
! editor = {Ru-Shan Wu and Val\'erie Maupin},
! volume = {48},
! series = {Advances in Geophysics},
! pages = {365-419}}
!
! @ARTICLE{KoVi98,
! author={D. Komatitsch and J. P. Vilotte},
! title={The spectral-element method: an efficient tool to simulate the seismic response of 2{D} and 3{D} geological structures},
! journal={Bull. Seismol. Soc. Am.},
! year=1998,
! volume=88,
! number=2,
! pages={368-392}}
!
! @ARTICLE{KoTr99,
! author={D. Komatitsch and J. Tromp},
! year=1999,
! title={Introduction to the spectral-element method for 3-{D} seismic wave propagation},
! journal={Geophys. J. Int.},
! volume=139,
! number=3,
! pages={806-822},
! doi={10.1046/j.1365-246x.1999.00967.x}}
!
! @ARTICLE{KoRiTr02,
! author={D. Komatitsch and J. Ritsema and J. Tromp},
! year=2002,
! title={The Spectral-Element Method, {B}eowulf Computing, and Global Seismology},
! journal={Science},
! volume=298,
! number=5599,
! pages={1737-1742},
! doi={10.1126/science.1076024}}
!
! @ARTICLE{KoTr02a,
! author={D. Komatitsch and J. Tromp},
! year=2002,
! title={Spectral-Element Simulations of Global Seismic Wave Propagation{-I. V}alidation},
! journal={Geophys. J. Int.},
! volume=149,
! number=2,
! pages={390-412},
! doi={10.1046/j.1365-246X.2002.01653.x}}
!
! @ARTICLE{KoTr02b,
! author={D. Komatitsch and J. Tromp},
! year=2002,
! title={Spectral-Element Simulations of Global Seismic Wave Propagation{-II. 3-D} Models, Oceans, Rotation, and Self-Gravitation},
! journal={Geophys. J. Int.},
! volume=150,
! pages={303-318},
! number=1,
! doi={10.1046/j.1365-246X.2002.01716.x}}
!
! and/or another article from http://web.univ-pau.fr/~dkomati1/publications.html
!
!
! If you use the kernel capabilities of the code, please cite at least one article
! written by the developers of the package, for instance:
!
! @ARTICLE{TrKoLi08,
! author = {Jeroen Tromp and Dimitri Komatitsch and Qinya Liu},
! title = {Spectral-Element and Adjoint Methods in Seismology},
! journal = {Communications in Computational Physics},
! year = {2008},
! volume = {3},
! pages = {1-32},
! number = {1}}
!
! or
!
! @ARTICLE{LiTr06,
! author={Qinya Liu and Jeroen Tromp},
! title={Finite-frequency kernels based on adjoint methods},
! journal={Bull. Seismol. Soc. Am.},
! year=2006,
! volume=96,
! number=6,
! pages={2383-2397},
! doi={10.1785/0120060041}}
!
! If you use 3-D model S20RTS, please cite:
!
! @ARTICLE{RiVa00,
! author={J. Ritsema and H. J. {Van Heijst}},
! year=2000,
! title={Seismic imaging of structural heterogeneity in {E}arth's mantle: Evidence for large-scale mantle flow},
! journal={Science Progress},
! volume=83,
! pages={243-259}}
!
! Reference frame - convention:
! ----------------------------
!
! The code uses the following convention for the reference frame:
!
!  - X axis is East
!  - Y axis is North
!  - Z axis is up
!
! Note that this convention is different from both the Aki-Richards convention
! and the Harvard CMT convention.
!
! Let us recall that the Aki-Richards convention is:
!
!  - X axis is North
!  - Y axis is East
!  - Z axis is down
!
! and that the Harvard CMT convention is:
!
!  - X axis is South
!  - Y axis is East
!  - Z axis is up
!
! To report bugs or suggest improvements to the code, please send an email
! to Jeroen Tromp <jtromp AT princeton.edu> and/or use our online
! bug tracking system at http://www.geodynamics.org/roundup .
!
! Evolution of the code:
! ---------------------
!
! v. 5.1, Dimitri Komatitsch, University of Toulouse, France and Ebru Bozdag, Princeton University, USA, February 2011:
!     non blocking MPI for much better scaling on large clusters;
!     new convention for the name of seismograms, to conform to the IRIS standard;
!     new directory structure
!
! v. 5.0 aka Tiger, many developers some with Princeton Tiger logo on their shirts, February 2010:
!     new moho mesh stretching honoring crust2.0 moho depths,
!     new attenuation assignment, new SAC headers, new general crustal models,
!     faster performance due to Deville routines and enhanced loop unrolling,
!     slight changes in code structure (see also trivia at program start)
!
! v. 4.0 David Michea and Dimitri Komatitsch, University of Pau, France, February 2008:
!      new doubling brick in the mesh, new perfectly load-balanced mesh,
!      more flexible routines for mesh design, new inflated central cube
!      with optimized shape, far fewer mesh files saved by the mesher,
!      global arrays sorted to speed up the simulation, seismos can be
!      written by the master, one more doubling level at the bottom
!      of the outer core if needed (off by default)
!
! v. 3.6 Many people, many affiliations, September 2006:
!      adjoint and kernel calculations, fixed IASP91 model,
!      added AK135 and 1066a, fixed topography/bathymetry routine,
!      new attenuation routines, faster and better I/Os on very large
!      systems, many small improvements and bug fixes, new "configure"
!      script, new Pyre version, new user's manual etc.
!
! v. 3.5 Dimitri Komatitsch, Brian Savage and Jeroen Tromp, Caltech, July 2004:
!      any size of chunk, 3D attenuation, case of two chunks,
!      more precise topography/bathymetry model, new Par_file structure
!
! v. 3.4 Dimitri Komatitsch and Jeroen Tromp, Caltech, August 2003:
!      merged global and regional codes, no iterations in fluid, better movies
!
! v. 3.3 Dimitri Komatitsch, Caltech, September 2002:
!      flexible mesh doubling in outer core, inlined code, OpenDX support
!
! v. 3.2 Jeroen Tromp, Caltech, July 2002:
!      multiple sources and flexible PREM reading
!
! v. 3.1 Dimitri Komatitsch, Caltech, June 2002:
!      vectorized loops in solver and merged central cube
!
! v. 3.0 Dimitri Komatitsch and Jeroen Tromp, Caltech, May 2002:
!   ported to SGI and Compaq, double precision solver, more general anisotropy
!
! v. 2.3 Dimitri Komatitsch and Jeroen Tromp, Caltech, August 2001:
!                       gravity, rotation, oceans and 3-D models
!
! v. 2.2 Dimitri Komatitsch and Jeroen Tromp, Caltech, March 2001:
!                       final MPI package
!
! v. 2.0 Dimitri Komatitsch, Harvard, January 2000: MPI code for the globe
!
! v. 1.0 Dimitri Komatitsch, Mexico, June 1999: first MPI code for a chunk
!
! Jeroen Tromp, Harvard, July 1998: first chunk solver using OpenMP on Sun
!
! Dimitri Komatitsch, IPG Paris, December 1996: first 3-D solver for the CM-5 Connection Machine
!
! From Dahlen and Tromp (1998):
! ----------------------------
!
! Gravity is approximated by solving eq (3.259) without the Phi_E' term
! The ellipsoidal reference model is that of section 14.1
! The transversely isotropic expression for PREM is that of eq (8.190)
!
! Formulation in the fluid (acoustic) outer core:
! -----------------------------------------------
!
! In case of an acoustic medium, a displacement potential Chi is used
! as in Chaljub and Valette, Geophysical Journal International, vol. 158,
! p. 131-141 (2004) and *NOT* a velocity potential as in Komatitsch and Tromp,
! Geophysical Journal International, vol. 150, p. 303-318 (2002).
! This permits acoustic-elastic coupling based on a non-iterative time scheme.
! Displacement if we ignore gravity is then: u = grad(Chi)
! (In the context of the Cowling approximation displacement is
! u = grad(rho * Chi) / rho, *not* u = grad(Chi).)
! Velocity is then: v = grad(Chi_dot)       (Chi_dot being the time derivative of Chi)
! and pressure is: p = - rho * Chi_dot_dot  (Chi_dot_dot being the time second derivative of Chi).
! The source in an acoustic element is a pressure source.
! The potential in the outer core is called displ_outer_core for simplicity.
! Its first time derivative is called veloc_outer_core.
! Its second time derivative is called accel_outer_core.

! memory variables and standard linear solids for attenuation
  real(kind=CUSTOM_REAL), dimension(ATT1,ATT2,ATT3,ATT4) :: one_minus_sum_beta_crust_mantle, factor_scale_crust_mantle
  real(kind=CUSTOM_REAL), dimension(ATT1,ATT2,ATT3,ATT5) :: one_minus_sum_beta_inner_core, factor_scale_inner_core

  real(kind=CUSTOM_REAL), dimension(N_SLS) :: alphaval, betaval, gammaval
  real(kind=CUSTOM_REAL), dimension(N_SLS,ATT1,ATT2,ATT3,ATT4) :: factor_common_crust_mantle
  real(kind=CUSTOM_REAL), dimension(N_SLS,ATT1,ATT2,ATT3,ATT5) :: factor_common_inner_core

  real(kind=CUSTOM_REAL), dimension(5,N_SLS,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ATTENUAT) :: R_memory_crust_mantle
  real(kind=CUSTOM_REAL), dimension(5,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_STR_OR_ATT) :: epsilondev_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_STRAIN_ONLY) :: eps_trace_over_3_crust_mantle

  real(kind=CUSTOM_REAL), dimension(5,N_SLS,NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE_ATTENUATION) :: R_memory_inner_core
  real(kind=CUSTOM_REAL), dimension(5,NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE_STR_OR_ATT) :: epsilondev_inner_core
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE_STRAIN_ONLY) :: eps_trace_over_3_inner_core

! ADJOINT
  real(kind=CUSTOM_REAL), dimension(N_SLS) :: b_alphaval, b_betaval, b_gammaval

  real(kind=CUSTOM_REAL), dimension(5,N_SLS,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_STR_AND_ATT) :: b_R_memory_crust_mantle
  real(kind=CUSTOM_REAL), dimension(5,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ADJOINT) :: b_epsilondev_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ADJOINT) :: b_eps_trace_over_3_crust_mantle

  real(kind=CUSTOM_REAL), dimension(5,N_SLS,NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE_STR_AND_ATT) :: b_R_memory_inner_core
  real(kind=CUSTOM_REAL), dimension(5,NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE_ADJOINT) :: b_epsilondev_inner_core
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE_ADJOINT) :: b_eps_trace_over_3_inner_core

! for matching with central cube in inner core
  integer, dimension(:), allocatable :: sender_from_slices_to_cube
  integer, dimension(:,:), allocatable :: ibool_central_cube
  double precision, dimension(:,:), allocatable :: buffer_slices,b_buffer_slices,buffer_slices2
  double precision, dimension(:,:,:), allocatable :: buffer_all_cube_from_slices,b_buffer_all_cube_from_slices
  integer nb_msgs_theor_in_cube,non_zero_nb_msgs_theor_in_cube,npoin2D_cube_from_slices,receiver_cube_from_slices

  integer nspec2D_xmin_inner_core,nspec2D_xmax_inner_core,nspec2D_ymin_inner_core,nspec2D_ymax_inner_core

! to save movie frames
  integer nmovie_points,NIT
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: &
      store_val_x,store_val_y,store_val_z, &
      store_val_ux,store_val_uy,store_val_uz
  real(kind=CUSTOM_REAL), dimension(:,:), allocatable :: &
      store_val_x_all,store_val_y_all,store_val_z_all, &
      store_val_ux_all,store_val_uy_all,store_val_uz_all

! to save movie volume
  integer :: npoints_3dmovie,nspecel_3dmovie
  integer, dimension(NGLOB_CRUST_MANTLE) :: num_ibool_3dmovie
  double precision :: scalingval
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_STR_OR_ATT) :: muvstore_crust_mantle_3dmovie
  real(kind=CUSTOM_REAL), dimension(:,:,:), allocatable :: nu_3dmovie
  logical, dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_STRAIN_ONLY) :: mask_3dmovie

  real(kind=CUSTOM_REAL), dimension(5,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_STR_OR_ATT) :: Iepsilondev_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_STRAIN_ONLY) :: Ieps_trace_over_3_crust_mantle

! use integer array to store values
  integer, dimension(NX_BATHY,NY_BATHY) :: ibathy_topo

! for crust/oceans coupling
  integer, dimension(NSPEC2DMAX_XMIN_XMAX_CM) :: ibelm_xmin_crust_mantle,ibelm_xmax_crust_mantle
  integer, dimension(NSPEC2DMAX_YMIN_YMAX_CM) :: ibelm_ymin_crust_mantle,ibelm_ymax_crust_mantle
  integer, dimension(NSPEC2D_BOTTOM_CM) :: ibelm_bottom_crust_mantle
  integer, dimension(NSPEC2D_TOP_CM) :: ibelm_top_crust_mantle

! additional mass matrix for ocean load
  real(kind=CUSTOM_REAL), dimension(NGLOB_CRUST_MANTLE_OCEANS) :: rmass_ocean_load

! flag to mask ocean-bottom degrees of freedom for ocean load
  logical, dimension(NGLOB_CRUST_MANTLE_OCEANS) :: updated_dof_ocean_load

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_BOTTOM_CM) :: jacobian2D_bottom_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_TOP_CM) :: jacobian2D_top_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLLY,NGLLZ,NSPEC2DMAX_XMIN_XMAX_CM) :: jacobian2D_xmin_crust_mantle,&
  jacobian2D_xmax_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLZ,NSPEC2DMAX_YMIN_YMAX_CM) :: jacobian2D_ymin_crust_mantle,&
  jacobian2D_ymax_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLY,NGLLZ,NSPEC2DMAX_XMIN_XMAX_CM) :: &
  normal_xmin_crust_mantle,normal_xmax_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2DMAX_YMIN_YMAX_CM) :: &
  normal_ymin_crust_mantle,normal_ymax_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_BOTTOM_CM) :: normal_bottom_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_TOP_CM) :: normal_top_crust_mantle

! Stacey
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_STACEY) :: rho_vp_crust_mantle,rho_vs_crust_mantle
  integer nspec2D_xmin_crust_mantle,nspec2D_xmax_crust_mantle,nspec2D_ymin_crust_mantle,nspec2D_ymax_crust_mantle
  integer, dimension(2,NSPEC2DMAX_YMIN_YMAX_CM) :: nimin_crust_mantle,nimax_crust_mantle,nkmin_eta_crust_mantle
  integer, dimension(2,NSPEC2DMAX_XMIN_XMAX_CM) :: njmin_crust_mantle,njmax_crust_mantle,nkmin_xi_crust_mantle

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_STACEY) :: vp_outer_core
  integer nspec2D_xmin_outer_core,nspec2D_xmax_outer_core,nspec2D_ymin_outer_core,nspec2D_ymax_outer_core
  integer, dimension(2,NSPEC2DMAX_YMIN_YMAX_OC) :: nimin_outer_core,nimax_outer_core,nkmin_eta_outer_core
  integer, dimension(2,NSPEC2DMAX_XMIN_XMAX_OC) :: njmin_outer_core,njmax_outer_core,nkmin_xi_outer_core

! arrays to couple with the fluid regions by pointwise matching
  integer, dimension(NSPEC2DMAX_XMIN_XMAX_OC) :: ibelm_xmin_outer_core,ibelm_xmax_outer_core
  integer, dimension(NSPEC2DMAX_YMIN_YMAX_OC) :: ibelm_ymin_outer_core,ibelm_ymax_outer_core
  integer, dimension(NSPEC2D_BOTTOM_OC) :: ibelm_bottom_outer_core
  integer, dimension(NSPEC2D_TOP_OC) :: ibelm_top_outer_core

  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLY,NGLLZ,NSPEC2DMAX_XMIN_XMAX_OC) :: normal_xmin_outer_core,normal_xmax_outer_core
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLZ,NSPEC2DMAX_YMIN_YMAX_OC) :: normal_ymin_outer_core,normal_ymax_outer_core
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_BOTTOM_OC) :: normal_bottom_outer_core
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_TOP_OC) :: normal_top_outer_core

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_BOTTOM_OC) :: jacobian2D_bottom_outer_core
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_TOP_OC) :: jacobian2D_top_outer_core
  real(kind=CUSTOM_REAL), dimension(NGLLY,NGLLZ,NSPEC2DMAX_XMIN_XMAX_OC) :: jacobian2D_xmin_outer_core,jacobian2D_xmax_outer_core
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLZ,NSPEC2DMAX_YMIN_YMAX_OC) :: jacobian2D_ymin_outer_core,jacobian2D_ymax_outer_core


  integer, dimension(NSPEC2DMAX_XMIN_XMAX_IC) :: ibelm_xmin_inner_core,ibelm_xmax_inner_core
  integer, dimension(NSPEC2DMAX_YMIN_YMAX_IC) :: ibelm_ymin_inner_core,ibelm_ymax_inner_core
  integer, dimension(NSPEC2D_BOTTOM_IC) :: ibelm_bottom_inner_core
  integer, dimension(NSPEC2D_TOP_IC) :: ibelm_top_inner_core

! for ellipticity
  integer nspl
  double precision rspl(NR),espl(NR),espl2(NR)

! for conversion from x y z to r theta phi
  real(kind=CUSTOM_REAL) rval,thetaval,phival

! ---- arrays to assemble between chunks

! communication pattern for faces between chunks
  integer, dimension(NUMMSGS_FACES_VAL) :: iprocfrom_faces,iprocto_faces,imsg_type

! communication pattern for corners between chunks
  integer, dimension(NCORNERSCHUNKS_VAL) :: iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners

! indirect addressing for each message for faces and corners of the chunks
! a given slice can belong to at most one corner and at most two faces
  integer NGLOB2DMAX_XY
  integer, dimension(NGLOB2DMAX_XY_VAL,NUMFACES_SHARED) :: iboolfaces_crust_mantle, &
      iboolfaces_outer_core,iboolfaces_inner_core

! this for non blocking MPI

! buffers for send and receive between faces of the slices and the chunks
! we use the same buffers to assemble scalars and vectors because vectors are
! always three times bigger and therefore scalars can use the first part
! of the vector buffer in memory even if it has an additional index here
  integer :: npoin2D_max_all_CM_IC
  real(kind=CUSTOM_REAL), dimension(:,:,:), allocatable :: buffer_send_faces,buffer_received_faces, &
                                                           b_buffer_send_faces,b_buffer_received_faces

! for non blocking communications
  logical, dimension(NSPEC_CRUST_MANTLE) :: is_on_a_slice_edge_crust_mantle
  logical, dimension(NSPEC_OUTER_CORE) :: is_on_a_slice_edge_outer_core
  logical, dimension(NSPEC_INNER_CORE) :: is_on_a_slice_edge_inner_core
  logical, dimension(NGLOB_CRUST_MANTLE) :: mask_ibool
  real :: percentage_edge

! assembling phase number for non blocking MPI
! iphase is for the crust_mantle, outer_core and inner_core regions
! iphase_CC is for the central cube
  integer :: iphase,iphase_CC,icall
  integer :: b_iphase,b_iphase_CC,b_icall

! -------- arrays specific to each region here -----------

! ----------------- crust, mantle and oceans ---------------------

! mesh parameters
  integer, dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE) :: ibool_crust_mantle

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE) :: &
        xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle,&
        etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
        gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLOB_CRUST_MANTLE) :: &
        xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle

! arrays for isotropic elements stored only where needed to save space
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPECMAX_ISO_MANTLE) :: &
        rhostore_crust_mantle,kappavstore_crust_mantle,muvstore_crust_mantle

! arrays for anisotropic elements stored only where needed to save space
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPECMAX_TISO_MANTLE) :: &
        kappahstore_crust_mantle,muhstore_crust_mantle,eta_anisostore_crust_mantle

! arrays for full anisotropy only when needed
  integer nspec_iso,nspec_tiso,nspec_ani
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPECMAX_ANISO_MANTLE) :: &
        c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
        c14store_crust_mantle,c15store_crust_mantle,c16store_crust_mantle, &
        c22store_crust_mantle,c23store_crust_mantle,c24store_crust_mantle, &
        c25store_crust_mantle,c26store_crust_mantle,c33store_crust_mantle, &
        c34store_crust_mantle,c35store_crust_mantle,c36store_crust_mantle, &
        c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
        c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle

! local to global mapping
!  integer, dimension(NSPEC_CRUST_MANTLE) :: idoubling_crust_mantle
  logical, dimension(NSPEC_CRUST_MANTLE) :: ispec_is_tiso_crust_mantle

! mass matrix
  real(kind=CUSTOM_REAL), dimension(NGLOB_CRUST_MANTLE) :: rmass_crust_mantle

! displacement, velocity, acceleration
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLOB_CRUST_MANTLE) :: &
     displ_crust_mantle,veloc_crust_mantle,accel_crust_mantle

! ----------------- outer core ---------------------

! mesh parameters
  integer, dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE) :: ibool_outer_core

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE) :: &
        xix_outer_core,xiy_outer_core,xiz_outer_core,&
        etax_outer_core,etay_outer_core,etaz_outer_core, &
        gammax_outer_core,gammay_outer_core,gammaz_outer_core
  real(kind=CUSTOM_REAL), dimension(NGLOB_OUTER_CORE) :: &
        xstore_outer_core,ystore_outer_core,zstore_outer_core

 real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE) :: &
        rhostore_outer_core,kappavstore_outer_core

! local to global mapping
  integer, dimension(NSPEC_OUTER_CORE) :: idoubling_outer_core
  logical, dimension(NSPEC_OUTER_CORE) :: ispec_is_tiso_outer_core ! only needed for compute_boundary_kernel()

! mass matrix
  real(kind=CUSTOM_REAL), dimension(NGLOB_OUTER_CORE) :: rmass_outer_core

! velocity potential
  real(kind=CUSTOM_REAL), dimension(NGLOB_OUTER_CORE) :: displ_outer_core, &
    veloc_outer_core,accel_outer_core

! ----------------- inner core ---------------------

! mesh parameters
  integer, dimension(NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE) :: ibool_inner_core

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE) :: &
        xix_inner_core,xiy_inner_core,xiz_inner_core,&
        etax_inner_core,etay_inner_core,etaz_inner_core, &
        gammax_inner_core,gammay_inner_core,gammaz_inner_core, &
        rhostore_inner_core, kappavstore_inner_core,muvstore_inner_core
  real(kind=CUSTOM_REAL), dimension(NGLOB_INNER_CORE) :: &
        xstore_inner_core,ystore_inner_core,zstore_inner_core

! arrays for inner-core anisotropy only when needed
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPECMAX_ANISO_IC) :: &
        c11store_inner_core,c33store_inner_core,c12store_inner_core, &
        c13store_inner_core,c44store_inner_core

! local to global mapping
  integer, dimension(NSPEC_INNER_CORE) :: idoubling_inner_core
  logical, dimension(NSPEC_INNER_CORE) :: ispec_is_tiso_inner_core ! only needed for computer_boundary_kernel() routine

! mass matrix
  real(kind=CUSTOM_REAL), dimension(NGLOB_INNER_CORE) :: rmass_inner_core

! displacement, velocity, acceleration
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLOB_INNER_CORE) :: &
     displ_inner_core,veloc_inner_core,accel_inner_core

! Newmark time scheme parameters and non-dimensionalization
  real(kind=CUSTOM_REAL) time,deltat,deltatover2,deltatsqover2
  double precision scale_t,scale_t_inv,scale_displ,scale_veloc

! ADJOINT
  real(kind=CUSTOM_REAL) b_deltat,b_deltatover2,b_deltatsqover2
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLOB_CRUST_MANTLE_ADJOINT) :: &
    b_displ_crust_mantle,b_veloc_crust_mantle,b_accel_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLOB_OUTER_CORE_ADJOINT) :: &
    b_displ_outer_core,b_veloc_outer_core,b_accel_outer_core
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLOB_INNER_CORE_ADJOINT) :: &
    b_displ_inner_core,b_veloc_inner_core,b_accel_inner_core

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_ADJOINT) :: div_displ_outer_core
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_ADJOINT) :: b_div_displ_outer_core

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ADJOINT) :: rho_kl_crust_mantle, &
     beta_kl_crust_mantle, alpha_kl_crust_mantle, Sigma_kl_crust_mantle
! For anisotropic kernels (see compute_kernels.f90 for a definition of the array)
  real(kind=CUSTOM_REAL), dimension(21,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ADJOINT) :: cijkl_kl_crust_mantle

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_ADJOINT) :: rho_kl_outer_core, &
     alpha_kl_outer_core

  ! approximate hessian
  real(kind=CUSTOM_REAL), dimension(:,:,:,:),allocatable :: hess_kl_crust_mantle

  ! check for deviatoric kernel for outer core region
  real(kind=CUSTOM_REAL), dimension(:,:,:,:),allocatable :: beta_kl_outer_core
  integer :: nspec_beta_kl_outer_core
  logical,parameter:: deviatoric_outercore = .false.

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE_ADJOINT) :: rho_kl_inner_core, &
     beta_kl_inner_core, alpha_kl_inner_core

  real(kind=CUSTOM_REAL), dimension(:,:,:,:,:), allocatable :: absorb_xmin_crust_mantle5, &
     absorb_xmax_crust_mantle5, absorb_ymin_crust_mantle5, absorb_ymax_crust_mantle5

  real(kind=CUSTOM_REAL), dimension(:,:,:), allocatable :: absorb_xmin_outer_core, &
     absorb_xmax_outer_core, absorb_ymin_outer_core, absorb_ymax_outer_core, &
     absorb_zmin_outer_core
  integer nabs_xmin_cm,nabs_xmax_cm,nabs_ymin_cm,nabs_ymax_cm
  integer nabs_xmin_oc,nabs_xmax_oc,nabs_ymin_oc,nabs_ymax_oc,nabs_zmin_oc

  integer reclen_xmin_crust_mantle, reclen_xmax_crust_mantle, reclen_ymin_crust_mantle, &
     reclen_ymax_crust_mantle, reclen_xmin_outer_core, reclen_xmax_outer_core,&
     reclen_ymin_outer_core, reclen_ymax_outer_core, reclen_zmin

  real(kind=CUSTOM_REAL), dimension(NDIM,NGLOB_OUTER_CORE) :: vector_accel_outer_core,&
             vector_displ_outer_core, b_vector_displ_outer_core

  integer npoin2D_faces_crust_mantle(NUMFACES_SHARED)
  integer npoin2D_faces_outer_core(NUMFACES_SHARED)
  integer npoin2D_faces_inner_core(NUMFACES_SHARED)

! parameters for the source
  integer it
  integer, dimension(:), allocatable :: islice_selected_source,ispec_selected_source
  real(kind=CUSTOM_REAL), dimension(:,:,:,:,:), allocatable :: sourcearrays
  double precision, dimension(:,:,:) ,allocatable:: nu_source
  double precision sec
  double precision, dimension(:), allocatable :: Mxx,Myy,Mzz,Mxy,Mxz,Myz
  double precision, dimension(:), allocatable :: xi_source,eta_source,gamma_source
  double precision, dimension(:), allocatable :: tshift_cmt,hdur,hdur_gaussian
  double precision, dimension(:), allocatable :: theta_source,phi_source
  double precision, external :: comp_source_time_function
  double precision t0

! receiver information
  integer nrec,nrec_local
  integer, dimension(:), allocatable :: islice_selected_rec,ispec_selected_rec,number_receiver_global
  double precision, dimension(:), allocatable :: xi_receiver,eta_receiver,gamma_receiver
  character(len=150) :: STATIONS,rec_filename
  double precision, dimension(:,:,:), allocatable :: nu
  double precision, allocatable, dimension(:) :: stlat,stlon,stele,stbur
  character(len=MAX_LENGTH_STATION_NAME), dimension(:), allocatable  :: station_name
  character(len=MAX_LENGTH_NETWORK_NAME), dimension(:), allocatable :: network_name

!ADJOINT
  real(kind=CUSTOM_REAL), dimension(:,:,:,:,:,:), allocatable :: adj_sourcearrays
  integer nrec_simulation, nadj_rec_local
  integer NSTEP_SUB_ADJ  ! to read input in chunks
  integer, dimension(:,:), allocatable :: iadjsrc ! to read input in chunks
  integer, dimension(:), allocatable :: iadjsrc_len,iadj_vec
! source frechet derivatives
  real(kind=CUSTOM_REAL), dimension(:,:,:), allocatable :: moment_der
  real(kind=CUSTOM_REAL), dimension(:,:), allocatable :: sloc_der
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: stshift_der, shdur_der
  double precision, dimension(:,:), allocatable :: hpxir_store,hpetar_store,hpgammar_store
  integer :: nadj_hprec_local

! seismograms
  integer it_begin,it_end,nit_written
  real(kind=CUSTOM_REAL), dimension(:,:,:), allocatable :: seismograms
  integer :: seismo_offset, seismo_current

! non-dimensionalized rotation rate of the Earth times two
  real(kind=CUSTOM_REAL) two_omega_earth

! for the Euler scheme for rotation
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_ROTATION) :: &
    A_array_rotation,B_array_rotation

! number of faces between chunks
  integer NUMMSGS_FACES

! number of corners between chunks
  integer NCORNERSCHUNKS

! number of message types
  integer NUM_MSG_TYPES

! indirect addressing for each corner of the chunks
  integer, dimension(NGLOB1D_RADIAL_CM,NUMCORNERS_SHARED) :: iboolcorner_crust_mantle
  integer, dimension(NGLOB1D_RADIAL_OC,NUMCORNERS_SHARED) :: iboolcorner_outer_core
  integer, dimension(NGLOB1D_RADIAL_IC,NUMCORNERS_SHARED) :: iboolcorner_inner_core

! buffers for send and receive between corners of the chunks
  real(kind=CUSTOM_REAL), dimension(NGLOB1D_RADIAL_CM) :: buffer_send_chunkcorn_scalar,buffer_recv_chunkcorn_scalar, &
                                                          b_buffer_send_chunkcorn_scalar,b_buffer_recv_chunkcorn_scalar
! size of buffers is the sum of two sizes because we handle two regions in the same MPI call
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLOB1D_RADIAL_CM + NGLOB1D_RADIAL_IC) :: &
     buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector, &
     b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector

! Gauss-Lobatto-Legendre points of integration and weights
  double precision, dimension(NGLLX) :: xigll,wxgll
  double precision, dimension(NGLLY) :: yigll,wygll
  double precision, dimension(NGLLZ) :: zigll,wzgll

! product of weights for gravity term
  double precision, dimension(NGLLX,NGLLY,NGLLZ) :: wgll_cube

! array with derivatives of Lagrange polynomials and precalculated products
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLX) :: hprime_xx,hprimewgll_xx
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLX) :: hprime_xxT,hprimewgll_xxT
  real(kind=CUSTOM_REAL), dimension(NGLLY,NGLLY) :: hprime_yy,hprimewgll_yy
  real(kind=CUSTOM_REAL), dimension(NGLLZ,NGLLZ) :: hprime_zz,hprimewgll_zz
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY) :: wgllwgll_xy
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLZ) :: wgllwgll_xz
  real(kind=CUSTOM_REAL), dimension(NGLLY,NGLLZ) :: wgllwgll_yz

! Lagrange interpolators at receivers
  double precision, dimension(:,:), allocatable :: hxir_store,hetar_store,hgammar_store

! 2-D addressing and buffers for summation between slices
  integer, dimension(NGLOB2DMAX_XMIN_XMAX_CM) :: iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle
  integer, dimension(NGLOB2DMAX_YMIN_YMAX_CM) :: iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle

  integer, dimension(NGLOB2DMAX_XMIN_XMAX_OC) :: iboolleft_xi_outer_core,iboolright_xi_outer_core
  integer, dimension(NGLOB2DMAX_YMIN_YMAX_OC) :: iboolleft_eta_outer_core,iboolright_eta_outer_core

  integer, dimension(NGLOB2DMAX_XMIN_XMAX_IC) :: iboolleft_xi_inner_core,iboolright_xi_inner_core
  integer, dimension(NGLOB2DMAX_YMIN_YMAX_IC) :: iboolleft_eta_inner_core,iboolright_eta_inner_core

! for addressing of the slices
  integer, dimension(NCHUNKS_VAL,0:NPROC_XI_VAL-1,0:NPROC_ETA_VAL-1) :: addressing
  integer, dimension(0:NPROCTOT_VAL-1) :: ichunk_slice,iproc_xi_slice,iproc_eta_slice

! proc numbers for MPI
  integer myrank

  integer, dimension(NB_SQUARE_EDGES_ONEDIR) :: npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle
  integer, dimension(NB_SQUARE_EDGES_ONEDIR) :: npoin2D_xi_outer_core,npoin2D_eta_outer_core
  integer, dimension(NB_SQUARE_EDGES_ONEDIR) :: npoin2D_xi_inner_core,npoin2D_eta_inner_core

  integer ichunk,iproc_xi,iproc_eta

!ADJOINT
  real(kind=CUSTOM_REAL) b_two_omega_earth
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_ROT_ADJOINT) :: &
    b_A_array_rotation,b_B_array_rotation

  double precision :: time_start

! parameters read from parameter file
  integer MIN_ATTENUATION_PERIOD,MAX_ATTENUATION_PERIOD,NER_CRUST, &
          NER_80_MOHO,NER_220_80,NER_400_220,NER_600_400,NER_670_600,NER_771_670, &
          NER_TOPDDOUBLEPRIME_771,NER_CMB_TOPDDOUBLEPRIME,NER_OUTER_CORE, &
          NER_TOP_CENTRAL_CUBE_ICB,NEX_XI,NEX_ETA, &
          NTSTEP_BETWEEN_OUTPUT_SEISMOS,&
          NTSTEP_BETWEEN_READ_ADJSRC,NSTEP,NSOURCES,NTSTEP_BETWEEN_FRAMES, &
          NTSTEP_BETWEEN_OUTPUT_INFO,NUMBER_OF_RUNS,NUMBER_OF_THIS_RUN,SIMULATION_TYPE, &
          MOVIE_VOLUME_TYPE,MOVIE_START,MOVIE_STOP,NOISE_TOMOGRAPHY

  double precision DT,ROCEAN,RMIDDLE_CRUST, &
          RMOHO,R80,R220,R400,R600,R670,R771,RTOPDDOUBLEPRIME,RCMB,RICB, &
          RHO_TOP_OC,RHO_BOTTOM_OC,RHO_OCEANS,HDUR_MOVIE, &
          MOVIE_TOP,MOVIE_BOTTOM,MOVIE_WEST,MOVIE_EAST,MOVIE_NORTH,MOVIE_SOUTH, &
          ANGULAR_WIDTH_XI_IN_DEGREES

  logical ONE_CRUST,TOPOGRAPHY,MOVIE_SURFACE,MOVIE_VOLUME,MOVIE_COARSE, &
          RECEIVERS_CAN_BE_BURIED,PRINT_SOURCE_TIME_FUNCTION, &
          SAVE_MESH_FILES,ABSORBING_CONDITIONS,INCLUDE_CENTRAL_CUBE,SAVE_FORWARD, &
          OUTPUT_SEISMOS_ASCII_TEXT,OUTPUT_SEISMOS_SAC_ALPHANUM,OUTPUT_SEISMOS_SAC_BINARY, &
          ROTATE_SEISMOGRAMS_RT,HONOR_1D_SPHERICAL_MOHO,WRITE_SEISMOGRAMS_BY_MASTER,&
          SAVE_ALL_SEISMOS_IN_ONE_FILE,USE_BINARY_FOR_LARGE_FILE

  character(len=150) OUTPUT_FILES,LOCAL_PATH

!  logical COMPUTE_AND_STORE_STRAIN

! for SAC headers for seismograms
  integer yr_SAC,jda_SAC,ho_SAC,mi_SAC
  real mb_SAC
  double precision t_cmt_SAC,t_shift_SAC,elat_SAC,elon_SAC,depth_SAC, &
    cmt_lat_SAC,cmt_lon_SAC,cmt_depth_SAC,cmt_hdur_SAC,sec_SAC
  character(len=20) event_name_SAC

! this for all the regions
  integer, dimension(MAX_NUM_REGIONS) :: NSPEC2DMAX_XMIN_XMAX,NSPEC2DMAX_YMIN_YMAX, &
               NSPEC2D_BOTTOM,NSPEC2D_TOP, &
               NGLOB1D_RADIAL, &
               NGLOB2DMAX_XMIN_XMAX,NGLOB2DMAX_YMIN_YMAX

  character(len=150) prname

! lookup table every km for gravity
  real(kind=CUSTOM_REAL) minus_g_cmb,minus_g_icb
  double precision, dimension(NRAD_GRAVITY) :: minus_gravity_table, &
    minus_deriv_gravity_table,density_table,d_ln_density_dr_table,minus_rho_g_over_kappa_fluid

! dummy array that does not need to be actually read
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,1) :: dummy_array

! computed in read_compute_parameters
  integer, dimension(MAX_NUMBER_OF_MESH_LAYERS) :: ner,ratio_sampling_array
  integer, dimension(MAX_NUMBER_OF_MESH_LAYERS) :: doubling_index
  double precision, dimension(MAX_NUMBER_OF_MESH_LAYERS) :: r_bottom,r_top
  logical, dimension(MAX_NUMBER_OF_MESH_LAYERS) :: this_region_has_a_doubling
  double precision, dimension(MAX_NUMBER_OF_MESH_LAYERS) :: rmins,rmaxs

! Boundary Mesh and Kernels
  integer k_top,k_bot,iregion_code
  integer, dimension(NSPEC2D_MOHO) :: ibelm_moho_top,ibelm_moho_bot
  integer, dimension(NSPEC2D_400) :: ibelm_400_top,ibelm_400_bot
  integer, dimension(NSPEC2D_670) :: ibelm_670_top,ibelm_670_bot
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_MOHO) :: normal_moho
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_400) :: normal_400
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_670) :: normal_670
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_MOHO) :: moho_kl, moho_kl_top, moho_kl_bot
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_400) :: d400_kl, d400_kl_top, d400_kl_bot
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_670) ::  d670_kl, d670_kl_top, d670_kl_bot
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_CMB) :: cmb_kl, cmb_kl_top, cmb_kl_bot
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_ICB) :: icb_kl, icb_kl_top, icb_kl_bot
  logical :: fluid_solid_boundary

  integer :: i,ier

  integer :: imodulo_NGLOB_CRUST_MANTLE

! NOISE_TOMOGRAPHY
  real(kind=CUSTOM_REAL), dimension(:,:,:,:,:), allocatable :: noise_sourcearray
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: &
             normal_x_noise,normal_y_noise,normal_z_noise, mask_noise
  real(kind=CUSTOM_REAL), dimension(:,:,:,:), allocatable :: noise_surface_movie  
  integer :: irec_master_noise

! ************** PROGRAM STARTS HERE **************
!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!
! trivia about the programming style adopted here:
!
! note 1: for performance reasons, we try to use as much from the stack memory as possible.
!             This is done to avoid memory fragmentation and also to optimize performance.
!             Stack memory is a place in computer memory where all the variables that are declared
!             and initialized **before** runtime are stored. Our static array allocation will use that one.
!             All variables declared within our main routine also will be stored on the stack.
!
!             the heap is the section of computer memory where all the variables created or initialized
!             **at** runtime are stored. it is used for dynamic memory allocation.
!
!             stack is much faster than the heap.
!
!             when calling a function, additional storage will be allocated for the variables in that function.
!             that storage will be allocated in the heap memory segment.
!
!             most routine calls here will have rather long argument lists, probably because of this performance criteria.
!             using modules/common data blocks together with dynamic allocation will put data into heap memory,
!             thus it has longer latency to access variables than stack memory variables.
!
!             however, declaring the static arrays needed in compute_forces_crust_mantle_Dev()
!             like e.g. sum_terms, tempx1,...B1_m1_m2_5points,... in this main routine and
!             passing them along as arguments to the routine makes the code slower.
!             it seems that this stack/heap criterion is more complicated.
!
!             another reason why modules are avoided is to make the code thread safe.
!             having different threads access the same data structure and modifying it at the same time
!             would lead to problems. passing arguments is a way to avoid such complications.
!
! note 2: Most of the computation time is spent
!             inside the time loop (mainly in the compute_forces_crust_mantle_Dev() routine).
!             Any code performance tuning will be most effective in there.
!
! note 3: Fortran is a code language that uses column-first ordering for arrays,
!             e.g., it stores a(i,j) in this order: a(1,1),a(2,1),a(3,1),...,a(1,2),a(2,2),a(3,2),..
!             it is therefore more efficient to have the inner-loop over i, and the outer loop over j
!
! note 4: Deville et al. (2002) routines significantly reduce the total number of memory accesses
!             required to perform matrix-matrix products at the spectral element level.
!             For most compilers and hardware, will result in a significant speedup (> 30% or more, sometimes twice faster).
!
! note 5: a common technique to help compilers enhance pipelining is loop unrolling. We do this here in a simple
!             and straigthforward way, so don't be confused about the do-loop writing.
!
! note 6: whenever adding some new code, please make sure to use
!             spaces rather than tabs. Tabulators are in principle not allowed in Fortran95.
!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!
  ! initialize the MPI communicator and start the NPROCTOT MPI processes.
  call MPI_INIT(ier)

  ! initializes simulation parameters
  call initialize_simulation(myrank,MIN_ATTENUATION_PERIOD,MAX_ATTENUATION_PERIOD,NER_CRUST, &
                NER_80_MOHO,NER_220_80,NER_400_220,NER_600_400,NER_670_600,NER_771_670, &
                NER_TOPDDOUBLEPRIME_771,NER_CMB_TOPDDOUBLEPRIME,NER_OUTER_CORE, &
                NER_TOP_CENTRAL_CUBE_ICB,ANGULAR_WIDTH_XI_IN_DEGREES,NEX_XI,NEX_ETA, &
                NTSTEP_BETWEEN_OUTPUT_SEISMOS, &
                NTSTEP_BETWEEN_READ_ADJSRC,NSTEP,NSOURCES,NTSTEP_BETWEEN_FRAMES, &
                NTSTEP_BETWEEN_OUTPUT_INFO,NUMBER_OF_RUNS,NUMBER_OF_THIS_RUN,SIMULATION_TYPE, &
                DT,ROCEAN,RMIDDLE_CRUST,RMOHO,R80,R220,R400,R600,R670,R771,&
                RTOPDDOUBLEPRIME,RCMB,RICB, &
                RHO_TOP_OC,RHO_BOTTOM_OC,RHO_OCEANS, &
                MOVIE_VOLUME_TYPE,MOVIE_START,MOVIE_STOP, &
                HDUR_MOVIE,MOVIE_TOP,MOVIE_BOTTOM,MOVIE_WEST,MOVIE_EAST, &
                MOVIE_NORTH,MOVIE_SOUTH,MOVIE_SURFACE,MOVIE_VOLUME, &
                RECEIVERS_CAN_BE_BURIED,PRINT_SOURCE_TIME_FUNCTION, &
                SAVE_MESH_FILES,ABSORBING_CONDITIONS,INCLUDE_CENTRAL_CUBE,SAVE_FORWARD, &
                SAVE_ALL_SEISMOS_IN_ONE_FILE,MOVIE_COARSE,OUTPUT_SEISMOS_ASCII_TEXT, &
                OUTPUT_SEISMOS_SAC_ALPHANUM,OUTPUT_SEISMOS_SAC_BINARY, &
                ROTATE_SEISMOGRAMS_RT,WRITE_SEISMOGRAMS_BY_MASTER,USE_BINARY_FOR_LARGE_FILE, &
                LOCAL_PATH,OUTPUT_FILES, &
                ratio_sampling_array, ner, doubling_index,r_bottom,r_top, &
                this_region_has_a_doubling,rmins,rmaxs, &
                TOPOGRAPHY,HONOR_1D_SPHERICAL_MOHO,ONE_CRUST, &
                nspl,rspl,espl,espl2,ibathy_topo, &
                NSPEC2DMAX_XMIN_XMAX,NSPEC2DMAX_YMIN_YMAX,NSPEC2D_BOTTOM,NSPEC2D_TOP, &
                NGLOB1D_RADIAL,NGLOB2DMAX_XMIN_XMAX,NGLOB2DMAX_YMIN_YMAX, &
                xigll,yigll,zigll,wxgll,wygll,wzgll,wgll_cube, &
                hprime_xx,hprime_yy,hprime_zz,hprime_xxT, &
                hprimewgll_xx,hprimewgll_yy,hprimewgll_zz,hprimewgll_xxT, &
                wgllwgll_xy,wgllwgll_xz,wgllwgll_yz, &
                rec_filename,STATIONS,nrec,NOISE_TOMOGRAPHY)

!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!
! starts reading the databases
  call read_mesh_databases(myrank,rho_vp_crust_mantle,rho_vs_crust_mantle, &
              xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
              xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
              etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
              gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
              rhostore_crust_mantle,kappavstore_crust_mantle,muvstore_crust_mantle, &
              kappahstore_crust_mantle,muhstore_crust_mantle,eta_anisostore_crust_mantle, &
              nspec_iso,nspec_tiso,nspec_ani, &
              c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
              c14store_crust_mantle,c15store_crust_mantle,c16store_crust_mantle, &
              c22store_crust_mantle,c23store_crust_mantle,c24store_crust_mantle, &
              c25store_crust_mantle,c26store_crust_mantle,c33store_crust_mantle, &
              c34store_crust_mantle,c35store_crust_mantle,c36store_crust_mantle, &
              c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
              c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
              ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
            ! -- idoubling_crust_mantle,  
              is_on_a_slice_edge_crust_mantle,rmass_crust_mantle,rmass_ocean_load, &
              vp_outer_core,xstore_outer_core,ystore_outer_core,zstore_outer_core, &
              xix_outer_core,xiy_outer_core,xiz_outer_core, &
              etax_outer_core,etay_outer_core,etaz_outer_core, &
              gammax_outer_core,gammay_outer_core,gammaz_outer_core, &
              rhostore_outer_core,kappavstore_outer_core, &
              ibool_outer_core,idoubling_outer_core,ispec_is_tiso_outer_core, &
              is_on_a_slice_edge_outer_core,rmass_outer_core, &
              xstore_inner_core,ystore_inner_core,zstore_inner_core, &
              xix_inner_core,xiy_inner_core,xiz_inner_core, &
              etax_inner_core,etay_inner_core,etaz_inner_core, &
              gammax_inner_core,gammay_inner_core,gammaz_inner_core, &
              rhostore_inner_core,kappavstore_inner_core,muvstore_inner_core, &
              c11store_inner_core,c12store_inner_core,c13store_inner_core, &
              c33store_inner_core,c44store_inner_core, &
              ibool_inner_core,idoubling_inner_core,ispec_is_tiso_inner_core, &
              is_on_a_slice_edge_inner_core,rmass_inner_core, &
              ABSORBING_CONDITIONS,LOCAL_PATH)

  ! read 2-D addressing for summation between slices with MPI
  call read_mesh_databases_addressing(myrank, &
              iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle, &
              iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
              npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
              iboolfaces_crust_mantle,npoin2D_faces_crust_mantle, &
              iboolcorner_crust_mantle, &
              iboolleft_xi_outer_core,iboolright_xi_outer_core, &
              iboolleft_eta_outer_core,iboolright_eta_outer_core, &
              npoin2D_xi_outer_core,npoin2D_eta_outer_core,&
              iboolfaces_outer_core,npoin2D_faces_outer_core, &
              iboolcorner_outer_core, &
              iboolleft_xi_inner_core,iboolright_xi_inner_core, &
              iboolleft_eta_inner_core,iboolright_eta_inner_core, &
              npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
              iboolfaces_inner_core,npoin2D_faces_inner_core, &
              iboolcorner_inner_core, &
              iprocfrom_faces,iprocto_faces,imsg_type, &
              iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
              LOCAL_PATH,OUTPUT_FILES, &
              NGLOB2DMAX_XMIN_XMAX,NGLOB2DMAX_YMIN_YMAX,NGLOB1D_RADIAL, &
              NGLOB2DMAX_XY,NUMMSGS_FACES,NUM_MSG_TYPES,NCORNERSCHUNKS, &
              addressing,ichunk_slice,iproc_xi_slice,iproc_eta_slice, &
              ichunk,iproc_xi,iproc_eta)

  ! to couple mantle with outer core
  call read_mesh_databases_coupling(myrank, &
              nspec2D_xmin_crust_mantle,nspec2D_xmax_crust_mantle, &
              nspec2D_ymin_crust_mantle,nspec2D_ymax_crust_mantle, &
              ibelm_xmin_crust_mantle,ibelm_xmax_crust_mantle,ibelm_ymin_crust_mantle, &
              ibelm_ymax_crust_mantle,ibelm_bottom_crust_mantle,ibelm_top_crust_mantle, &
              normal_xmin_crust_mantle,normal_xmax_crust_mantle,normal_ymin_crust_mantle, &
              normal_ymax_crust_mantle,normal_bottom_crust_mantle,normal_top_crust_mantle, &
              jacobian2D_xmin_crust_mantle,jacobian2D_xmax_crust_mantle,jacobian2D_ymin_crust_mantle, &
              jacobian2D_ymax_crust_mantle,jacobian2D_bottom_crust_mantle,jacobian2D_top_crust_mantle, &
              nspec2D_xmin_outer_core,nspec2D_xmax_outer_core, &
              nspec2D_ymin_outer_core,nspec2D_ymax_outer_core, &
              ibelm_xmin_outer_core,ibelm_xmax_outer_core,ibelm_ymin_outer_core, &
              ibelm_ymax_outer_core,ibelm_bottom_outer_core,ibelm_top_outer_core, &
              normal_xmin_outer_core,normal_xmax_outer_core,normal_ymin_outer_core, &
              normal_ymax_outer_core,normal_bottom_outer_core,normal_top_outer_core, &
              jacobian2D_xmin_outer_core,jacobian2D_xmax_outer_core,jacobian2D_ymin_outer_core, &
              jacobian2D_ymax_outer_core,jacobian2D_bottom_outer_core,jacobian2D_top_outer_core, &
              nspec2D_xmin_inner_core,nspec2D_xmax_inner_core, &
              nspec2D_ymin_inner_core,nspec2D_ymax_inner_core, &
              ibelm_xmin_inner_core,ibelm_xmax_inner_core,ibelm_ymin_inner_core, &
              ibelm_ymax_inner_core,ibelm_bottom_inner_core,ibelm_top_inner_core, &
              ibelm_moho_top,ibelm_moho_bot,ibelm_400_top,ibelm_400_bot, &
              ibelm_670_top,ibelm_670_bot,normal_moho,normal_400,normal_670, &
              k_top,k_bot,moho_kl,d400_kl,d670_kl,cmb_kl,icb_kl, &
              LOCAL_PATH,SIMULATION_TYPE)

! added this to reduce the size of the buffers
! size of buffers is the sum of two sizes because we handle two regions in the same MPI call
  npoin2D_max_all_CM_IC = max(maxval(npoin2D_xi_crust_mantle(:) + npoin2D_xi_inner_core(:)), &
                        maxval(npoin2D_eta_crust_mantle(:) + npoin2D_eta_inner_core(:)))

  allocate(buffer_send_faces(NDIM,npoin2D_max_all_CM_IC,NUMFACES_SHARED), &
          buffer_received_faces(NDIM,npoin2D_max_all_CM_IC,NUMFACES_SHARED),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating mpi buffer')

  allocate(b_buffer_send_faces(NDIM,npoin2D_max_all_CM_IC,NUMFACES_SHARED), &
          b_buffer_received_faces(NDIM,npoin2D_max_all_CM_IC,NUMFACES_SHARED),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating mpi b_buffer')

  call fix_non_blocking_slices(is_on_a_slice_edge_crust_mantle,iboolright_xi_crust_mantle, &
         iboolleft_xi_crust_mantle,iboolright_eta_crust_mantle,iboolleft_eta_crust_mantle, &
         npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle,ibool_crust_mantle, &
         mask_ibool,NSPEC_CRUST_MANTLE,NGLOB_CRUST_MANTLE,NGLOB2DMAX_XMIN_XMAX_CM,NGLOB2DMAX_YMIN_YMAX_CM)

  call fix_non_blocking_slices(is_on_a_slice_edge_outer_core,iboolright_xi_outer_core, &
         iboolleft_xi_outer_core,iboolright_eta_outer_core,iboolleft_eta_outer_core, &
         npoin2D_xi_outer_core,npoin2D_eta_outer_core,ibool_outer_core, &
         mask_ibool,NSPEC_OUTER_CORE,NGLOB_OUTER_CORE,NGLOB2DMAX_XMIN_XMAX_OC,NGLOB2DMAX_YMIN_YMAX_OC)

  call fix_non_blocking_slices(is_on_a_slice_edge_inner_core,iboolright_xi_inner_core, &
         iboolleft_xi_inner_core,iboolright_eta_inner_core,iboolleft_eta_inner_core, &
         npoin2D_xi_inner_core,npoin2D_eta_inner_core,ibool_inner_core, &
         mask_ibool,NSPEC_INNER_CORE,NGLOB_INNER_CORE,NGLOB2DMAX_XMIN_XMAX_IC,NGLOB2DMAX_YMIN_YMAX_IC)

  ! absorbing boundaries
  if(ABSORBING_CONDITIONS) then
    ! crust_mantle
    if (nspec2D_xmin_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_xmin_cm = nspec2D_xmin_crust_mantle
    else
      nabs_xmin_cm = 1
    endif
    allocate(absorb_xmin_crust_mantle5(NDIM,NGLLY,NGLLZ,nabs_xmin_cm,8),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb xmin')

    if (nspec2D_xmax_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_xmax_cm = nspec2D_xmax_crust_mantle
    else
      nabs_xmax_cm = 1
    endif
    allocate(absorb_xmax_crust_mantle5(NDIM,NGLLY,NGLLZ,nabs_xmax_cm,8),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb xmax')

    if (nspec2D_ymin_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_ymin_cm = nspec2D_ymin_crust_mantle
    else
      nabs_ymin_cm = 1
    endif
    allocate(absorb_ymin_crust_mantle5(NDIM,NGLLX,NGLLZ,nabs_ymin_cm,8),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb ymin')

    if (nspec2D_ymax_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_ymax_cm = nspec2D_ymax_crust_mantle
    else
      nabs_ymax_cm = 1
    endif
    allocate(absorb_ymax_crust_mantle5(NDIM,NGLLX,NGLLZ,nabs_ymax_cm,8),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb ymax')

    ! outer_core
    if (nspec2D_xmin_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_xmin_oc = nspec2D_xmin_outer_core
    else
      nabs_xmin_oc = 1
    endif
    allocate(absorb_xmin_outer_core(NGLLY,NGLLZ,nabs_xmin_oc),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb xmin')

    if (nspec2D_xmax_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_xmax_oc = nspec2D_xmax_outer_core
    else
      nabs_xmax_oc = 1
    endif
    allocate(absorb_xmax_outer_core(NGLLY,NGLLZ,nabs_xmax_oc),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb xmax')

    if (nspec2D_ymin_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_ymin_oc = nspec2D_ymin_outer_core
    else
      nabs_ymin_oc = 1
    endif
    allocate(absorb_ymin_outer_core(NGLLX,NGLLZ,nabs_ymin_oc),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb ymin')

    if (nspec2D_ymax_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_ymax_oc = nspec2D_ymax_outer_core
    else
      nabs_ymax_oc = 1
    endif
    allocate(absorb_ymax_outer_core(NGLLX,NGLLZ,nabs_ymax_oc),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb ymax')

    if (NSPEC2D_BOTTOM(IREGION_OUTER_CORE) > 0 .and. &
       (SIMULATION_TYPE == 3 .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_zmin_oc = NSPEC2D_BOTTOM(IREGION_OUTER_CORE)
    else
      nabs_zmin_oc = 1
    endif
    allocate(absorb_zmin_outer_core(NGLLX,NGLLY,nabs_zmin_oc),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb zmin')

    ! read arrays for Stacey conditions
    call read_mesh_databases_stacey(myrank, &
                      nimin_crust_mantle,nimax_crust_mantle,njmin_crust_mantle, &
                      njmax_crust_mantle,nkmin_xi_crust_mantle,nkmin_eta_crust_mantle, &
                      nspec2D_xmin_crust_mantle,nspec2D_xmax_crust_mantle, &
                      nspec2D_ymin_crust_mantle,nspec2D_ymax_crust_mantle, &
                      reclen_xmin_crust_mantle,reclen_xmax_crust_mantle, &
                      reclen_ymin_crust_mantle,reclen_ymax_crust_mantle, &
                      nimin_outer_core,nimax_outer_core,njmin_outer_core, &
                      njmax_outer_core,nkmin_xi_outer_core,nkmin_eta_outer_core, &
                      nspec2D_xmin_outer_core,nspec2D_xmax_outer_core, &
                      nspec2D_ymin_outer_core,nspec2D_ymax_outer_core, &
                      reclen_xmin_outer_core,reclen_xmax_outer_core, &
                      reclen_ymin_outer_core,reclen_ymax_outer_core, &
                      reclen_zmin,NSPEC2D_BOTTOM, &
                      SIMULATION_TYPE,SAVE_FORWARD,LOCAL_PATH,NSTEP)

  endif

!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!
! source and receivers

  ! allocate arrays for source
  allocate(islice_selected_source(NSOURCES), &
          ispec_selected_source(NSOURCES), &
          Mxx(NSOURCES), &
          Myy(NSOURCES), &
          Mzz(NSOURCES), &
          Mxy(NSOURCES), &
          Mxz(NSOURCES), &
          Myz(NSOURCES), &
          xi_source(NSOURCES), &
          eta_source(NSOURCES), &
          gamma_source(NSOURCES), &
          tshift_cmt(NSOURCES), &
          hdur(NSOURCES), &
          hdur_gaussian(NSOURCES), &
          theta_source(NSOURCES), &
          phi_source(NSOURCES), &
          nu_source(NDIM,NDIM,NSOURCES),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating source arrays')

  ! allocate memory for receiver arrays
  allocate(islice_selected_rec(nrec), &
          ispec_selected_rec(nrec), &
          xi_receiver(nrec), &
          eta_receiver(nrec), &
          gamma_receiver(nrec), &
          station_name(nrec), &
          network_name(nrec), &
          stlat(nrec), &
          stlon(nrec), &
          stele(nrec), &
          stbur(nrec), &
          nu(NDIM,NDIM,nrec),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating receiver arrays')

  ! locates sources and receivers
  call setup_sources_receivers(NSOURCES,myrank,ibool_crust_mantle, &
                      xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
                      xigll,yigll,zigll,TOPOGRAPHY, &
                      sec,tshift_cmt,theta_source,phi_source, &
                      NSTEP,DT,hdur,hdur_gaussian,t0,Mxx,Myy,Mzz,Mxy,Mxz,Myz, &
                      islice_selected_source,ispec_selected_source, &
                      xi_source,eta_source,gamma_source,nu_source, &
                      rspl,espl,espl2,nspl,ibathy_topo,NEX_XI,PRINT_SOURCE_TIME_FUNCTION, &
                      rec_filename,nrec,islice_selected_rec,ispec_selected_rec, &
                      xi_receiver,eta_receiver,gamma_receiver,station_name,network_name, &
                      stlat,stlon,stele,stbur,nu, &
                      nrec_local,nadj_rec_local,nrec_simulation, &
                      SIMULATION_TYPE,RECEIVERS_CAN_BE_BURIED,MOVIE_SURFACE,MOVIE_VOLUME, &
                      HDUR_MOVIE,OUTPUT_FILES,LOCAL_PATH)

  ! allocates source arrays
  if (SIMULATION_TYPE == 1  .or. SIMULATION_TYPE == 3) then
    allocate(sourcearrays(NDIM,NGLLX,NGLLY,NGLLZ,NSOURCES),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating sourcearrays')

    ! stores source arrays
    call setup_sources_receivers_srcarr(NSOURCES,myrank, &
                      ispec_selected_source,islice_selected_source, &
                      xi_source,eta_source,gamma_source, &
                      Mxx,Myy,Mzz,Mxy,Mxz,Myz, &
                      xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
                      etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
                      gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
                      xigll,yigll,zigll,sourcearrays)
  endif


  if (SIMULATION_TYPE == 2 .or. SIMULATION_TYPE == 3) then
    NSTEP_SUB_ADJ = ceiling( dble(NSTEP)/dble(NTSTEP_BETWEEN_READ_ADJSRC) )
    allocate(iadj_vec(NSTEP),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating iadj_vec')
    
    ! initializes iadj_vec
    do it=1,NSTEP
       iadj_vec(it) = NSTEP-it+1  ! default is for reversing entire record
    enddo

    if(nadj_rec_local > 0) then
      ! allocate adjoint source arrays
      allocate(adj_sourcearrays(NDIM,NGLLX,NGLLY,NGLLZ,nadj_rec_local,NTSTEP_BETWEEN_READ_ADJSRC),stat=ier)
      if( ier /= 0 ) call exit_MPI(myrank,'error allocating adjoint sourcearrays')
      adj_sourcearrays = 0._CUSTOM_REAL

      ! allocate indexing arrays
      allocate(iadjsrc(NSTEP_SUB_ADJ,2), &
              iadjsrc_len(NSTEP_SUB_ADJ),stat=ier)
      if( ier /= 0 ) call exit_MPI(myrank,'error allocating adjoint indexing arrays')
      ! initializes iadjsrc, iadjsrc_len and iadj_vec
      call setup_sources_receivers_adjindx(NSTEP,NSTEP_SUB_ADJ, &
                      NTSTEP_BETWEEN_READ_ADJSRC, &
                      iadjsrc,iadjsrc_len,iadj_vec)
    endif
  endif

  ! allocates receiver interpolators
  if (nrec_local > 0) then
    ! allocate Lagrange interpolators for receivers
    allocate(hxir_store(nrec_local,NGLLX), &
            hetar_store(nrec_local,NGLLY), &
            hgammar_store(nrec_local,NGLLZ),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating receiver interpolators')
    ! define local to global receiver numbering mapping
    allocate(number_receiver_global(nrec_local),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating global receiver numbering')
    ! define and store Lagrange interpolators at all the receivers
    if (SIMULATION_TYPE == 2) then
      nadj_hprec_local = nrec_local
    else
      nadj_hprec_local = 1
    endif
    allocate(hpxir_store(nadj_hprec_local,NGLLX), &
            hpetar_store(nadj_hprec_local,NGLLY), &
            hpgammar_store(nadj_hprec_local,NGLLZ),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating derivative interpolators')

    ! stores interpolators for receiver positions
    call setup_sources_receivers_intp(NSOURCES,myrank, &
                      islice_selected_source, &
                      xi_source,eta_source,gamma_source, &
                      xigll,yigll,zigll, &
                      SIMULATION_TYPE,nrec,nrec_local, &
                      islice_selected_rec,number_receiver_global, &
                      xi_receiver,eta_receiver,gamma_receiver, &
                      hxir_store,hetar_store,hgammar_store, &
                      nadj_hprec_local,hpxir_store,hpetar_store,hpgammar_store)

    ! allocate seismogram array
    if (SIMULATION_TYPE == 1 .or. SIMULATION_TYPE == 3) then
      allocate(seismograms(NDIM,nrec_local,NTSTEP_BETWEEN_OUTPUT_SEISMOS),stat=ier)
      if(ier /= 0) stop 'error while allocating seismograms'
    else
      allocate(seismograms(NDIM*NDIM,nrec_local,NTSTEP_BETWEEN_OUTPUT_SEISMOS),stat=ier)
      if(ier /= 0) stop 'error while allocating seismograms'
      ! allocate Frechet derivatives array
      allocate(moment_der(NDIM,NDIM,nrec_local),sloc_der(NDIM,nrec_local), &
              stshift_der(nrec_local),shdur_der(nrec_local),stat=ier)
      if( ier /= 0 ) call exit_MPI(myrank,'error allocating frechet derivatives arrays')
      
      moment_der = 0._CUSTOM_REAL
      sloc_der = 0._CUSTOM_REAL
      stshift_der = 0._CUSTOM_REAL
      shdur_der = 0._CUSTOM_REAL

    endif
    ! initialize seismograms
    seismograms(:,:,:) = 0._CUSTOM_REAL
    nit_written = 0
  else
    ! allocate dummy array since we need it to pass as argument e.g. in write_seismograms() routine
    ! note: nrec_local is zero, fortran 90/95 should allow zero-sized array allocation...
    allocate(seismograms(NDIM,nrec_local,NTSTEP_BETWEEN_OUTPUT_SEISMOS),stat=ier)
    if( ier /= 0) stop 'error while allocating zero seismograms'    
    allocate(number_receiver_global(nrec_local),stat=ier)
    if( ier /= 0) stop 'error while allocating zero number_receiver_global'        
  endif

  ! get information about event name and location for SAC seismograms

  ! The following line is added for get_event_info subroutine.
  ! Because the way NSOURCES_SAC was declared has been changed.
  ! The rest of the changes in this program is just the updates of the subroutines that
  ! I did changes, e.g., adding/removing parameters. by Ebru Bozdag
  call get_event_info_parallel(myrank,yr_SAC,jda_SAC,ho_SAC,mi_SAC,sec_SAC,&
                              event_name_SAC,t_cmt_SAC,t_shift_SAC, &
                              elat_SAC,elon_SAC,depth_SAC,mb_SAC,cmt_lat_SAC,&
                              cmt_lon_SAC,cmt_depth_SAC,cmt_hdur_SAC,NSOURCES)

!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!

  ! user output
  if(myrank == 0) then

    write(IMAIN,*)
    write(IMAIN,*) 'Reference radius of the Earth used is ',R_EARTH_KM,' km'
    write(IMAIN,*)

    write(IMAIN,*)
    if(OCEANS_VAL) then
      write(IMAIN,*) 'incorporating the oceans using equivalent load'
    else
      write(IMAIN,*) 'no oceans'
    endif

    write(IMAIN,*)
    if(ELLIPTICITY_VAL) then
      write(IMAIN,*) 'incorporating ellipticity'
    else
      write(IMAIN,*) 'no ellipticity'
    endif

    write(IMAIN,*)
    if(TOPOGRAPHY) then
      write(IMAIN,*) 'incorporating surface topography'
    else
      write(IMAIN,*) 'no surface topography'
    endif

    write(IMAIN,*)
    if(GRAVITY_VAL) then
      write(IMAIN,*) 'incorporating self-gravitation (Cowling approximation)'
    else
      write(IMAIN,*) 'no self-gravitation'
    endif

    write(IMAIN,*)
    if(ROTATION_VAL) then
      write(IMAIN,*) 'incorporating rotation'
    else
      write(IMAIN,*) 'no rotation'
    endif

    write(IMAIN,*)
    if(ATTENUATION_VAL) then
      write(IMAIN,*) 'incorporating attenuation using ',N_SLS,' standard linear solids'

      if(ATTENUATION_3D_VAL) write(IMAIN,*) 'using 3D attenuation'

      if(USE_ATTENUATION_MIMIC ) write(IMAIN,*) 'mimicking effects on velocity only'
    else
      write(IMAIN,*) 'no attenuation'
    endif

    write(IMAIN,*)
    write(IMAIN,*)
    write(IMAIN,*)

  endif

  ! the mass matrix needs to be assembled with MPI here once and for all
  call prepare_timerun_rmass(myrank,rmass_ocean_load,rmass_crust_mantle, &
                      rmass_outer_core,rmass_inner_core, &
                      iproc_xi,iproc_eta,ichunk,addressing, &
                      iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle, &
                      iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
                      npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
                      iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
                      iboolleft_xi_outer_core,iboolright_xi_outer_core, &
                      iboolleft_eta_outer_core,iboolright_eta_outer_core, &
                      npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
                      iboolfaces_outer_core,iboolcorner_outer_core, &
                      iboolleft_xi_inner_core,iboolright_xi_inner_core, &
                      iboolleft_eta_inner_core,iboolright_eta_inner_core, &
                      npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
                      iboolfaces_inner_core,iboolcorner_inner_core, &
                      iprocfrom_faces,iprocto_faces,imsg_type, &
                      iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
                      buffer_send_faces,buffer_received_faces, &
                      buffer_send_chunkcorn_scalar,buffer_recv_chunkcorn_scalar, &
                      NUMMSGS_FACES,NUM_MSG_TYPES,NCORNERSCHUNKS, &
                      NGLOB1D_RADIAL,NGLOB2DMAX_XMIN_XMAX,NGLOB2DMAX_YMIN_YMAX,NGLOB2DMAX_XY,npoin2D_max_all_CM_IC)

  ! mass matrix including central cube
  if(INCLUDE_CENTRAL_CUBE) then

    if(myrank == 0) write(IMAIN,*) 'including central cube'

    ! compute number of messages to expect in cube as well as their size
    call comp_central_cube_buffer_size(iproc_xi,iproc_eta,ichunk, &
                NPROC_XI_VAL,NPROC_ETA_VAL,NSPEC2D_BOTTOM(IREGION_INNER_CORE), &
                nb_msgs_theor_in_cube,npoin2D_cube_from_slices)

    ! this value is used for dynamic memory allocation, therefore make sure it is never zero
    if(nb_msgs_theor_in_cube > 0) then
      non_zero_nb_msgs_theor_in_cube = nb_msgs_theor_in_cube
    else
      non_zero_nb_msgs_theor_in_cube = 1
    endif

    ! allocate buffers for cube and slices
    allocate(sender_from_slices_to_cube(non_zero_nb_msgs_theor_in_cube), &
            buffer_all_cube_from_slices(non_zero_nb_msgs_theor_in_cube,npoin2D_cube_from_slices,NDIM), &
            b_buffer_all_cube_from_slices(non_zero_nb_msgs_theor_in_cube,npoin2D_cube_from_slices,NDIM), &
            buffer_slices(npoin2D_cube_from_slices,NDIM), &
            b_buffer_slices(npoin2D_cube_from_slices,NDIM), &
            buffer_slices2(npoin2D_cube_from_slices,NDIM), &
            ibool_central_cube(non_zero_nb_msgs_theor_in_cube,npoin2D_cube_from_slices),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating cube buffers')

    ! handles the communications with the central cube if it was included in the mesh
    call prepare_timerun_centralcube(myrank,rmass_inner_core, &
                      iproc_xi,iproc_eta,ichunk, &
                      NSPEC2DMAX_XMIN_XMAX,NSPEC2DMAX_YMIN_YMAX,NSPEC2D_BOTTOM, &
                      addressing,ibool_inner_core,idoubling_inner_core, &
                      xstore_inner_core,ystore_inner_core,zstore_inner_core, &
                      nspec2D_xmin_inner_core,nspec2D_xmax_inner_core, &
                      nspec2D_ymin_inner_core,nspec2D_ymax_inner_core, &
                      ibelm_xmin_inner_core,ibelm_xmax_inner_core, &
                      ibelm_ymin_inner_core,ibelm_ymax_inner_core,ibelm_bottom_inner_core, &
                      nb_msgs_theor_in_cube,non_zero_nb_msgs_theor_in_cube, &
                      npoin2D_cube_from_slices,receiver_cube_from_slices, &
                      sender_from_slices_to_cube,ibool_central_cube, &
                      buffer_slices,buffer_slices2,buffer_all_cube_from_slices)

    call fix_non_blocking_central_cube(is_on_a_slice_edge_inner_core, &
         ibool_inner_core,NSPEC_INNER_CORE,NGLOB_INNER_CORE,nb_msgs_theor_in_cube,ibelm_bottom_inner_core, &
         idoubling_inner_core,npoin2D_cube_from_slices,ibool_central_cube, &
         NSPEC2D_BOTTOM(IREGION_INNER_CORE),ichunk)

  else

    ! allocate fictitious buffers for cube and slices with a dummy size
    ! just to be able to use them as arguments in subroutine calls
    allocate(sender_from_slices_to_cube(1), &
            buffer_all_cube_from_slices(1,1,1), &
            b_buffer_all_cube_from_slices(1,1,1), &
            buffer_slices(1,1), &
            b_buffer_slices(1,1), &
            buffer_slices2(1,1), &
            ibool_central_cube(1,1),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating dummy buffers')

  endif

  ! check that all the mass matrices are positive
  if(OCEANS_VAL) then
    if(minval(rmass_ocean_load) <= 0.) call exit_MPI(myrank,'negative mass matrix term for the oceans')
  endif
  if(minval(rmass_crust_mantle) <= 0.) call exit_MPI(myrank,'negative mass matrix term for the crust_mantle')
  if(minval(rmass_inner_core) <= 0.) call exit_MPI(myrank,'negative mass matrix term for the inner core')
  if(minval(rmass_outer_core) <= 0.) call exit_MPI(myrank,'negative mass matrix term for the outer core')

  ! for efficiency, invert final mass matrix once and for all on each slice
  if(OCEANS_VAL) rmass_ocean_load = 1._CUSTOM_REAL / rmass_ocean_load
  rmass_crust_mantle = 1._CUSTOM_REAL / rmass_crust_mantle
  rmass_outer_core = 1._CUSTOM_REAL / rmass_outer_core
  rmass_inner_core = 1._CUSTOM_REAL / rmass_inner_core


  ! change x, y, z to r, theta and phi once and for all
  ! IMPROVE dangerous: old name kept (xstore ystore zstore) for new values

  ! convert in the crust and mantle
  do i = 1,NGLOB_CRUST_MANTLE
    call xyz_2_rthetaphi(xstore_crust_mantle(i), &
                        ystore_crust_mantle(i), &
                        zstore_crust_mantle(i),rval,thetaval,phival)
    xstore_crust_mantle(i) = rval
    ystore_crust_mantle(i) = thetaval
    zstore_crust_mantle(i) = phival
  enddo

  ! convert in the outer core
  do i = 1,NGLOB_OUTER_CORE
    call xyz_2_rthetaphi(xstore_outer_core(i), &
                        ystore_outer_core(i), &
                        zstore_outer_core(i),rval,thetaval,phival)
    xstore_outer_core(i) = rval
    ystore_outer_core(i) = thetaval
    zstore_outer_core(i) = phival
  enddo

  ! convert in the inner core
  do i = 1,NGLOB_INNER_CORE
    call xyz_2_rthetaphi(xstore_inner_core(i), &
                        ystore_inner_core(i), &
                        zstore_inner_core(i),rval,thetaval,phival)
    xstore_inner_core(i) = rval
    ystore_inner_core(i) = thetaval
    zstore_inner_core(i) = phival
  enddo

  ! allocate files to save movies
  if(MOVIE_SURFACE .or. NOISE_TOMOGRAPHY /=0) then    ! for noise tomography, store_val_x/y/z/ux/uy/uz needed for 'surface movie'
    if(MOVIE_COARSE .and. NOISE_TOMOGRAPHY ==0) then  ! only output corners !for noise tomography, must NOT be coarse
       nmovie_points = 2 * 2 * NSPEC2D_TOP(IREGION_CRUST_MANTLE)
       if(NGLLX /= NGLLY) &
        call exit_MPI(myrank,'MOVIE_COARSE together with MOVIE_SURFACE requires NGLLX=NGLLY')
       NIT = NGLLX - 1
    else
       nmovie_points = NGLLX * NGLLY * NSPEC2D_TOP(IREGION_CRUST_MANTLE)
       NIT = 1
    endif
    allocate(store_val_x(nmovie_points), &
            store_val_y(nmovie_points), &
            store_val_z(nmovie_points), &
            store_val_ux(nmovie_points), &
            store_val_uy(nmovie_points), &
            store_val_uz(nmovie_points),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating movie surface arrays')
  
    if (MOVIE_SURFACE) then  ! those arrays are not neccessary for noise tomography, so only allocate them in MOVIE_SURFACE case
       allocate(store_val_x_all(nmovie_points,0:NPROCTOT_VAL-1), &
              store_val_y_all(nmovie_points,0:NPROCTOT_VAL-1), &
              store_val_z_all(nmovie_points,0:NPROCTOT_VAL-1), &
              store_val_ux_all(nmovie_points,0:NPROCTOT_VAL-1), &
              store_val_uy_all(nmovie_points,0:NPROCTOT_VAL-1), &
              store_val_uz_all(nmovie_points,0:NPROCTOT_VAL-1),stat=ier)
       if( ier /= 0 ) call exit_MPI(myrank,'error allocating movie surface all arrays')
    endif
    if(myrank == 0) then
      write(IMAIN,*)
      write(IMAIN,*) 'Movie surface:'
      write(IMAIN,*) '  Writing to moviedata*** files in output directory'
      if(MOVIE_VOLUME_TYPE == 5) then
        write(IMAIN,*) '  movie output: displacement'
      else
        write(IMAIN,*) '  movie output: velocity'
      endif
      write(IMAIN,*) '  time steps every: ',NTSTEP_BETWEEN_FRAMES
    endif
  endif


  ! output point and element information for 3D movies
  if(MOVIE_VOLUME) then
    ! the following has to be true for the the array dimensions of eps to match with those of xstore etc..
    ! note that epsilondev and eps_trace_over_3 don't have the same dimensions.. could cause trouble
    if (NSPEC_CRUST_MANTLE_STR_OR_ATT /= NSPEC_CRUST_MANTLE) &
      stop 'NSPEC_CRUST_MANTLE_STRAINS_ATT /= NSPEC_CRUST_MANTLE'
    if (NSPEC_CRUST_MANTLE_STRAIN_ONLY /= NSPEC_CRUST_MANTLE) &
      stop 'NSPEC_CRUST_MANTLE_STRAIN_ONLY /= NSPEC_CRUST_MANTLE'

    write(prname,'(a,i6.6,a)') trim(LOCAL_PATH)//'/'//'proc',myrank,'_'
    call count_points_movie_volume(prname,ibool_crust_mantle, xstore_crust_mantle,ystore_crust_mantle, &
                zstore_crust_mantle,MOVIE_TOP,MOVIE_BOTTOM,MOVIE_WEST,MOVIE_EAST,MOVIE_NORTH,MOVIE_SOUTH, &
                MOVIE_COARSE,npoints_3dmovie,nspecel_3dmovie,num_ibool_3dmovie,mask_ibool,mask_3dmovie)


    allocate(nu_3dmovie(3,3,npoints_3dmovie),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating nu for 3d movie')

    call write_movie_volume_mesh(npoints_3dmovie,prname,ibool_crust_mantle,xstore_crust_mantle, &
                           ystore_crust_mantle,zstore_crust_mantle, muvstore_crust_mantle_3dmovie, &
                           mask_3dmovie,mask_ibool,num_ibool_3dmovie,nu_3dmovie,MOVIE_COARSE)

    if(myrank == 0) then
      write(IMAIN,*)
      write(IMAIN,*) 'Movie volume:'    
      write(IMAIN,*) '  Writing to movie3D*** files on local disk databases directory'
      if(MOVIE_VOLUME_TYPE == 1) then
        write(IMAIN,*) '  movie output: strain'
      else if(MOVIE_VOLUME_TYPE == 2) then
        write(IMAIN,*) '  movie output: time integral of strain'
      else if(MOVIE_VOLUME_TYPE == 3) then
        write(IMAIN,*) '  movie output: potency or integral of strain'
      else if(MOVIE_VOLUME_TYPE == 4) then
        write(IMAIN,*) '  movie output: divergence and curl'  
      else if(MOVIE_VOLUME_TYPE == 5) then
        write(IMAIN,*) '  movie output: displacement'
      else if(MOVIE_VOLUME_TYPE == 6) then
        write(IMAIN,*) '  movie output: velocity'
      endif
      write(IMAIN,*) '  depth(T,B):',MOVIE_TOP,MOVIE_BOTTOM
      write(IMAIN,*) '  lon(W,E)  :',MOVIE_WEST,MOVIE_EAST
      write(IMAIN,*) '  lat(S,N)  :',MOVIE_SOUTH,MOVIE_NORTH
      write(IMAIN,*) '  Starting at time step:',MOVIE_START, 'ending at:',MOVIE_STOP,'every: ',NTSTEP_BETWEEN_FRAMES
    endif

  endif ! MOVIE_VOLUME

  ! sets up time increments and rotation constants
  call prepare_timerun_constants(myrank,NSTEP, &
                    DT,t0,scale_t,scale_t_inv,scale_displ,scale_veloc, &
                    deltat,deltatover2,deltatsqover2, &
                    b_deltat,b_deltatover2,b_deltatsqover2, &
                    two_omega_earth,A_array_rotation,B_array_rotation, &
                    b_two_omega_earth, SIMULATION_TYPE)

  ! precomputes gravity factors
  call prepare_timerun_gravity(myrank, &
                    minus_g_cmb,minus_g_icb, &
                    minus_gravity_table,minus_deriv_gravity_table, &
                    density_table,d_ln_density_dr_table,minus_rho_g_over_kappa_fluid, &
                    ONE_CRUST,RICB,RCMB,RTOPDDOUBLEPRIME, &
                    R600,R670,R220,R771,R400,R80,RMOHO,RMIDDLE_CRUST,ROCEAN)

  ! precomputes attenuation factors
  if(ATTENUATION_VAL) then
    call prepare_timerun_attenuation(myrank, &
                factor_scale_crust_mantle,one_minus_sum_beta_crust_mantle,factor_common_crust_mantle, &
                factor_scale_inner_core,one_minus_sum_beta_inner_core,factor_common_inner_core, &
                c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
                c22store_crust_mantle,c23store_crust_mantle, &
                c33store_crust_mantle,c44store_crust_mantle, &
                c55store_crust_mantle,c66store_crust_mantle, &
                muvstore_crust_mantle,muhstore_crust_mantle,ispec_is_tiso_crust_mantle, &
                muvstore_inner_core, &
                SIMULATION_TYPE,MOVIE_VOLUME,muvstore_crust_mantle_3dmovie, &
                c11store_inner_core,c12store_inner_core,c13store_inner_core, &
                c33store_inner_core,c44store_inner_core, &
                alphaval,betaval,gammaval,b_alphaval,b_betaval,b_gammaval, &
                deltat,b_deltat,LOCAL_PATH)
  endif

  if(myrank == 0) then

  write(IMAIN,*) 'for overlapping of communications with calculations:'
  write(IMAIN,*)

  percentage_edge = 100.*count(is_on_a_slice_edge_crust_mantle(:))/real(NSPEC_CRUST_MANTLE)
  write(IMAIN,*) 'percentage of edge elements in crust/mantle ',percentage_edge,'%'
  write(IMAIN,*) 'percentage of volume elements in crust/mantle ',100. - percentage_edge,'%'
  write(IMAIN,*)

  percentage_edge = 100.*count(is_on_a_slice_edge_outer_core(:))/real(NSPEC_OUTER_CORE)
  write(IMAIN,*) 'percentage of edge elements in outer core ',percentage_edge,'%'
  write(IMAIN,*) 'percentage of volume elements in outer core ',100. - percentage_edge,'%'
  write(IMAIN,*)

  percentage_edge = 100.*count(is_on_a_slice_edge_inner_core(:))/real(NSPEC_INNER_CORE)
  write(IMAIN,*) 'percentage of edge elements in inner core ',percentage_edge,'%'
  write(IMAIN,*) 'percentage of volume elements in inner core ',100. - percentage_edge,'%'
  write(IMAIN,*)

  endif

  if(.not. USE_NONBLOCKING_COMMS) then
    is_on_a_slice_edge_crust_mantle(:) = .true.
    is_on_a_slice_edge_outer_core(:) = .true.
    is_on_a_slice_edge_inner_core(:) = .true.
  endif

  ! initialize arrays to zero
  displ_crust_mantle(:,:) = 0._CUSTOM_REAL
  veloc_crust_mantle(:,:) = 0._CUSTOM_REAL
  accel_crust_mantle(:,:) = 0._CUSTOM_REAL

  displ_outer_core(:) = 0._CUSTOM_REAL
  veloc_outer_core(:) = 0._CUSTOM_REAL
  accel_outer_core(:) = 0._CUSTOM_REAL

  displ_inner_core(:,:) = 0._CUSTOM_REAL
  veloc_inner_core(:,:) = 0._CUSTOM_REAL
  accel_inner_core(:,:) = 0._CUSTOM_REAL

  ! put negligible initial value to avoid very slow underflow trapping
  if(FIX_UNDERFLOW_PROBLEM) then
    displ_crust_mantle(:,:) = VERYSMALLVAL
    displ_outer_core(:) = VERYSMALLVAL
    displ_inner_core(:,:) = VERYSMALLVAL
  endif

  if (SIMULATION_TYPE == 3) then
    rho_kl_crust_mantle(:,:,:,:) = 0._CUSTOM_REAL
    beta_kl_crust_mantle(:,:,:,:) = 0._CUSTOM_REAL
    alpha_kl_crust_mantle(:,:,:,:) = 0._CUSTOM_REAL
    if (NOISE_TOMOGRAPHY == 3) Sigma_kl_crust_mantle(:,:,:,:) = 0._CUSTOM_REAL

    ! approximate hessian
    if( APPROXIMATE_HESS_KL ) then
      allocate( hess_kl_crust_mantle(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ADJOINT),stat=ier)
      if( ier /= 0 ) call exit_MPI(myrank,'error allocating hessian')
      hess_kl_crust_mantle(:,:,:,:) = 0._CUSTOM_REAL
    endif

    ! For anisotropic kernels (in crust_mantle only)
    cijkl_kl_crust_mantle(:,:,:,:,:) = 0._CUSTOM_REAL

    rho_kl_outer_core(:,:,:,:) = 0._CUSTOM_REAL
    alpha_kl_outer_core(:,:,:,:) = 0._CUSTOM_REAL

    rho_kl_inner_core(:,:,:,:) = 0._CUSTOM_REAL
    beta_kl_inner_core(:,:,:,:) = 0._CUSTOM_REAL
    alpha_kl_inner_core(:,:,:,:) = 0._CUSTOM_REAL

    div_displ_outer_core(:,:,:,:) = 0._CUSTOM_REAL
    b_div_displ_outer_core(:,:,:,:) = 0._CUSTOM_REAL

    ! deviatoric kernel check
    if( deviatoric_outercore) then
      nspec_beta_kl_outer_core = NSPEC_OUTER_CORE_ADJOINT
    else
      nspec_beta_kl_outer_core = 1
    endif
    allocate(beta_kl_outer_core(NGLLX,NGLLY,NGLLZ,nspec_beta_kl_outer_core),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating beta outercore')
    beta_kl_outer_core(:,:,:,:) = 0._CUSTOM_REAL
  endif

  ! initialize to be on the save side for adjoint runs SIMULATION_TYPE==2
  eps_trace_over_3_crust_mantle(:,:,:,:) = 0._CUSTOM_REAL
  epsilondev_crust_mantle(:,:,:,:,:) = 0._CUSTOM_REAL
  eps_trace_over_3_inner_core(:,:,:,:) = 0._CUSTOM_REAL
  epsilondev_inner_core(:,:,:,:,:) = 0._CUSTOM_REAL
  if(FIX_UNDERFLOW_PROBLEM) then
    eps_trace_over_3_crust_mantle(:,:,:,:) = VERYSMALLVAL
    epsilondev_crust_mantle(:,:,:,:,:) = VERYSMALLVAL
    eps_trace_over_3_inner_core(:,:,:,:) = VERYSMALLVAL
    epsilondev_inner_core(:,:,:,:,:) = VERYSMALLVAL
  endif

  if (COMPUTE_AND_STORE_STRAIN) then
    if(MOVIE_VOLUME .and. (MOVIE_VOLUME_TYPE == 2 .or. MOVIE_VOLUME_TYPE == 3)) then
      Iepsilondev_crust_mantle(:,:,:,:,:) = 0._CUSTOM_REAL
      Ieps_trace_over_3_crust_mantle(:,:,:,:)=0._CUSTOM_REAL
    endif
  endif

  ! clear memory variables if attenuation
  if(ATTENUATION_VAL) then
    R_memory_crust_mantle(:,:,:,:,:,:) = 0._CUSTOM_REAL
    R_memory_inner_core(:,:,:,:,:,:) = 0._CUSTOM_REAL
    if(FIX_UNDERFLOW_PROBLEM) then
      R_memory_crust_mantle(:,:,:,:,:,:) = VERYSMALLVAL
      R_memory_inner_core(:,:,:,:,:,:) = VERYSMALLVAL
    endif
  endif

  ! reads files back from local disk or MT tape system if restart file
  ! note: for SIMULATION_TYPE 3 simulations, the stored wavefields
  !          will be read in the time loop after the Newmark time scheme update.
  !          this makes indexing and timing easier to match with adjoint wavefields indexing.
  call read_forward_arrays_startrun(myrank,NSTEP, &
                    SIMULATION_TYPE,NUMBER_OF_RUNS,NUMBER_OF_THIS_RUN, &
                    it_begin,it_end, &
                    displ_crust_mantle,veloc_crust_mantle,accel_crust_mantle, &
                    displ_inner_core,veloc_inner_core,accel_inner_core, &
                    displ_outer_core,veloc_outer_core,accel_outer_core, &
                    R_memory_crust_mantle,R_memory_inner_core, &
                    epsilondev_crust_mantle,epsilondev_inner_core, &
                    A_array_rotation,B_array_rotation, &
                    b_displ_crust_mantle,b_veloc_crust_mantle,b_accel_crust_mantle, &
                    b_displ_inner_core,b_veloc_inner_core,b_accel_inner_core, &
                    b_displ_outer_core,b_veloc_outer_core,b_accel_outer_core, &
                    b_R_memory_crust_mantle,b_R_memory_inner_core, &
                    b_epsilondev_crust_mantle,b_epsilondev_inner_core, &
                    b_A_array_rotation,b_B_array_rotation,LOCAL_PATH)

!<YANGL
  ! NOISE TOMOGRAPHY
  if ( NOISE_TOMOGRAPHY /= 0 ) then
    allocate(noise_sourcearray(NDIM,NGLLX,NGLLY,NGLLZ,NSTEP), &
            normal_x_noise(nmovie_points), &
            normal_y_noise(nmovie_points), &
            normal_z_noise(nmovie_points), &
            mask_noise(nmovie_points), &
            noise_surface_movie(NDIM,NGLLX,NGLLY,NSPEC2D_TOP(IREGION_CRUST_MANTLE)),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating noise arrays')
  
    noise_sourcearray(:,:,:,:,:) = 0._CUSTOM_REAL
    normal_x_noise(:)            = 0._CUSTOM_REAL
    normal_y_noise(:)            = 0._CUSTOM_REAL
    normal_z_noise(:)            = 0._CUSTOM_REAL
    mask_noise(:)                = 0._CUSTOM_REAL
    noise_surface_movie(:,:,:,:) = 0._CUSTOM_REAL
    
    call read_parameters_noise(myrank,nrec,NSTEP,nmovie_points, &
                              islice_selected_rec,xi_receiver,eta_receiver,gamma_receiver,nu, &
                              noise_sourcearray,xigll,yigll,zigll,NSPEC2D_TOP(IREGION_CRUST_MANTLE), &
                              NIT, ibool_crust_mantle, ibelm_top_crust_mantle, &
                              xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
                              irec_master_noise,normal_x_noise,normal_y_noise,normal_z_noise,mask_noise)

    call check_parameters_noise(myrank,NOISE_TOMOGRAPHY,SIMULATION_TYPE,SAVE_FORWARD, &
                              NUMBER_OF_RUNS, NUMBER_OF_THIS_RUN,ROTATE_SEISMOGRAMS_RT, &
                              SAVE_ALL_SEISMOS_IN_ONE_FILE, USE_BINARY_FOR_LARGE_FILE, &
                              MOVIE_COARSE,LOCAL_PATH,NSPEC2D_TOP(IREGION_CRUST_MANTLE),NSTEP)
  endif
!>YANGL

!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!

!
!   s t a r t   t i m e   i t e r a t i o n s
!

! synchronize all processes to make sure everybody is ready to start time loop
  call MPI_BARRIER(MPI_COMM_WORLD,ier)
  if(myrank == 0) write(IMAIN,*) 'All processes are synchronized before time loop'

  if(myrank == 0) then
    write(IMAIN,*)
    write(IMAIN,*) 'Starting time iteration loop...'
    write(IMAIN,*)
  endif

! create an empty file to monitor the start of the simulation
  if(myrank == 0) then
    open(unit=IOUT,file=trim(OUTPUT_FILES)//'/starttimeloop.txt',status='unknown',action='write')
    write(IOUT,*) 'hello, starting time loop'
    close(IOUT)
  endif

! initialize variables for writing seismograms
  seismo_offset = it_begin-1
  seismo_current = 0

  imodulo_NGLOB_CRUST_MANTLE = mod(NGLOB_CRUST_MANTLE,3)

! get MPI starting time
  time_start = MPI_WTIME()

! *********************************************************
! ************* MAIN LOOP OVER THE TIME STEPS *************
! *********************************************************

  do it = it_begin,it_end

    ! update position in seismograms
    seismo_current = seismo_current + 1

! way 1:
!    ! mantle
!    do i=1,NGLOB_CRUST_MANTLE
!      displ_crust_mantle(:,i) = displ_crust_mantle(:,i) &
!        + deltat*veloc_crust_mantle(:,i) + deltatsqover2*accel_crust_mantle(:,i)
!      veloc_crust_mantle(:,i) = veloc_crust_mantle(:,i) &
!        + deltatover2*accel_crust_mantle(:,i)
!    enddo
!    ! outer core
!    do i=1,NGLOB_OUTER_CORE
!      displ_outer_core(i) = displ_outer_core(i) &
!        + deltat*veloc_outer_core(i) + deltatsqover2*accel_outer_core(i)
!      veloc_outer_core(i) = veloc_outer_core(i) &
!        + deltatover2*accel_outer_core(i)
!    enddo
!    ! inner core
!    do i=1,NGLOB_INNER_CORE
!      displ_inner_core(:,i) = displ_inner_core(:,i) &
!        + deltat*veloc_inner_core(:,i) + deltatsqover2*accel_inner_core(:,i)
!      veloc_inner_core(:,i) = veloc_inner_core(:,i) &
!        + deltatover2*accel_inner_core(:,i)
!    enddo

! way 2:
! One common technique in computational science to help enhance pipelining is loop unrolling
!
! we're accessing NDIM=3 components at each line,
! that is, for an iteration, the register must contain
! NDIM * displ_ + NDIM * veloc_ + NDIM * accel + deltat + deltatsq..
! in most cases a real (CUSTOM_REAL) value will have 4 bytes,
! assuming a default cache size of about 128 bytes, we unroll here in steps of 3, thus 29 reals or 118 bytes,
! rather than with steps of 4
  if(imodulo_NGLOB_CRUST_MANTLE >= 1) then
    do i = 1,imodulo_NGLOB_CRUST_MANTLE
      displ_crust_mantle(:,i) = displ_crust_mantle(:,i) &
        + deltat*veloc_crust_mantle(:,i) + deltatsqover2*accel_crust_mantle(:,i)

      veloc_crust_mantle(:,i) = veloc_crust_mantle(:,i) &
        + deltatover2*accel_crust_mantle(:,i)

      accel_crust_mantle(:,i) = 0._CUSTOM_REAL
    enddo
  endif

    do i = mod(NGLOB_CRUST_MANTLE,3)+1,NGLOB_CRUST_MANTLE, 3 ! in steps of 3
      displ_crust_mantle(:,i) = displ_crust_mantle(:,i) &
        + deltat*veloc_crust_mantle(:,i) + deltatsqover2*accel_crust_mantle(:,i)
      displ_crust_mantle(:,i+1) = displ_crust_mantle(:,i+1) &
        + deltat*veloc_crust_mantle(:,i+1) + deltatsqover2*accel_crust_mantle(:,i+1)
      displ_crust_mantle(:,i+2) = displ_crust_mantle(:,i+2) &
        + deltat*veloc_crust_mantle(:,i+2) + deltatsqover2*accel_crust_mantle(:,i+2)


      veloc_crust_mantle(:,i) = veloc_crust_mantle(:,i) &
        + deltatover2*accel_crust_mantle(:,i)
      veloc_crust_mantle(:,i+1) = veloc_crust_mantle(:,i+1) &
        + deltatover2*accel_crust_mantle(:,i+1)
      veloc_crust_mantle(:,i+2) = veloc_crust_mantle(:,i+2) &
        + deltatover2*accel_crust_mantle(:,i+2)

      ! set acceleration to zero
      ! note: we do initialize acceleration in this loop since it is read already into the cache,
      !           otherwise it would have to be read in again for this explicitly,
      !           which would make this step more expensive
      accel_crust_mantle(:,i) = 0._CUSTOM_REAL
      accel_crust_mantle(:,i+1) = 0._CUSTOM_REAL
      accel_crust_mantle(:,i+2) = 0._CUSTOM_REAL
    enddo


    ! outer core
    do i = 1,mod(NGLOB_OUTER_CORE,4)
      displ_outer_core(i) = displ_outer_core(i) &
        + deltat*veloc_outer_core(i) + deltatsqover2*accel_outer_core(i)

      veloc_outer_core(i) = veloc_outer_core(i) &
        + deltatover2*accel_outer_core(i)

      accel_outer_core(i) = 0._CUSTOM_REAL
    enddo
    do i = mod(NGLOB_OUTER_CORE,4)+1,NGLOB_OUTER_CORE, 4 ! in steps of 4
      displ_outer_core(i) = displ_outer_core(i) &
        + deltat*veloc_outer_core(i) + deltatsqover2*accel_outer_core(i)
      displ_outer_core(i+1) = displ_outer_core(i+1) &
        + deltat*veloc_outer_core(i+1) + deltatsqover2*accel_outer_core(i+1)
      displ_outer_core(i+2) = displ_outer_core(i+2) &
        + deltat*veloc_outer_core(i+2) + deltatsqover2*accel_outer_core(i+2)
      displ_outer_core(i+3) = displ_outer_core(i+3) &
        + deltat*veloc_outer_core(i+3) + deltatsqover2*accel_outer_core(i+3)

      veloc_outer_core(i) = veloc_outer_core(i) &
        + deltatover2*accel_outer_core(i)
      veloc_outer_core(i+1) = veloc_outer_core(i+1) &
        + deltatover2*accel_outer_core(i+1)
      veloc_outer_core(i+2) = veloc_outer_core(i+2) &
        + deltatover2*accel_outer_core(i+2)
      veloc_outer_core(i+3) = veloc_outer_core(i+3) &
        + deltatover2*accel_outer_core(i+3)

      accel_outer_core(i) = 0._CUSTOM_REAL
      accel_outer_core(i+1) = 0._CUSTOM_REAL
      accel_outer_core(i+2) = 0._CUSTOM_REAL
      accel_outer_core(i+3) = 0._CUSTOM_REAL
    enddo


    ! inner core
    do i = 1,mod(NGLOB_INNER_CORE,3)
      displ_inner_core(:,i) = displ_inner_core(:,i) &
        + deltat*veloc_inner_core(:,i) + deltatsqover2*accel_inner_core(:,i)

      veloc_inner_core(:,i) = veloc_inner_core(:,i) &
        + deltatover2*accel_inner_core(:,i)

      accel_inner_core(:,i) = 0._CUSTOM_REAL
    enddo
    do i = mod(NGLOB_INNER_CORE,3)+1,NGLOB_INNER_CORE, 3 ! in steps of 3
      displ_inner_core(:,i) = displ_inner_core(:,i) &
        + deltat*veloc_inner_core(:,i) + deltatsqover2*accel_inner_core(:,i)
      displ_inner_core(:,i+1) = displ_inner_core(:,i+1) &
        + deltat*veloc_inner_core(:,i+1) + deltatsqover2*accel_inner_core(:,i+1)
      displ_inner_core(:,i+2) = displ_inner_core(:,i+2) &
        + deltat*veloc_inner_core(:,i+2) + deltatsqover2*accel_inner_core(:,i+2)


      veloc_inner_core(:,i) = veloc_inner_core(:,i) &
        + deltatover2*accel_inner_core(:,i)
      veloc_inner_core(:,i+1) = veloc_inner_core(:,i+1) &
        + deltatover2*accel_inner_core(:,i+1)
      veloc_inner_core(:,i+2) = veloc_inner_core(:,i+2) &
        + deltatover2*accel_inner_core(:,i+2)

      accel_inner_core(:,i) = 0._CUSTOM_REAL
      accel_inner_core(:,i+1) = 0._CUSTOM_REAL
      accel_inner_core(:,i+2) = 0._CUSTOM_REAL
    enddo



    ! backward field
    if (SIMULATION_TYPE == 3) then
! way 1:
!      do i=1,NGLOB_CRUST_MANTLE
!        b_displ_crust_mantle(:,i) = b_displ_crust_mantle(:,i) &
!          + b_deltat*b_veloc_crust_mantle(:,i) + b_deltatsqover2*b_accel_crust_mantle(:,i)
!        b_veloc_crust_mantle(:,i) = b_veloc_crust_mantle(:,i) &
!          + b_deltatover2*b_accel_crust_mantle(:,i)
!      enddo
!      do i=1,NGLOB_OUTER_CORE
!        b_displ_outer_core(i) = b_displ_outer_core(i) &
!          + b_deltat*b_veloc_outer_core(i) + b_deltatsqover2*b_accel_outer_core(i)
!        b_veloc_outer_core(i) = b_veloc_outer_core(i) &
!          + b_deltatover2*b_accel_outer_core(i)
!      enddo
!      do i=1,NGLOB_INNER_CORE
!        b_displ_inner_core(:,i) = b_displ_inner_core(:,i) &
!          + b_deltat*b_veloc_inner_core(:,i) + b_deltatsqover2*b_accel_inner_core(:,i)
!        b_veloc_inner_core(:,i) = b_veloc_inner_core(:,i) &
!          + b_deltatover2*b_accel_inner_core(:,i)
!      enddo

! way 2:
    if(imodulo_NGLOB_CRUST_MANTLE >= 1) then
      do i=1,imodulo_NGLOB_CRUST_MANTLE
        b_displ_crust_mantle(:,i) = b_displ_crust_mantle(:,i) &
          + b_deltat*b_veloc_crust_mantle(:,i) + b_deltatsqover2*b_accel_crust_mantle(:,i)
        b_veloc_crust_mantle(:,i) = b_veloc_crust_mantle(:,i) &
          + b_deltatover2*b_accel_crust_mantle(:,i)
        b_accel_crust_mantle(:,i) = 0._CUSTOM_REAL
      enddo
    endif

      do i=mod(NGLOB_CRUST_MANTLE,3)+1,NGLOB_CRUST_MANTLE,3
        b_displ_crust_mantle(:,i) = b_displ_crust_mantle(:,i) &
          + b_deltat*b_veloc_crust_mantle(:,i) + b_deltatsqover2*b_accel_crust_mantle(:,i)
        b_displ_crust_mantle(:,i+1) = b_displ_crust_mantle(:,i+1) &
          + b_deltat*b_veloc_crust_mantle(:,i+1) + b_deltatsqover2*b_accel_crust_mantle(:,i+1)
        b_displ_crust_mantle(:,i+2) = b_displ_crust_mantle(:,i+2) &
          + b_deltat*b_veloc_crust_mantle(:,i+2) + b_deltatsqover2*b_accel_crust_mantle(:,i+2)


        b_veloc_crust_mantle(:,i) = b_veloc_crust_mantle(:,i) &
          + b_deltatover2*b_accel_crust_mantle(:,i)
        b_veloc_crust_mantle(:,i+1) = b_veloc_crust_mantle(:,i+1) &
          + b_deltatover2*b_accel_crust_mantle(:,i+1)
        b_veloc_crust_mantle(:,i+2) = b_veloc_crust_mantle(:,i+2) &
          + b_deltatover2*b_accel_crust_mantle(:,i+2)

        b_accel_crust_mantle(:,i) = 0._CUSTOM_REAL
        b_accel_crust_mantle(:,i+1) = 0._CUSTOM_REAL
        b_accel_crust_mantle(:,i+2) = 0._CUSTOM_REAL
      enddo


      do i=1,mod(NGLOB_OUTER_CORE,4)
        b_displ_outer_core(i) = b_displ_outer_core(i) &
          + b_deltat*b_veloc_outer_core(i) + b_deltatsqover2*b_accel_outer_core(i)
        b_veloc_outer_core(i) = b_veloc_outer_core(i) &
          + b_deltatover2*b_accel_outer_core(i)
        b_accel_outer_core(i) = 0._CUSTOM_REAL
      enddo
      do i=mod(NGLOB_OUTER_CORE,4)+1,NGLOB_OUTER_CORE,4
        b_displ_outer_core(i) = b_displ_outer_core(i) &
          + b_deltat*b_veloc_outer_core(i) + b_deltatsqover2*b_accel_outer_core(i)
        b_displ_outer_core(i+1) = b_displ_outer_core(i+1) &
          + b_deltat*b_veloc_outer_core(i+1) + b_deltatsqover2*b_accel_outer_core(i+1)
        b_displ_outer_core(i+2) = b_displ_outer_core(i+2) &
          + b_deltat*b_veloc_outer_core(i+2) + b_deltatsqover2*b_accel_outer_core(i+2)
        b_displ_outer_core(i+3) = b_displ_outer_core(i+3) &
          + b_deltat*b_veloc_outer_core(i+3) + b_deltatsqover2*b_accel_outer_core(i+3)

        b_veloc_outer_core(i) = b_veloc_outer_core(i) &
          + b_deltatover2*b_accel_outer_core(i)
        b_veloc_outer_core(i+1) = b_veloc_outer_core(i+1) &
          + b_deltatover2*b_accel_outer_core(i+1)
        b_veloc_outer_core(i+2) = b_veloc_outer_core(i+2) &
          + b_deltatover2*b_accel_outer_core(i+2)
        b_veloc_outer_core(i+3) = b_veloc_outer_core(i+3) &
          + b_deltatover2*b_accel_outer_core(i+3)

        b_accel_outer_core(i) = 0._CUSTOM_REAL
        b_accel_outer_core(i+1) = 0._CUSTOM_REAL
        b_accel_outer_core(i+2) = 0._CUSTOM_REAL
        b_accel_outer_core(i+3) = 0._CUSTOM_REAL
      enddo


      do i=1,mod(NGLOB_INNER_CORE,3)
        b_displ_inner_core(:,i) = b_displ_inner_core(:,i) &
          + b_deltat*b_veloc_inner_core(:,i) + b_deltatsqover2*b_accel_inner_core(:,i)
        b_veloc_inner_core(:,i) = b_veloc_inner_core(:,i) &
          + b_deltatover2*b_accel_inner_core(:,i)
        b_accel_inner_core(:,i) = 0._CUSTOM_REAL
      enddo
      do i=mod(NGLOB_INNER_CORE,3)+1,NGLOB_INNER_CORE,3
        b_displ_inner_core(:,i) = b_displ_inner_core(:,i) &
          + b_deltat*b_veloc_inner_core(:,i) + b_deltatsqover2*b_accel_inner_core(:,i)
        b_displ_inner_core(:,i+1) = b_displ_inner_core(:,i+1) &
          + b_deltat*b_veloc_inner_core(:,i+1) + b_deltatsqover2*b_accel_inner_core(:,i+1)
        b_displ_inner_core(:,i+2) = b_displ_inner_core(:,i+2) &
          + b_deltat*b_veloc_inner_core(:,i+2) + b_deltatsqover2*b_accel_inner_core(:,i+2)

        b_veloc_inner_core(:,i) = b_veloc_inner_core(:,i) &
          + b_deltatover2*b_accel_inner_core(:,i)
        b_veloc_inner_core(:,i+1) = b_veloc_inner_core(:,i+1) &
          + b_deltatover2*b_accel_inner_core(:,i+1)
        b_veloc_inner_core(:,i+2) = b_veloc_inner_core(:,i+2) &
          + b_deltatover2*b_accel_inner_core(:,i+2)

        b_accel_inner_core(:,i) = 0._CUSTOM_REAL
        b_accel_inner_core(:,i+1) = 0._CUSTOM_REAL
        b_accel_inner_core(:,i+2) = 0._CUSTOM_REAL
      enddo

    endif

    ! integral of strain for adjoint movie volume
    if(MOVIE_VOLUME .and. (MOVIE_VOLUME_TYPE == 2 .or. MOVIE_VOLUME_TYPE == 3) ) then
      Iepsilondev_crust_mantle(:,:,:,:,:) = Iepsilondev_crust_mantle(:,:,:,:,:)  &
                                              + deltat*epsilondev_crust_mantle(:,:,:,:,:)
      Ieps_trace_over_3_crust_mantle(:,:,:,:) = Ieps_trace_over_3_crust_mantle(:,:,:,:) &
                                              + deltat*eps_trace_over_3_crust_mantle(:,:,:,:)
    endif

    ! daniel: debugging
    !if( maxval(displ_crust_mantle(1,:)**2 + &
    !                displ_crust_mantle(2,:)**2 + displ_crust_mantle(3,:)**2) > 1.e4 ) then
    !  print*,'slice',myrank
    !  print*,'  crust_mantle displ:', maxval(displ_crust_mantle(1,:)), &
    !           maxval(displ_crust_mantle(2,:)),maxval(displ_crust_mantle(3,:))
    !  print*,'  indxs: ',maxloc( displ_crust_mantle(1,:)),maxloc( displ_crust_mantle(2,:)),maxloc( displ_crust_mantle(3,:))
    !  indx = maxloc( displ_crust_mantle(3,:) )
    !  rval = xstore_crust_mantle(indx(1))
    !  thetaval = ystore_crust_mantle(indx(1))
    !  phival = zstore_crust_mantle(indx(1))
    !  !thetaval = PI/2.0d0-datan(1.006760466d0*dcos(dble(thetaval))/dmax1(TINYVAL,dsin(dble(thetaval))))
    !  print*,'r/lat/lon:',rval*R_EARTH_KM,90.0-thetaval*180./PI,phival*180./PI
    !  call rthetaphi_2_xyz(rval,thetaval,phival,xstore_crust_mantle(indx(1)),&
    !                     ystore_crust_mantle(indx(1)),zstore_crust_mantle(indx(1)))
    !  print*,'x/y/z:',rval,thetaval,phival
    !  call exit_MPI(myrank,'error stability')
    !endif


    ! compute the maximum of the norm of the displacement
    ! in all the slices using an MPI reduction
    ! and output timestamp file to check that simulation is running fine
    if(mod(it,NTSTEP_BETWEEN_OUTPUT_INFO) == 0 .or. it == 5 .or. it == NSTEP) &
      call check_simulation_stability(it,displ_crust_mantle,displ_inner_core,displ_outer_core, &
                          b_displ_crust_mantle,b_displ_inner_core,b_displ_outer_core, &
                          eps_trace_over_3_crust_mantle,epsilondev_crust_mantle, &
                          SIMULATION_TYPE,OUTPUT_FILES,time_start,DT,t0,NSTEP, &
                          myrank)


    ! ****************************************************
    !   big loop over all spectral elements in the fluid
    ! ****************************************************

    ! compute internal forces in the fluid region
    if(CUSTOM_REAL == SIZE_REAL) then
      time = sngl((dble(it-1)*DT-t0)*scale_t_inv)
    else
      time = (dble(it-1)*DT-t0)*scale_t_inv
    endif

    iphase = 0 ! do not start any non blocking communications at this stage
    icall = 1  ! compute all the outer elements first in the case of non blocking MPI

    if( USE_DEVILLE_PRODUCTS_VAL ) then
      ! uses Deville et al. (2002) routine
      call compute_forces_outer_core_Dev(time,deltat,two_omega_earth, &
           A_array_rotation,B_array_rotation,d_ln_density_dr_table, &
           minus_rho_g_over_kappa_fluid, &
           displ_outer_core,accel_outer_core,div_displ_outer_core, &
           xstore_outer_core,ystore_outer_core,zstore_outer_core, &
           xix_outer_core,xiy_outer_core,xiz_outer_core, &
           etax_outer_core,etay_outer_core,etaz_outer_core, &
           gammax_outer_core,gammay_outer_core,gammaz_outer_core, &
          is_on_a_slice_edge_outer_core, &
          myrank,iproc_xi,iproc_eta,ichunk,addressing, &
          iboolleft_xi_outer_core,iboolright_xi_outer_core,iboolleft_eta_outer_core,iboolright_eta_outer_core, &
          npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
          iboolfaces_outer_core,iboolcorner_outer_core, &
          iprocfrom_faces,iprocto_faces, &
          iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
          buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
          buffer_send_chunkcorn_scalar,buffer_recv_chunkcorn_scalar,iphase,icall, &
           hprime_xx,hprime_xxT,hprimewgll_xx,hprimewgll_xxT, &
           wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
           ibool_outer_core,MOVIE_VOLUME)
    else
      ! div_displ_outer_core is initialized to zero in the following subroutine.
      call compute_forces_outer_core(time,deltat,two_omega_earth, &
           A_array_rotation,B_array_rotation,d_ln_density_dr_table, &
           minus_rho_g_over_kappa_fluid, &
           displ_outer_core,accel_outer_core,div_displ_outer_core, &
           xstore_outer_core,ystore_outer_core,zstore_outer_core, &
           xix_outer_core,xiy_outer_core,xiz_outer_core, &
           etax_outer_core,etay_outer_core,etaz_outer_core, &
           gammax_outer_core,gammay_outer_core,gammaz_outer_core, &
          is_on_a_slice_edge_outer_core, &
          myrank,iproc_xi,iproc_eta,ichunk,addressing, &
          iboolleft_xi_outer_core,iboolright_xi_outer_core,iboolleft_eta_outer_core,iboolright_eta_outer_core, &
          npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
          iboolfaces_outer_core,iboolcorner_outer_core, &
          iprocfrom_faces,iprocto_faces, &
          iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
          buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
          buffer_send_chunkcorn_scalar,buffer_recv_chunkcorn_scalar,iphase,icall, &
           hprime_xx,hprime_yy,hprime_zz,hprimewgll_xx,hprimewgll_yy,hprimewgll_zz, &
           wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
           ibool_outer_core,MOVIE_VOLUME)
    endif

    if (SIMULATION_TYPE == 3) then
      ! note on backward/reconstructed wavefields:
      !       time for b_displ( it=1 ) corresponds to (NSTEP - 1)*DT - t0  (after Newmark scheme...)
      !       as we start with saved wavefields b_displ( 1 ) <-> displ( NSTEP ) which correspond
      !       to a time (NSTEP - (it-1) - 1)*DT - t0
      !       for reconstructing the rotational contributions
      if(CUSTOM_REAL == SIZE_REAL) then
        time = sngl((dble(NSTEP-it)*DT-t0)*scale_t_inv)
      else
        time = (dble(NSTEP-it)*DT-t0)*scale_t_inv
      endif

      b_iphase = 0 ! do not start any non blocking communications at this stage
      b_icall = 1  ! compute all the outer elements first in the case of non blocking MPI

      if( USE_DEVILLE_PRODUCTS_VAL ) then
        ! uses Deville et al. (2002) routine
        call compute_forces_outer_core_Dev(time,b_deltat,b_two_omega_earth, &
           b_A_array_rotation,b_B_array_rotation,d_ln_density_dr_table, &
           minus_rho_g_over_kappa_fluid, &
           b_displ_outer_core,b_accel_outer_core,b_div_displ_outer_core, &
           xstore_outer_core,ystore_outer_core,zstore_outer_core, &
           xix_outer_core,xiy_outer_core,xiz_outer_core, &
           etax_outer_core,etay_outer_core,etaz_outer_core, &
           gammax_outer_core,gammay_outer_core,gammaz_outer_core, &
          is_on_a_slice_edge_outer_core, &
          myrank,iproc_xi,iproc_eta,ichunk,addressing, &
          iboolleft_xi_outer_core,iboolright_xi_outer_core,iboolleft_eta_outer_core,iboolright_eta_outer_core, &
          npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
          iboolfaces_outer_core,iboolcorner_outer_core, &
          iprocfrom_faces,iprocto_faces, &
          iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
          b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
          b_buffer_send_chunkcorn_scalar,b_buffer_recv_chunkcorn_scalar,b_iphase,b_icall, &
           hprime_xx,hprime_xxT,hprimewgll_xx,hprimewgll_xxT, &
           wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
           ibool_outer_core,MOVIE_VOLUME)
      else
        call compute_forces_outer_core(time,b_deltat,b_two_omega_earth, &
           b_A_array_rotation,b_B_array_rotation,d_ln_density_dr_table, &
           minus_rho_g_over_kappa_fluid, &
           b_displ_outer_core,b_accel_outer_core,b_div_displ_outer_core, &
           xstore_outer_core,ystore_outer_core,zstore_outer_core, &
           xix_outer_core,xiy_outer_core,xiz_outer_core, &
           etax_outer_core,etay_outer_core,etaz_outer_core, &
           gammax_outer_core,gammay_outer_core,gammaz_outer_core, &
          is_on_a_slice_edge_outer_core, &
          myrank,iproc_xi,iproc_eta,ichunk,addressing, &
          iboolleft_xi_outer_core,iboolright_xi_outer_core,iboolleft_eta_outer_core,iboolright_eta_outer_core, &
          npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
          iboolfaces_outer_core,iboolcorner_outer_core, &
          iprocfrom_faces,iprocto_faces, &
          iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
          b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
          b_buffer_send_chunkcorn_scalar,b_buffer_recv_chunkcorn_scalar,b_iphase,b_icall, &
           hprime_xx,hprime_yy,hprime_zz,hprimewgll_xx,hprimewgll_yy,hprimewgll_zz, &
           wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
           ibool_outer_core,MOVIE_VOLUME)
      endif
    endif

    ! Stacey absorbing boundaries
    if(NCHUNKS_VAL /= 6 .and. ABSORBING_CONDITIONS) then
      call compute_stacey_outer_core(ichunk,SIMULATION_TYPE,SAVE_FORWARD, &
                              NSTEP,it,ibool_outer_core, &
                              veloc_outer_core,accel_outer_core,b_accel_outer_core, &
                              vp_outer_core,wgllwgll_xz,wgllwgll_yz,wgllwgll_xy, &
                              jacobian2D_bottom_outer_core, &
                              jacobian2D_xmin_outer_core,jacobian2D_xmax_outer_core, &
                              jacobian2D_ymin_outer_core,jacobian2D_ymax_outer_core, &
                              ibelm_bottom_outer_core, &
                              ibelm_xmin_outer_core,ibelm_xmax_outer_core, &
                              ibelm_ymin_outer_core,ibelm_ymax_outer_core, &
                              nimin_outer_core,nimax_outer_core, &
                              njmin_outer_core,njmax_outer_core, &
                              nkmin_xi_outer_core,nkmin_eta_outer_core, &
                              NSPEC2D_BOTTOM, &
                              nspec2D_xmin_outer_core,nspec2D_xmax_outer_core, &
                              nspec2D_ymin_outer_core,nspec2D_ymax_outer_core, &
                              reclen_zmin, &
                              reclen_xmin_outer_core,reclen_xmax_outer_core, &
                              reclen_ymin_outer_core,reclen_ymax_outer_core, &
                              nabs_zmin_oc, &
                              nabs_xmin_oc,nabs_xmax_oc,nabs_ymin_oc,nabs_ymax_oc, &
                              absorb_zmin_outer_core, &
                              absorb_xmin_outer_core,absorb_xmax_outer_core, &
                              absorb_ymin_outer_core,absorb_ymax_outer_core)
    endif ! Stacey conditions


    ! ****************************************************
    ! **********  add matching with solid part  **********
    ! ****************************************************

    ! only for elements in first matching layer in the fluid

    !---
    !--- couple with mantle at the top of the outer core
    !---
    if(ACTUALLY_COUPLE_FLUID_CMB) &
      call compute_coupling_fluid_CMB(displ_crust_mantle,b_displ_crust_mantle, &
                            ibool_crust_mantle,ibelm_bottom_crust_mantle,  &
                            accel_outer_core,b_accel_outer_core, &
                            normal_top_outer_core,jacobian2D_top_outer_core, &
                            wgllwgll_xy,ibool_outer_core,ibelm_top_outer_core, &
                            SIMULATION_TYPE,NSPEC2D_TOP(IREGION_OUTER_CORE))

    !---
    !--- couple with inner core at the bottom of the outer core
    !---
    if(ACTUALLY_COUPLE_FLUID_ICB) &
      call compute_coupling_fluid_ICB(displ_inner_core,b_displ_inner_core, &
                            ibool_inner_core,ibelm_top_inner_core,  &
                            accel_outer_core,b_accel_outer_core, &
                            normal_bottom_outer_core,jacobian2D_bottom_outer_core, &
                            wgllwgll_xy,ibool_outer_core,ibelm_bottom_outer_core, &
                            SIMULATION_TYPE,NSPEC2D_BOTTOM(IREGION_OUTER_CORE))


    ! assemble all the contributions between slices using MPI

    ! outer core
  if(USE_NONBLOCKING_COMMS) then
    iphase = 1 ! start the non blocking communications
    call assemble_MPI_scalar(myrank,accel_outer_core,NGLOB_OUTER_CORE, &
            iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_outer_core,iboolright_xi_outer_core,iboolleft_eta_outer_core,iboolright_eta_outer_core, &
            npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
            iboolfaces_outer_core,iboolcorner_outer_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_scalar,buffer_recv_chunkcorn_scalar, &
            NUMMSGS_FACES,NCORNERSCHUNKS, &
            NPROC_XI_VAL,NPROC_ETA_VAL,NGLOB1D_RADIAL(IREGION_OUTER_CORE), &
            NGLOB2DMAX_XMIN_XMAX(IREGION_OUTER_CORE),NGLOB2DMAX_YMIN_YMAX(IREGION_OUTER_CORE), &
            NGLOB2DMAX_XY,NCHUNKS_VAL,iphase)

    icall = 2 ! now compute all the inner elements in the case of non blocking MPI

    if( USE_DEVILLE_PRODUCTS_VAL ) then
        ! uses Deville et al. (2002) routine
      call compute_forces_outer_core_Dev(time,deltat,two_omega_earth, &
           A_array_rotation,B_array_rotation,d_ln_density_dr_table, &
           minus_rho_g_over_kappa_fluid,displ_outer_core,accel_outer_core,div_displ_outer_core, &
           xstore_outer_core,ystore_outer_core,zstore_outer_core, &
           xix_outer_core,xiy_outer_core,xiz_outer_core, &
           etax_outer_core,etay_outer_core,etaz_outer_core, &
           gammax_outer_core,gammay_outer_core,gammaz_outer_core, &
          is_on_a_slice_edge_outer_core, &
          myrank,iproc_xi,iproc_eta,ichunk,addressing, &
          iboolleft_xi_outer_core,iboolright_xi_outer_core,iboolleft_eta_outer_core,iboolright_eta_outer_core, &
          npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
          iboolfaces_outer_core,iboolcorner_outer_core, &
          iprocfrom_faces,iprocto_faces, &
          iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
          buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
          buffer_send_chunkcorn_scalar,buffer_recv_chunkcorn_scalar,iphase,icall, &
           hprime_xx,hprime_xxT,hprimewgll_xx,hprimewgll_xxT, &
           wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
           ibool_outer_core,MOVIE_VOLUME)
    else
      ! div_displ_outer_core is initialized to zero in the following subroutine.
      call compute_forces_outer_core(time,deltat,two_omega_earth, &
           A_array_rotation,B_array_rotation,d_ln_density_dr_table, &
           minus_rho_g_over_kappa_fluid,displ_outer_core,accel_outer_core,div_displ_outer_core, &
           xstore_outer_core,ystore_outer_core,zstore_outer_core, &
           xix_outer_core,xiy_outer_core,xiz_outer_core, &
           etax_outer_core,etay_outer_core,etaz_outer_core, &
           gammax_outer_core,gammay_outer_core,gammaz_outer_core, &
          is_on_a_slice_edge_outer_core, &
          myrank,iproc_xi,iproc_eta,ichunk,addressing, &
          iboolleft_xi_outer_core,iboolright_xi_outer_core,iboolleft_eta_outer_core,iboolright_eta_outer_core, &
          npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
          iboolfaces_outer_core,iboolcorner_outer_core, &
          iprocfrom_faces,iprocto_faces, &
          iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
          buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
          buffer_send_chunkcorn_scalar,buffer_recv_chunkcorn_scalar,iphase,icall, &
           hprime_xx,hprime_yy,hprime_zz,hprimewgll_xx,hprimewgll_yy,hprimewgll_zz, &
           wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
           ibool_outer_core,MOVIE_VOLUME)
    endif

    do while (iphase <= 7) ! make sure the last communications are finished and processed
      call assemble_MPI_scalar(myrank,accel_outer_core,NGLOB_OUTER_CORE, &
            iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_outer_core,iboolright_xi_outer_core,iboolleft_eta_outer_core,iboolright_eta_outer_core, &
            npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
            iboolfaces_outer_core,iboolcorner_outer_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_scalar,buffer_recv_chunkcorn_scalar, &
            NUMMSGS_FACES,NCORNERSCHUNKS, &
            NPROC_XI_VAL,NPROC_ETA_VAL,NGLOB1D_RADIAL(IREGION_OUTER_CORE), &
            NGLOB2DMAX_XMIN_XMAX(IREGION_OUTER_CORE),NGLOB2DMAX_YMIN_YMAX(IREGION_OUTER_CORE), &
            NGLOB2DMAX_XY,NCHUNKS_VAL,iphase)
    enddo

  else ! if(.not. USE_NONBLOCKING_COMMS) then

    call assemble_MPI_scalar_block(myrank,accel_outer_core,NGLOB_OUTER_CORE, &
            iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_outer_core,iboolright_xi_outer_core, &
            iboolleft_eta_outer_core,iboolright_eta_outer_core, &
            npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
            iboolfaces_outer_core,iboolcorner_outer_core, &
            iprocfrom_faces,iprocto_faces,imsg_type, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_scalar,buffer_recv_chunkcorn_scalar, &
            NUMMSGS_FACES,NUM_MSG_TYPES,NCORNERSCHUNKS, &
            NPROC_XI_VAL,NPROC_ETA_VAL,NGLOB1D_RADIAL(IREGION_OUTER_CORE), &
            NGLOB2DMAX_XMIN_XMAX(IREGION_OUTER_CORE),NGLOB2DMAX_YMIN_YMAX(IREGION_OUTER_CORE), &
            NGLOB2DMAX_XY,NCHUNKS_VAL)

  endif

    ! multiply by the inverse of the mass matrix and update velocity

! way 1:
!    do i=1,NGLOB_OUTER_CORE
!      accel_outer_core(i) = accel_outer_core(i)*rmass_outer_core(i)
!      veloc_outer_core(i) = veloc_outer_core(i) + deltatover2*accel_outer_core(i)
!    enddo

! way 2:
    do i=1,mod(NGLOB_OUTER_CORE,4)
      accel_outer_core(i) = accel_outer_core(i)*rmass_outer_core(i)
      veloc_outer_core(i) = veloc_outer_core(i) + deltatover2*accel_outer_core(i)
    enddo
    do i=mod(NGLOB_OUTER_CORE,4)+1,NGLOB_OUTER_CORE,4
      accel_outer_core(i) = accel_outer_core(i)*rmass_outer_core(i)
      accel_outer_core(i+1) = accel_outer_core(i+1)*rmass_outer_core(i+1)
      accel_outer_core(i+2) = accel_outer_core(i+2)*rmass_outer_core(i+2)
      accel_outer_core(i+3) = accel_outer_core(i+3)*rmass_outer_core(i+3)

      veloc_outer_core(i) = veloc_outer_core(i) + deltatover2*accel_outer_core(i)
      veloc_outer_core(i+1) = veloc_outer_core(i+1) + deltatover2*accel_outer_core(i+1)
      veloc_outer_core(i+2) = veloc_outer_core(i+2) + deltatover2*accel_outer_core(i+2)
      veloc_outer_core(i+3) = veloc_outer_core(i+3) + deltatover2*accel_outer_core(i+3)
    enddo

    if (SIMULATION_TYPE == 3) then

! ------------------- new non blocking implementation -------------------

    ! outer core
  if(USE_NONBLOCKING_COMMS) then
    b_iphase = 1 ! start the non blocking communications
    call assemble_MPI_scalar(myrank,b_accel_outer_core,NGLOB_OUTER_CORE, &
            iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_outer_core,iboolright_xi_outer_core,iboolleft_eta_outer_core,iboolright_eta_outer_core, &
            npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
            iboolfaces_outer_core,iboolcorner_outer_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_scalar,b_buffer_recv_chunkcorn_scalar, &
            NUMMSGS_FACES,NCORNERSCHUNKS, &
            NPROC_XI_VAL,NPROC_ETA_VAL,NGLOB1D_RADIAL(IREGION_OUTER_CORE), &
            NGLOB2DMAX_XMIN_XMAX(IREGION_OUTER_CORE),NGLOB2DMAX_YMIN_YMAX(IREGION_OUTER_CORE), &
            NGLOB2DMAX_XY,NCHUNKS_VAL,b_iphase)

    b_icall = 2 ! now compute all the inner elements in the case of non blocking MPI

    if( USE_DEVILLE_PRODUCTS_VAL ) then
        ! uses Deville et al. (2002) routine
      call compute_forces_outer_core_Dev(time,b_deltat,b_two_omega_earth, &
           b_A_array_rotation,b_B_array_rotation,d_ln_density_dr_table, &
           minus_rho_g_over_kappa_fluid, &
           b_displ_outer_core,b_accel_outer_core,b_div_displ_outer_core, &
           xstore_outer_core,ystore_outer_core,zstore_outer_core, &
           xix_outer_core,xiy_outer_core,xiz_outer_core, &
           etax_outer_core,etay_outer_core,etaz_outer_core, &
           gammax_outer_core,gammay_outer_core,gammaz_outer_core, &
          is_on_a_slice_edge_outer_core, &
          myrank,iproc_xi,iproc_eta,ichunk,addressing, &
          iboolleft_xi_outer_core,iboolright_xi_outer_core,iboolleft_eta_outer_core,iboolright_eta_outer_core, &
          npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
          iboolfaces_outer_core,iboolcorner_outer_core, &
          iprocfrom_faces,iprocto_faces, &
          iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
          b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
          b_buffer_send_chunkcorn_scalar,b_buffer_recv_chunkcorn_scalar,b_iphase,b_icall, &
           hprime_xx,hprime_xxT,hprimewgll_xx,hprimewgll_xxT, &
           wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
           ibool_outer_core,MOVIE_VOLUME)
    else
      ! div_displ_outer_core is initialized to zero in the following subroutine.
      call compute_forces_outer_core(time,b_deltat,b_two_omega_earth, &
           b_A_array_rotation,b_B_array_rotation,d_ln_density_dr_table, &
           minus_rho_g_over_kappa_fluid, &
           b_displ_outer_core,b_accel_outer_core,b_div_displ_outer_core, &
           xstore_outer_core,ystore_outer_core,zstore_outer_core, &
           xix_outer_core,xiy_outer_core,xiz_outer_core, &
           etax_outer_core,etay_outer_core,etaz_outer_core, &
           gammax_outer_core,gammay_outer_core,gammaz_outer_core, &
          is_on_a_slice_edge_outer_core, &
          myrank,iproc_xi,iproc_eta,ichunk,addressing, &
          iboolleft_xi_outer_core,iboolright_xi_outer_core,iboolleft_eta_outer_core,iboolright_eta_outer_core, &
          npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
          iboolfaces_outer_core,iboolcorner_outer_core, &
          iprocfrom_faces,iprocto_faces, &
          iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
          b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
          b_buffer_send_chunkcorn_scalar,b_buffer_recv_chunkcorn_scalar,b_iphase,b_icall, &
           hprime_xx,hprime_yy,hprime_zz,hprimewgll_xx,hprimewgll_yy,hprimewgll_zz, &
           wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
           ibool_outer_core,MOVIE_VOLUME)
    endif

    do while (b_iphase <= 7) ! make sure the last communications are finished and processed
      call assemble_MPI_scalar(myrank,b_accel_outer_core,NGLOB_OUTER_CORE, &
            iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_outer_core,iboolright_xi_outer_core,iboolleft_eta_outer_core,iboolright_eta_outer_core, &
            npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
            iboolfaces_outer_core,iboolcorner_outer_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_scalar,b_buffer_recv_chunkcorn_scalar, &
            NUMMSGS_FACES,NCORNERSCHUNKS, &
            NPROC_XI_VAL,NPROC_ETA_VAL,NGLOB1D_RADIAL(IREGION_OUTER_CORE), &
            NGLOB2DMAX_XMIN_XMAX(IREGION_OUTER_CORE),NGLOB2DMAX_YMIN_YMAX(IREGION_OUTER_CORE), &
            NGLOB2DMAX_XY,NCHUNKS_VAL,b_iphase)
    enddo

  else ! if(.not. USE_NONBLOCKING_COMMS) then

    call assemble_MPI_scalar_block(myrank,b_accel_outer_core,NGLOB_OUTER_CORE, &
            iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_outer_core,iboolright_xi_outer_core, &
            iboolleft_eta_outer_core,iboolright_eta_outer_core, &
            npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
            iboolfaces_outer_core,iboolcorner_outer_core, &
            iprocfrom_faces,iprocto_faces,imsg_type, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_scalar,b_buffer_recv_chunkcorn_scalar, &
            NUMMSGS_FACES,NUM_MSG_TYPES,NCORNERSCHUNKS, &
            NPROC_XI_VAL,NPROC_ETA_VAL,NGLOB1D_RADIAL(IREGION_OUTER_CORE), &
            NGLOB2DMAX_XMIN_XMAX(IREGION_OUTER_CORE),NGLOB2DMAX_YMIN_YMAX(IREGION_OUTER_CORE), &
            NGLOB2DMAX_XY,NCHUNKS_VAL)

  endif

! ------------------- new non blocking implementation -------------------

! way 1:
!      do i=1,NGLOB_OUTER_CORE
!        b_accel_outer_core(i) = b_accel_outer_core(i)*rmass_outer_core(i)
!        b_veloc_outer_core(i) = b_veloc_outer_core(i) + b_deltatover2*b_accel_outer_core(i)
!      enddo

! way 2:
      do i=1,mod(NGLOB_OUTER_CORE,4)
        b_accel_outer_core(i) = b_accel_outer_core(i)*rmass_outer_core(i)
        b_veloc_outer_core(i) = b_veloc_outer_core(i) + b_deltatover2*b_accel_outer_core(i)
      enddo
      do i=mod(NGLOB_OUTER_CORE,4)+1,NGLOB_OUTER_CORE,4
        b_accel_outer_core(i) = b_accel_outer_core(i)*rmass_outer_core(i)
        b_accel_outer_core(i+1) = b_accel_outer_core(i+1)*rmass_outer_core(i+1)
        b_accel_outer_core(i+2) = b_accel_outer_core(i+2)*rmass_outer_core(i+2)
        b_accel_outer_core(i+3) = b_accel_outer_core(i+3)*rmass_outer_core(i+3)

        b_veloc_outer_core(i) = b_veloc_outer_core(i) + b_deltatover2*b_accel_outer_core(i)
        b_veloc_outer_core(i+1) = b_veloc_outer_core(i+1) + b_deltatover2*b_accel_outer_core(i+1)
        b_veloc_outer_core(i+2) = b_veloc_outer_core(i+2) + b_deltatover2*b_accel_outer_core(i+2)
        b_veloc_outer_core(i+3) = b_veloc_outer_core(i+3) + b_deltatover2*b_accel_outer_core(i+3)
      enddo

    endif

    ! ****************************************************
    !   big loop over all spectral elements in the solid
    ! ****************************************************

    ! compute internal forces in the solid regions

    ! for anisotropy and gravity, x y and z contain r theta and phi

    iphase = 0 ! do not start any non blocking communications at this stage
    iphase_CC = 0 ! do not start any non blocking communications at this stage
    icall = 1  ! compute all the outer elements first in the case of non blocking MPI

    if( USE_DEVILLE_PRODUCTS_VAL ) then
      call compute_forces_crust_mantle_Dev(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          displ_crust_mantle,accel_crust_mantle, &
          xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
          xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
          etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
          gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
!----------------------
            is_on_a_slice_edge_crust_mantle,icall, &
            accel_inner_core,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector,iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,buffer_all_cube_from_slices,buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,iphase_CC, &
!----------------------
          hprime_xx,hprime_xxT, &
          hprimewgll_xx,hprimewgll_xxT, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_crust_mantle,kappahstore_crust_mantle,muvstore_crust_mantle, &
          muhstore_crust_mantle,eta_anisostore_crust_mantle, &
          c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
          c14store_crust_mantle,c15store_crust_mantle,c16store_crust_mantle, &
          c22store_crust_mantle,c23store_crust_mantle,c24store_crust_mantle, &
          c25store_crust_mantle,c26store_crust_mantle,c33store_crust_mantle, &
          c34store_crust_mantle,c35store_crust_mantle,c36store_crust_mantle, &
          c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
          c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
          ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
      ! --idoubling_crust_mantle, &
          R_memory_crust_mantle,epsilondev_crust_mantle, &
          eps_trace_over_3_crust_mantle,one_minus_sum_beta_crust_mantle, &
          alphaval,betaval,gammaval,factor_common_crust_mantle, &
          size(factor_common_crust_mantle,2), size(factor_common_crust_mantle,3), &
          size(factor_common_crust_mantle,4), size(factor_common_crust_mantle,5) )
    else
      call compute_forces_crust_mantle(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          displ_crust_mantle,accel_crust_mantle, &
          xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
          xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
          etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
          gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
!----------------------
            is_on_a_slice_edge_crust_mantle,icall, &
            accel_inner_core,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector,iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,buffer_all_cube_from_slices,buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,iphase_CC, &
!----------------------
          hprime_xx,hprime_yy,hprime_zz, &
          hprimewgll_xx,hprimewgll_yy,hprimewgll_zz, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_crust_mantle,kappahstore_crust_mantle,muvstore_crust_mantle, &
          muhstore_crust_mantle,eta_anisostore_crust_mantle, &
          c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
          c14store_crust_mantle,c15store_crust_mantle,c16store_crust_mantle, &
          c22store_crust_mantle,c23store_crust_mantle,c24store_crust_mantle, &
          c25store_crust_mantle,c26store_crust_mantle,c33store_crust_mantle, &
          c34store_crust_mantle,c35store_crust_mantle,c36store_crust_mantle, &
          c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
          c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
          ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
        ! --idoubling_crust_mantle, &
          R_memory_crust_mantle,epsilondev_crust_mantle, &
          eps_trace_over_3_crust_mantle,one_minus_sum_beta_crust_mantle, &
          alphaval,betaval,gammaval,factor_common_crust_mantle, &
          size(factor_common_crust_mantle,2), size(factor_common_crust_mantle,3), &
          size(factor_common_crust_mantle,4), size(factor_common_crust_mantle,5) )
    endif

    if (SIMULATION_TYPE == 3 ) then

      b_iphase = 0 ! do not start any non blocking communications at this stage
      b_iphase_CC = 0 ! do not start any non blocking communications at this stage
      b_icall = 1  ! compute all the outer elements first in the case of non blocking MPI

    ! for anisotropy and gravity, x y and z contain r theta and phi
      if( USE_DEVILLE_PRODUCTS_VAL ) then
        call compute_forces_crust_mantle_Dev(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          b_displ_crust_mantle,b_accel_crust_mantle, &
          xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
          xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
          etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
          gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
!----------------------
            is_on_a_slice_edge_crust_mantle,b_icall, &
            b_accel_inner_core,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector,b_iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,b_buffer_all_cube_from_slices,b_buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,b_iphase_CC, &
!----------------------
          hprime_xx,hprime_xxT, &
          hprimewgll_xx,hprimewgll_xxT, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_crust_mantle,kappahstore_crust_mantle,muvstore_crust_mantle, &
          muhstore_crust_mantle,eta_anisostore_crust_mantle, &
          c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
          c14store_crust_mantle,c15store_crust_mantle,c16store_crust_mantle, &
          c22store_crust_mantle,c23store_crust_mantle,c24store_crust_mantle, &
          c25store_crust_mantle,c26store_crust_mantle,c33store_crust_mantle, &
          c34store_crust_mantle,c35store_crust_mantle,c36store_crust_mantle, &
          c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
          c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
          ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
     ! --     idoubling_crust_mantle, &
          b_R_memory_crust_mantle,b_epsilondev_crust_mantle, &
          b_eps_trace_over_3_crust_mantle,one_minus_sum_beta_crust_mantle, &
          b_alphaval,b_betaval,b_gammaval,factor_common_crust_mantle, &
          size(factor_common_crust_mantle,2), size(factor_common_crust_mantle,3), &
          size(factor_common_crust_mantle,4), size(factor_common_crust_mantle,5) )
      else
        call compute_forces_crust_mantle(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          b_displ_crust_mantle,b_accel_crust_mantle, &
          xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
          xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
          etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
          gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
!----------------------
            is_on_a_slice_edge_crust_mantle,b_icall, &
            b_accel_inner_core,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector,b_iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,b_buffer_all_cube_from_slices,b_buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,b_iphase_CC, &
!----------------------
          hprime_xx,hprime_yy,hprime_zz, &
          hprimewgll_xx,hprimewgll_yy,hprimewgll_zz, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_crust_mantle,kappahstore_crust_mantle,muvstore_crust_mantle, &
          muhstore_crust_mantle,eta_anisostore_crust_mantle, &
          c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
          c14store_crust_mantle,c15store_crust_mantle,c16store_crust_mantle, &
          c22store_crust_mantle,c23store_crust_mantle,c24store_crust_mantle, &
          c25store_crust_mantle,c26store_crust_mantle,c33store_crust_mantle, &
          c34store_crust_mantle,c35store_crust_mantle,c36store_crust_mantle, &
          c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
          c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
          ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
      ! --idoubling_crust_mantle, &
          b_R_memory_crust_mantle,b_epsilondev_crust_mantle, &
          b_eps_trace_over_3_crust_mantle,one_minus_sum_beta_crust_mantle, &
          b_alphaval,b_betaval,b_gammaval,factor_common_crust_mantle, &
          size(factor_common_crust_mantle,2), size(factor_common_crust_mantle,3), &
          size(factor_common_crust_mantle,4), size(factor_common_crust_mantle,5) )

      endif
    endif

    ! Deville routine
    if( USE_DEVILLE_PRODUCTS_VAL ) then
      call compute_forces_inner_core_Dev(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          displ_inner_core,accel_inner_core, &
          xstore_inner_core,ystore_inner_core,zstore_inner_core, &
          xix_inner_core,xiy_inner_core,xiz_inner_core, &
          etax_inner_core,etay_inner_core,etaz_inner_core, &
          gammax_inner_core,gammay_inner_core,gammaz_inner_core, &
!----------------------
            is_on_a_slice_edge_inner_core,icall, &
            accel_crust_mantle,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector,iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,buffer_all_cube_from_slices,buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,iphase_CC, &
!----------------------
          hprime_xx,hprime_xxT,hprimewgll_xx,hprimewgll_xxT, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_inner_core,muvstore_inner_core,ibool_inner_core,idoubling_inner_core, &
          c11store_inner_core,c33store_inner_core,c12store_inner_core, &
          c13store_inner_core,c44store_inner_core, &
          R_memory_inner_core,epsilondev_inner_core, eps_trace_over_3_inner_core,&
          one_minus_sum_beta_inner_core, &
          alphaval,betaval,gammaval, &
          factor_common_inner_core, &
          size(factor_common_inner_core,2), size(factor_common_inner_core,3), &
          size(factor_common_inner_core,4), size(factor_common_inner_core,5) )
    else
      call compute_forces_inner_core(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          displ_inner_core,accel_inner_core, &
          xstore_inner_core,ystore_inner_core,zstore_inner_core, &
          xix_inner_core,xiy_inner_core,xiz_inner_core, &
          etax_inner_core,etay_inner_core,etaz_inner_core, &
          gammax_inner_core,gammay_inner_core,gammaz_inner_core, &
!----------------------
            is_on_a_slice_edge_inner_core,icall, &
            accel_crust_mantle,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector,iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,buffer_all_cube_from_slices,buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,iphase_CC, &
!----------------------
          hprime_xx,hprime_yy,hprime_zz,hprimewgll_xx,hprimewgll_yy,hprimewgll_zz, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_inner_core,muvstore_inner_core,ibool_inner_core,idoubling_inner_core, &
          c11store_inner_core,c33store_inner_core,c12store_inner_core, &
          c13store_inner_core,c44store_inner_core, &
          R_memory_inner_core,epsilondev_inner_core, eps_trace_over_3_inner_core,&
          one_minus_sum_beta_inner_core, &
          alphaval,betaval,gammaval, &
          factor_common_inner_core, &
          size(factor_common_inner_core,2), size(factor_common_inner_core,3), &
          size(factor_common_inner_core,4), size(factor_common_inner_core,5) )
    endif

    if (SIMULATION_TYPE == 3) then
      if( USE_DEVILLE_PRODUCTS_VAL ) then
        call compute_forces_inner_core_Dev(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          b_displ_inner_core,b_accel_inner_core, &
          xstore_inner_core,ystore_inner_core,zstore_inner_core, &
          xix_inner_core,xiy_inner_core,xiz_inner_core, &
          etax_inner_core,etay_inner_core,etaz_inner_core, &
          gammax_inner_core,gammay_inner_core,gammaz_inner_core, &
!----------------------
            is_on_a_slice_edge_inner_core,b_icall, &
            b_accel_crust_mantle,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector,b_iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,b_buffer_all_cube_from_slices,b_buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,b_iphase_CC, &
!----------------------
          hprime_xx,hprime_xxT,hprimewgll_xx,hprimewgll_xxT, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_inner_core,muvstore_inner_core,ibool_inner_core,idoubling_inner_core, &
          c11store_inner_core,c33store_inner_core,c12store_inner_core, &
          c13store_inner_core,c44store_inner_core, &
          b_R_memory_inner_core,b_epsilondev_inner_core, b_eps_trace_over_3_inner_core,&
          one_minus_sum_beta_inner_core, &
          b_alphaval,b_betaval,b_gammaval, &
          factor_common_inner_core, &
          size(factor_common_inner_core,2), size(factor_common_inner_core,3), &
          size(factor_common_inner_core,4), size(factor_common_inner_core,5) )
      else
        call compute_forces_inner_core(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          b_displ_inner_core,b_accel_inner_core, &
          xstore_inner_core,ystore_inner_core,zstore_inner_core, &
          xix_inner_core,xiy_inner_core,xiz_inner_core, &
          etax_inner_core,etay_inner_core,etaz_inner_core, &
          gammax_inner_core,gammay_inner_core,gammaz_inner_core, &
!----------------------
            is_on_a_slice_edge_inner_core,b_icall, &
            b_accel_crust_mantle,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector,b_iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,b_buffer_all_cube_from_slices,b_buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,b_iphase_CC, &
!----------------------
          hprime_xx,hprime_yy,hprime_zz,hprimewgll_xx,hprimewgll_yy,hprimewgll_zz, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_inner_core,muvstore_inner_core,ibool_inner_core,idoubling_inner_core, &
          c11store_inner_core,c33store_inner_core,c12store_inner_core, &
          c13store_inner_core,c44store_inner_core, &
          b_R_memory_inner_core,b_epsilondev_inner_core, b_eps_trace_over_3_inner_core,&
          one_minus_sum_beta_inner_core, &
          b_alphaval,b_betaval,b_gammaval, &
          factor_common_inner_core, &
          size(factor_common_inner_core,2), size(factor_common_inner_core,3), &
          size(factor_common_inner_core,4), size(factor_common_inner_core,5) )
      endif
    endif

    ! Stacey
    if(NCHUNKS_VAL /= 6 .and. ABSORBING_CONDITIONS) then
      call compute_stacey_crust_mantle(ichunk,SIMULATION_TYPE, &
                              NSTEP,it,SAVE_FORWARD,ibool_crust_mantle, &
                              veloc_crust_mantle,accel_crust_mantle,b_accel_crust_mantle, &
                              jacobian2D_xmin_crust_mantle,jacobian2D_xmax_crust_mantle, &
                              jacobian2D_ymin_crust_mantle,jacobian2D_ymax_crust_mantle, &
                              wgllwgll_xz,wgllwgll_yz, &
                              normal_xmin_crust_mantle,normal_xmax_crust_mantle, &
                              normal_ymin_crust_mantle,normal_ymax_crust_mantle, &
                              rho_vp_crust_mantle,rho_vs_crust_mantle, &
                              ibelm_xmin_crust_mantle,ibelm_xmax_crust_mantle, &
                              ibelm_ymin_crust_mantle,ibelm_ymax_crust_mantle, &
                              nimin_crust_mantle,nimax_crust_mantle, &
                              njmin_crust_mantle,njmax_crust_mantle, &
                              nkmin_xi_crust_mantle,nkmin_eta_crust_mantle, &
                              nspec2D_xmin_crust_mantle,nspec2D_xmax_crust_mantle, &
                              nspec2D_ymin_crust_mantle,nspec2D_ymax_crust_mantle, &
                              reclen_xmin_crust_mantle,reclen_xmax_crust_mantle, &
                              reclen_ymin_crust_mantle,reclen_ymax_crust_mantle, &
                              nabs_xmin_cm,nabs_xmax_cm,nabs_ymin_cm,nabs_ymax_cm, &
                              absorb_xmin_crust_mantle5,absorb_xmax_crust_mantle5, &
                              absorb_ymin_crust_mantle5,absorb_ymax_crust_mantle5)
    endif ! Stacey conditions

    ! add the sources
    if (SIMULATION_TYPE == 1) &
      call compute_add_sources(myrank,NSOURCES, &
                                accel_crust_mantle,sourcearrays, &
                                DT,t0,tshift_cmt,hdur_gaussian,ibool_crust_mantle, &
                                islice_selected_source,ispec_selected_source,it, &
                                hdur,xi_source,eta_source,gamma_source,nu_source)

    ! add adjoint sources
    if (SIMULATION_TYPE == 2 .or. SIMULATION_TYPE == 3) then
      if( nadj_rec_local > 0 ) &
        call compute_add_sources_adjoint(myrank,nrec, &
                                nadj_rec_local,NSTEP,NTSTEP_BETWEEN_READ_ADJSRC, &
                                accel_crust_mantle,adj_sourcearrays, &
                                nu,xi_receiver,eta_receiver,gamma_receiver, &
                                xigll,yigll,zigll,ibool_crust_mantle, &
                                islice_selected_rec,ispec_selected_rec, &
                                NSTEP_SUB_ADJ,iadjsrc_len,iadjsrc,iadj_vec, &
                                it,it_begin,station_name,network_name,DT)
    endif

    ! add sources for backward/reconstructed wavefield
    if (SIMULATION_TYPE == 3) &
      call compute_add_sources_backward(myrank,NSOURCES,NSTEP, &
                                b_accel_crust_mantle,sourcearrays, &
                                DT,t0,tshift_cmt,hdur_gaussian,ibool_crust_mantle, &
                                islice_selected_source,ispec_selected_source,it, &
                                hdur,xi_source,eta_source,gamma_source,nu_source)

!<YANGL
    ! NOISE_TOMOGRAPHY
    if ( NOISE_TOMOGRAPHY == 1 ) then
       ! the first step of noise tomography is to use |S(\omega)|^2 as a point force source at one of the receivers.
       ! hence, instead of a moment tensor 'sourcearrays', a 'noise_sourcearray' for a point force is needed.
       ! furthermore, the CMTSOLUTION needs to be zero, i.e., no earthquakes.
       ! now this must be manually set in DATA/CMTSOLUTION, by USERS.
       call add_source_master_rec_noise(myrank,nrec, &
                                NSTEP,accel_crust_mantle,noise_sourcearray, &
                                ibool_crust_mantle,islice_selected_rec,ispec_selected_rec, &
                                it,irec_master_noise)
    elseif ( NOISE_TOMOGRAPHY == 2 ) then
       ! second step of noise tomography, i.e., read the surface movie saved at every timestep
       ! use the movie to drive the ensemble forward wavefield
       call noise_read_add_surface_movie(nmovie_points,accel_crust_mantle, &
                              normal_x_noise,normal_y_noise,normal_z_noise,mask_noise, &
                              ibelm_top_crust_mantle,ibool_crust_mantle, &
                              NSPEC2D_TOP(IREGION_CRUST_MANTLE),noise_surface_movie, &
                              NSTEP-it+1,jacobian2D_top_crust_mantle,wgllwgll_xy)
        ! be careful, since ensemble forward sources are reversals of generating wavefield "eta"
        ! hence the "NSTEP-it+1", i.e., start reading from the last timestep
        ! note the ensemble forward sources are generally distributed on the surface of the earth
        ! that's to say, the ensemble forward source is kind of a surface force density, not a body force density
        ! therefore, we must add it here, before applying the inverse of mass matrix
    elseif ( NOISE_TOMOGRAPHY == 3 ) then
        ! third step of noise tomography, i.e., read the surface movie saved at every timestep
        ! use the movie to reconstruct the ensemble forward wavefield
        ! the ensemble adjoint wavefield is done as usual
        ! note instead of "NSTEP-it+1", now we us "it", since reconstruction is a reversal of reversal
        call noise_read_add_surface_movie(nmovie_points,b_accel_crust_mantle, &
                              normal_x_noise,normal_y_noise,normal_z_noise,mask_noise, &
                              ibelm_top_crust_mantle,ibool_crust_mantle, &
                              NSPEC2D_TOP(IREGION_CRUST_MANTLE),noise_surface_movie, &
                              it,jacobian2D_top_crust_mantle,wgllwgll_xy)
    endif
!>YANGL

    ! ****************************************************
    ! **********  add matching with fluid part  **********
    ! ****************************************************

    ! only for elements in first matching layer in the solid

    !---
    !--- couple with outer core at the bottom of the mantle
    !---
    if(ACTUALLY_COUPLE_FLUID_CMB) &
      call compute_coupling_CMB_fluid(displ_crust_mantle,b_displ_crust_mantle, &
                            accel_crust_mantle,b_accel_crust_mantle, &
                            ibool_crust_mantle,ibelm_bottom_crust_mantle,  &
                            accel_outer_core,b_accel_outer_core, &
                            normal_top_outer_core,jacobian2D_top_outer_core, &
                            wgllwgll_xy,ibool_outer_core,ibelm_top_outer_core, &
                            RHO_TOP_OC,minus_g_cmb, &
                            SIMULATION_TYPE,NSPEC2D_BOTTOM(IREGION_CRUST_MANTLE))

    !---
    !--- couple with outer core at the top of the inner core
    !---
    if(ACTUALLY_COUPLE_FLUID_ICB) &
      call compute_coupling_ICB_fluid(displ_inner_core,b_displ_inner_core, &
                            accel_inner_core,b_accel_inner_core, &
                            ibool_inner_core,ibelm_top_inner_core,  &
                            accel_outer_core,b_accel_outer_core, &
                            normal_bottom_outer_core,jacobian2D_bottom_outer_core, &
                            wgllwgll_xy,ibool_outer_core,ibelm_bottom_outer_core, &
                            RHO_BOTTOM_OC,minus_g_icb, &
                            SIMULATION_TYPE,NSPEC2D_TOP(IREGION_INNER_CORE))


    ! assemble all the contributions between slices using MPI

! assemble all the contributions between slices using MPI
! crust/mantle and inner core handled in the same call
! in order to reduce the number of MPI messages by 2
  if(USE_NONBLOCKING_COMMS) then

    iphase = 1 ! initialize the non blocking communication counter
    iphase_CC = 1 ! initialize the non blocking communication counter for the central cube

! start the non blocking communications
    call assemble_MPI_vector(myrank,accel_crust_mantle,accel_inner_core, &
            iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector, &
            NUMMSGS_FACES,NCORNERSCHUNKS, &
            NPROC_XI_VAL,NPROC_ETA_VAL,NGLOB1D_RADIAL(IREGION_CRUST_MANTLE), &
            NGLOB1D_RADIAL(IREGION_INNER_CORE),NCHUNKS_VAL,iphase)

    icall = 2 ! now compute all the inner elements in the case of non blocking MPI

    ! compute internal forces in the solid regions

    ! for anisotropy and gravity, x y and z contain r theta and phi

    if( USE_DEVILLE_PRODUCTS_VAL ) then
      call compute_forces_crust_mantle_Dev(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          displ_crust_mantle,accel_crust_mantle, &
          xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
          xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
          etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
          gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
!----------------------
            is_on_a_slice_edge_crust_mantle,icall, &
            accel_inner_core,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector,iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,buffer_all_cube_from_slices,buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,iphase_CC, &
!----------------------
          hprime_xx,hprime_xxT, &
          hprimewgll_xx,hprimewgll_xxT, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_crust_mantle,kappahstore_crust_mantle,muvstore_crust_mantle, &
          muhstore_crust_mantle,eta_anisostore_crust_mantle, &
          c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
          c14store_crust_mantle,c15store_crust_mantle,c16store_crust_mantle, &
          c22store_crust_mantle,c23store_crust_mantle,c24store_crust_mantle, &
          c25store_crust_mantle,c26store_crust_mantle,c33store_crust_mantle, &
          c34store_crust_mantle,c35store_crust_mantle,c36store_crust_mantle, &
          c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
          c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
          ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
      !---idoubling_crust_mantle, &
          R_memory_crust_mantle,epsilondev_crust_mantle, &
          eps_trace_over_3_crust_mantle,one_minus_sum_beta_crust_mantle, &
          alphaval,betaval,gammaval,factor_common_crust_mantle, &
          size(factor_common_crust_mantle,2), size(factor_common_crust_mantle,3), &
          size(factor_common_crust_mantle,4), size(factor_common_crust_mantle,5) )
    else
      call compute_forces_crust_mantle(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          displ_crust_mantle,accel_crust_mantle, &
          xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
          xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
          etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
          gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
!----------------------
            is_on_a_slice_edge_crust_mantle,icall, &
            accel_inner_core,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector,iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,buffer_all_cube_from_slices,buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,iphase_CC, &
!----------------------
          hprime_xx,hprime_yy,hprime_zz, &
          hprimewgll_xx,hprimewgll_yy,hprimewgll_zz, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_crust_mantle,kappahstore_crust_mantle,muvstore_crust_mantle, &
          muhstore_crust_mantle,eta_anisostore_crust_mantle, &
          c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
          c14store_crust_mantle,c15store_crust_mantle,c16store_crust_mantle, &
          c22store_crust_mantle,c23store_crust_mantle,c24store_crust_mantle, &
          c25store_crust_mantle,c26store_crust_mantle,c33store_crust_mantle, &
          c34store_crust_mantle,c35store_crust_mantle,c36store_crust_mantle, &
          c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
          c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
          ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
      ! --idoubling_crust_mantle, &
          R_memory_crust_mantle,epsilondev_crust_mantle, &
          eps_trace_over_3_crust_mantle,one_minus_sum_beta_crust_mantle, &
          alphaval,betaval,gammaval,factor_common_crust_mantle, &
          size(factor_common_crust_mantle,2), size(factor_common_crust_mantle,3), &
          size(factor_common_crust_mantle,4), size(factor_common_crust_mantle,5) )
    endif

    ! Deville routine
    if( USE_DEVILLE_PRODUCTS_VAL ) then
      call compute_forces_inner_core_Dev(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          displ_inner_core,accel_inner_core, &
          xstore_inner_core,ystore_inner_core,zstore_inner_core, &
          xix_inner_core,xiy_inner_core,xiz_inner_core, &
          etax_inner_core,etay_inner_core,etaz_inner_core, &
          gammax_inner_core,gammay_inner_core,gammaz_inner_core, &
!----------------------
            is_on_a_slice_edge_inner_core,icall, &
            accel_crust_mantle,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector,iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,buffer_all_cube_from_slices,buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,iphase_CC, &
!----------------------
          hprime_xx,hprime_xxT,hprimewgll_xx,hprimewgll_xxT, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_inner_core,muvstore_inner_core,ibool_inner_core,idoubling_inner_core, &
          c11store_inner_core,c33store_inner_core,c12store_inner_core, &
          c13store_inner_core,c44store_inner_core, &
          R_memory_inner_core,epsilondev_inner_core, eps_trace_over_3_inner_core,&
          one_minus_sum_beta_inner_core, &
          alphaval,betaval,gammaval, &
          factor_common_inner_core, &
          size(factor_common_inner_core,2), size(factor_common_inner_core,3), &
          size(factor_common_inner_core,4), size(factor_common_inner_core,5) )
    else
      call compute_forces_inner_core(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          displ_inner_core,accel_inner_core, &
          xstore_inner_core,ystore_inner_core,zstore_inner_core, &
          xix_inner_core,xiy_inner_core,xiz_inner_core, &
          etax_inner_core,etay_inner_core,etaz_inner_core, &
          gammax_inner_core,gammay_inner_core,gammaz_inner_core, &
!----------------------
            is_on_a_slice_edge_inner_core,icall, &
            accel_crust_mantle,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector,iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,buffer_all_cube_from_slices,buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,iphase_CC, &
!----------------------
          hprime_xx,hprime_yy,hprime_zz,hprimewgll_xx,hprimewgll_yy,hprimewgll_zz, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_inner_core,muvstore_inner_core,ibool_inner_core,idoubling_inner_core, &
          c11store_inner_core,c33store_inner_core,c12store_inner_core, &
          c13store_inner_core,c44store_inner_core, &
          R_memory_inner_core,epsilondev_inner_core, eps_trace_over_3_inner_core,&
          one_minus_sum_beta_inner_core, &
          alphaval,betaval,gammaval, &
          factor_common_inner_core, &
          size(factor_common_inner_core,2), size(factor_common_inner_core,3), &
          size(factor_common_inner_core,4), size(factor_common_inner_core,5) )
    endif

! assemble all the contributions between slices using MPI
! crust/mantle and inner core handled in the same call
! in order to reduce the number of MPI messages by 2
    do while (iphase <= 7) ! make sure the last communications are finished and processed
      call assemble_MPI_vector(myrank,accel_crust_mantle,accel_inner_core, &
            iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces,npoin2D_max_all_CM_IC, &
            buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector, &
            NUMMSGS_FACES,NCORNERSCHUNKS, &
            NPROC_XI_VAL,NPROC_ETA_VAL,NGLOB1D_RADIAL(IREGION_CRUST_MANTLE), &
            NGLOB1D_RADIAL(IREGION_INNER_CORE),NCHUNKS_VAL,iphase)
    enddo
  else
    ! crust/mantle and inner core handled in the same call
    ! in order to reduce the number of MPI messages by 2
    call assemble_MPI_vector_block(myrank, &
            accel_crust_mantle,NGLOB_CRUST_MANTLE, &
            accel_inner_core,NGLOB_INNER_CORE, &
            iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle, &
            iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core, &
            iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces,imsg_type, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            buffer_send_faces,buffer_received_faces, &
            buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector, &
            NUMMSGS_FACES,NUM_MSG_TYPES,NCORNERSCHUNKS, &
            NPROC_XI_VAL,NPROC_ETA_VAL, &
            NGLOB1D_RADIAL(IREGION_CRUST_MANTLE), &
            NGLOB2DMAX_XMIN_XMAX(IREGION_CRUST_MANTLE),NGLOB2DMAX_YMIN_YMAX(IREGION_CRUST_MANTLE), &
            NGLOB1D_RADIAL(IREGION_INNER_CORE), &
            NGLOB2DMAX_XMIN_XMAX(IREGION_INNER_CORE),NGLOB2DMAX_YMIN_YMAX(IREGION_INNER_CORE), &
            NGLOB2DMAX_XY,NCHUNKS_VAL)
  endif

    !---
    !---  use buffers to assemble forces with the central cube
    !---

  if(INCLUDE_CENTRAL_CUBE) then
    if(USE_NONBLOCKING_COMMS) then
      do while (iphase_CC <= 4) ! make sure the last communications are finished and processed
        call assemble_MPI_central_cube(ichunk,nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
          npoin2D_cube_from_slices,buffer_all_cube_from_slices,buffer_slices,ibool_central_cube, &
          receiver_cube_from_slices,ibool_inner_core,idoubling_inner_core, &
          ibelm_bottom_inner_core,NSPEC2D_BOTTOM(IREGION_INNER_CORE),accel_inner_core,NDIM,iphase_CC)
      enddo
    else
      call assemble_MPI_central_cube_block(ichunk,nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
        npoin2D_cube_from_slices,buffer_all_cube_from_slices,buffer_slices,buffer_slices2,ibool_central_cube, &
        receiver_cube_from_slices,ibool_inner_core,idoubling_inner_core,NSPEC_INNER_CORE, &
        ibelm_bottom_inner_core,NSPEC2D_BOTTOM(IREGION_INNER_CORE),NGLOB_INNER_CORE,accel_inner_core,NDIM)
    endif
  endif   ! end of assembling forces with the central cube

! way 1:
!    do i=1,NGLOB_CRUST_MANTLE
!      accel_crust_mantle(1,i) = accel_crust_mantle(1,i)*rmass_crust_mantle(i) &
!               + two_omega_earth*veloc_crust_mantle(2,i)
!      accel_crust_mantle(2,i) = accel_crust_mantle(2,i)*rmass_crust_mantle(i) &
!               - two_omega_earth*veloc_crust_mantle(1,i)
!      accel_crust_mantle(3,i) = accel_crust_mantle(3,i)*rmass_crust_mantle(i)
!    enddo

! way 2:
    do i=1,mod(NGLOB_CRUST_MANTLE,4)
      accel_crust_mantle(1,i) = accel_crust_mantle(1,i)*rmass_crust_mantle(i) &
               + two_omega_earth*veloc_crust_mantle(2,i)
      accel_crust_mantle(2,i) = accel_crust_mantle(2,i)*rmass_crust_mantle(i) &
               - two_omega_earth*veloc_crust_mantle(1,i)
      accel_crust_mantle(3,i) = accel_crust_mantle(3,i)*rmass_crust_mantle(i)
    enddo
    do i=mod(NGLOB_CRUST_MANTLE,4)+1,NGLOB_CRUST_MANTLE,4
      accel_crust_mantle(1,i) = accel_crust_mantle(1,i)*rmass_crust_mantle(i) &
               + two_omega_earth*veloc_crust_mantle(2,i)
      accel_crust_mantle(2,i) = accel_crust_mantle(2,i)*rmass_crust_mantle(i) &
               - two_omega_earth*veloc_crust_mantle(1,i)
      accel_crust_mantle(3,i) = accel_crust_mantle(3,i)*rmass_crust_mantle(i)

      accel_crust_mantle(1,i+1) = accel_crust_mantle(1,i+1)*rmass_crust_mantle(i+1) &
               + two_omega_earth*veloc_crust_mantle(2,i+1)
      accel_crust_mantle(2,i+1) = accel_crust_mantle(2,i+1)*rmass_crust_mantle(i+1) &
               - two_omega_earth*veloc_crust_mantle(1,i+1)
      accel_crust_mantle(3,i+1) = accel_crust_mantle(3,i+1)*rmass_crust_mantle(i+1)

      accel_crust_mantle(1,i+2) = accel_crust_mantle(1,i+2)*rmass_crust_mantle(i+2) &
               + two_omega_earth*veloc_crust_mantle(2,i+2)
      accel_crust_mantle(2,i+2) = accel_crust_mantle(2,i+2)*rmass_crust_mantle(i+2) &
               - two_omega_earth*veloc_crust_mantle(1,i+2)
      accel_crust_mantle(3,i+2) = accel_crust_mantle(3,i+2)*rmass_crust_mantle(i+2)

      accel_crust_mantle(1,i+3) = accel_crust_mantle(1,i+3)*rmass_crust_mantle(i+3) &
               + two_omega_earth*veloc_crust_mantle(2,i+3)
      accel_crust_mantle(2,i+3) = accel_crust_mantle(2,i+3)*rmass_crust_mantle(i+3) &
               - two_omega_earth*veloc_crust_mantle(1,i+3)
      accel_crust_mantle(3,i+3) = accel_crust_mantle(3,i+3)*rmass_crust_mantle(i+3)
    enddo

    if (SIMULATION_TYPE == 3) then

! ------------------- new non blocking implementation -------------------

    ! assemble all the contributions between slices using MPI

! assemble all the contributions between slices using MPI
! crust/mantle and inner core handled in the same call
! in order to reduce the number of MPI messages by 2
  if(USE_NONBLOCKING_COMMS) then

    b_iphase = 1 ! initialize the non blocking communication counter
    b_iphase_CC = 1 ! initialize the non blocking communication counter for the central cube

! start the non blocking communications
    call assemble_MPI_vector(myrank,b_accel_crust_mantle,b_accel_inner_core, &
            iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector, &
            NUMMSGS_FACES,NCORNERSCHUNKS, &
            NPROC_XI_VAL,NPROC_ETA_VAL,NGLOB1D_RADIAL(IREGION_CRUST_MANTLE), &
            NGLOB1D_RADIAL(IREGION_INNER_CORE),NCHUNKS_VAL,b_iphase)

    b_icall = 2 ! now compute all the inner elements in the case of non blocking MPI

    ! compute internal forces in the solid regions

    ! for anisotropy and gravity, x y and z contain r theta and phi

    if( USE_DEVILLE_PRODUCTS_VAL ) then
      call compute_forces_crust_mantle_Dev(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          b_displ_crust_mantle,b_accel_crust_mantle, &
          xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
          xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
          etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
          gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
!----------------------
            is_on_a_slice_edge_crust_mantle,b_icall, &
            b_accel_inner_core,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector,b_iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,b_buffer_all_cube_from_slices,b_buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,b_iphase_CC, &
!----------------------
          hprime_xx,hprime_xxT, &
          hprimewgll_xx,hprimewgll_xxT, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_crust_mantle,kappahstore_crust_mantle,muvstore_crust_mantle, &
          muhstore_crust_mantle,eta_anisostore_crust_mantle, &
          c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
          c14store_crust_mantle,c15store_crust_mantle,c16store_crust_mantle, &
          c22store_crust_mantle,c23store_crust_mantle,c24store_crust_mantle, &
          c25store_crust_mantle,c26store_crust_mantle,c33store_crust_mantle, &
          c34store_crust_mantle,c35store_crust_mantle,c36store_crust_mantle, &
          c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
          c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
          ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
      ! --idoubling_crust_mantle, &
          b_R_memory_crust_mantle,b_epsilondev_crust_mantle, &
          b_eps_trace_over_3_crust_mantle,one_minus_sum_beta_crust_mantle, &
          b_alphaval,b_betaval,b_gammaval,factor_common_crust_mantle, &
          size(factor_common_crust_mantle,2), size(factor_common_crust_mantle,3), &
          size(factor_common_crust_mantle,4), size(factor_common_crust_mantle,5) )
    else
      call compute_forces_crust_mantle(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          b_displ_crust_mantle,b_accel_crust_mantle, &
          xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
          xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
          etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
          gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
!----------------------
            is_on_a_slice_edge_crust_mantle,b_icall, &
            b_accel_inner_core,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector,b_iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,b_buffer_all_cube_from_slices,b_buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,b_iphase_CC, &
!----------------------
          hprime_xx,hprime_yy,hprime_zz, &
          hprimewgll_xx,hprimewgll_yy,hprimewgll_zz, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_crust_mantle,kappahstore_crust_mantle,muvstore_crust_mantle, &
          muhstore_crust_mantle,eta_anisostore_crust_mantle, &
          c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
          c14store_crust_mantle,c15store_crust_mantle,c16store_crust_mantle, &
          c22store_crust_mantle,c23store_crust_mantle,c24store_crust_mantle, &
          c25store_crust_mantle,c26store_crust_mantle,c33store_crust_mantle, &
          c34store_crust_mantle,c35store_crust_mantle,c36store_crust_mantle, &
          c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
          c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
          ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
      !--idoubling_crust_mantle, &
          b_R_memory_crust_mantle,b_epsilondev_crust_mantle, &
          b_eps_trace_over_3_crust_mantle,one_minus_sum_beta_crust_mantle, &
          b_alphaval,b_betaval,b_gammaval,factor_common_crust_mantle, &
          size(factor_common_crust_mantle,2), size(factor_common_crust_mantle,3), &
          size(factor_common_crust_mantle,4), size(factor_common_crust_mantle,5) )
    endif

    ! Deville routine
    if( USE_DEVILLE_PRODUCTS_VAL ) then
      call compute_forces_inner_core_Dev(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          b_displ_inner_core,b_accel_inner_core, &
          xstore_inner_core,ystore_inner_core,zstore_inner_core, &
          xix_inner_core,xiy_inner_core,xiz_inner_core, &
          etax_inner_core,etay_inner_core,etaz_inner_core, &
          gammax_inner_core,gammay_inner_core,gammaz_inner_core, &
!----------------------
            is_on_a_slice_edge_inner_core,b_icall, &
            b_accel_crust_mantle,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector,b_iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,b_buffer_all_cube_from_slices,b_buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,b_iphase_CC, &
!----------------------
          hprime_xx,hprime_xxT,hprimewgll_xx,hprimewgll_xxT, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_inner_core,muvstore_inner_core,ibool_inner_core,idoubling_inner_core, &
          c11store_inner_core,c33store_inner_core,c12store_inner_core, &
          c13store_inner_core,c44store_inner_core, &
          b_R_memory_inner_core,b_epsilondev_inner_core, b_eps_trace_over_3_inner_core,&
          one_minus_sum_beta_inner_core, &
          b_alphaval,b_betaval,b_gammaval, &
          factor_common_inner_core, &
          size(factor_common_inner_core,2), size(factor_common_inner_core,3), &
          size(factor_common_inner_core,4), size(factor_common_inner_core,5) )
    else
      call compute_forces_inner_core(minus_gravity_table,density_table,minus_deriv_gravity_table, &
          b_displ_inner_core,b_accel_inner_core, &
          xstore_inner_core,ystore_inner_core,zstore_inner_core, &
          xix_inner_core,xiy_inner_core,xiz_inner_core, &
          etax_inner_core,etay_inner_core,etaz_inner_core, &
          gammax_inner_core,gammay_inner_core,gammaz_inner_core, &
!----------------------
            is_on_a_slice_edge_inner_core,b_icall, &
            b_accel_crust_mantle,ibool_inner_core,idoubling_inner_core, &
            myrank,iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector,b_iphase, &
            nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
            npoin2D_cube_from_slices,b_buffer_all_cube_from_slices,b_buffer_slices,ibool_central_cube, &
            receiver_cube_from_slices,ibelm_bottom_inner_core,NSPEC2D_BOTTOM_IC,INCLUDE_CENTRAL_CUBE,b_iphase_CC, &
!----------------------
          hprime_xx,hprime_yy,hprime_zz,hprimewgll_xx,hprimewgll_yy,hprimewgll_zz, &
          wgllwgll_xy,wgllwgll_xz,wgllwgll_yz,wgll_cube, &
          kappavstore_inner_core,muvstore_inner_core,ibool_inner_core,idoubling_inner_core, &
          c11store_inner_core,c33store_inner_core,c12store_inner_core, &
          c13store_inner_core,c44store_inner_core, &
          b_R_memory_inner_core,b_epsilondev_inner_core, b_eps_trace_over_3_inner_core,&
          one_minus_sum_beta_inner_core, &
          b_alphaval,b_betaval,b_gammaval, &
          factor_common_inner_core, &
          size(factor_common_inner_core,2), size(factor_common_inner_core,3), &
          size(factor_common_inner_core,4), size(factor_common_inner_core,5) )
    endif

! assemble all the contributions between slices using MPI
! crust/mantle and inner core handled in the same call
! in order to reduce the number of MPI messages by 2
    do while (b_iphase <= 7) ! make sure the last communications are finished and processed
      call assemble_MPI_vector(myrank,b_accel_crust_mantle,b_accel_inner_core, &
            iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle,iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core,iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces,npoin2D_max_all_CM_IC, &
            b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector, &
            NUMMSGS_FACES,NCORNERSCHUNKS, &
            NPROC_XI_VAL,NPROC_ETA_VAL,NGLOB1D_RADIAL(IREGION_CRUST_MANTLE), &
            NGLOB1D_RADIAL(IREGION_INNER_CORE),NCHUNKS_VAL,b_iphase)
    enddo
  else
    ! crust/mantle and inner core handled in the same call
    ! in order to reduce the number of MPI messages by 2
    call assemble_MPI_vector_block(myrank, &
            b_accel_crust_mantle,NGLOB_CRUST_MANTLE, &
            b_accel_inner_core,NGLOB_INNER_CORE, &
            iproc_xi,iproc_eta,ichunk,addressing, &
            iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle, &
            iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
            npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
            iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
            iboolleft_xi_inner_core,iboolright_xi_inner_core, &
            iboolleft_eta_inner_core,iboolright_eta_inner_core, &
            npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
            iboolfaces_inner_core,iboolcorner_inner_core, &
            iprocfrom_faces,iprocto_faces,imsg_type, &
            iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
            b_buffer_send_faces,b_buffer_received_faces, &
            b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector, &
            NUMMSGS_FACES,NUM_MSG_TYPES,NCORNERSCHUNKS, &
            NPROC_XI_VAL,NPROC_ETA_VAL, &
            NGLOB1D_RADIAL(IREGION_CRUST_MANTLE), &
            NGLOB2DMAX_XMIN_XMAX(IREGION_CRUST_MANTLE),NGLOB2DMAX_YMIN_YMAX(IREGION_CRUST_MANTLE), &
            NGLOB1D_RADIAL(IREGION_INNER_CORE), &
            NGLOB2DMAX_XMIN_XMAX(IREGION_INNER_CORE),NGLOB2DMAX_YMIN_YMAX(IREGION_INNER_CORE), &
            NGLOB2DMAX_XY,NCHUNKS_VAL)
  endif

    !---
    !---  use buffers to assemble forces with the central cube
    !---

  if(INCLUDE_CENTRAL_CUBE) then
    if(USE_NONBLOCKING_COMMS) then
      do while (b_iphase_CC <= 4) ! make sure the last communications are finished and processed
        call assemble_MPI_central_cube(ichunk,nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
          npoin2D_cube_from_slices,b_buffer_all_cube_from_slices,b_buffer_slices,ibool_central_cube, &
          receiver_cube_from_slices,ibool_inner_core,idoubling_inner_core, &
          ibelm_bottom_inner_core,NSPEC2D_BOTTOM(IREGION_INNER_CORE),b_accel_inner_core,NDIM,b_iphase_CC)
      enddo
    else
      call assemble_MPI_central_cube_block(ichunk,nb_msgs_theor_in_cube,sender_from_slices_to_cube, &
        npoin2D_cube_from_slices,b_buffer_all_cube_from_slices,b_buffer_slices,buffer_slices2,ibool_central_cube, &
        receiver_cube_from_slices,ibool_inner_core,idoubling_inner_core,NSPEC_INNER_CORE, &
        ibelm_bottom_inner_core,NSPEC2D_BOTTOM(IREGION_INNER_CORE),NGLOB_INNER_CORE,b_accel_inner_core,NDIM)
    endif
  endif   ! end of assembling forces with the central cube

! ------------------- new non blocking implementation -------------------

! way 1:
!      do i=1,NGLOB_CRUST_MANTLE
!        b_accel_crust_mantle(1,i) = b_accel_crust_mantle(1,i)*rmass_crust_mantle(i) &
!                 + b_two_omega_earth*b_veloc_crust_mantle(2,i)
!        b_accel_crust_mantle(2,i) = b_accel_crust_mantle(2,i)*rmass_crust_mantle(i) &
!                 - b_two_omega_earth*b_veloc_crust_mantle(1,i)
!        b_accel_crust_mantle(3,i) = b_accel_crust_mantle(3,i)*rmass_crust_mantle(i)
!      enddo

! way 2:
      do i=1,mod(NGLOB_CRUST_MANTLE,4)
        b_accel_crust_mantle(1,i) = b_accel_crust_mantle(1,i)*rmass_crust_mantle(i) &
                 + b_two_omega_earth*b_veloc_crust_mantle(2,i)
        b_accel_crust_mantle(2,i) = b_accel_crust_mantle(2,i)*rmass_crust_mantle(i) &
                 - b_two_omega_earth*b_veloc_crust_mantle(1,i)
        b_accel_crust_mantle(3,i) = b_accel_crust_mantle(3,i)*rmass_crust_mantle(i)
      enddo
      do i=mod(NGLOB_CRUST_MANTLE,4)+1,NGLOB_CRUST_MANTLE,4
        b_accel_crust_mantle(1,i) = b_accel_crust_mantle(1,i)*rmass_crust_mantle(i) &
                 + b_two_omega_earth*b_veloc_crust_mantle(2,i)
        b_accel_crust_mantle(2,i) = b_accel_crust_mantle(2,i)*rmass_crust_mantle(i) &
                 - b_two_omega_earth*b_veloc_crust_mantle(1,i)
        b_accel_crust_mantle(3,i) = b_accel_crust_mantle(3,i)*rmass_crust_mantle(i)

        b_accel_crust_mantle(1,i+1) = b_accel_crust_mantle(1,i+1)*rmass_crust_mantle(i+1) &
                 + b_two_omega_earth*b_veloc_crust_mantle(2,i+1)
        b_accel_crust_mantle(2,i+1) = b_accel_crust_mantle(2,i+1)*rmass_crust_mantle(i+1) &
                 - b_two_omega_earth*b_veloc_crust_mantle(1,i+1)
        b_accel_crust_mantle(3,i+1) = b_accel_crust_mantle(3,i+1)*rmass_crust_mantle(i+1)

        b_accel_crust_mantle(1,i+2) = b_accel_crust_mantle(1,i+2)*rmass_crust_mantle(i+2) &
                 + b_two_omega_earth*b_veloc_crust_mantle(2,i+2)
        b_accel_crust_mantle(2,i+2) = b_accel_crust_mantle(2,i+2)*rmass_crust_mantle(i+2) &
                 - b_two_omega_earth*b_veloc_crust_mantle(1,i+2)
        b_accel_crust_mantle(3,i+2) = b_accel_crust_mantle(3,i+2)*rmass_crust_mantle(i+2)

        b_accel_crust_mantle(1,i+3) = b_accel_crust_mantle(1,i+3)*rmass_crust_mantle(i+3) &
                 + b_two_omega_earth*b_veloc_crust_mantle(2,i+3)
        b_accel_crust_mantle(2,i+3) = b_accel_crust_mantle(2,i+3)*rmass_crust_mantle(i+3) &
                 - b_two_omega_earth*b_veloc_crust_mantle(1,i+3)
        b_accel_crust_mantle(3,i+3) = b_accel_crust_mantle(3,i+3)*rmass_crust_mantle(i+3)
      enddo

    endif

    ! couples ocean with crust mantle
    if(OCEANS_VAL) &
      call compute_coupling_ocean(accel_crust_mantle,b_accel_crust_mantle, &
                            rmass_crust_mantle,rmass_ocean_load,normal_top_crust_mantle, &
                            ibool_crust_mantle,ibelm_top_crust_mantle, &
                            updated_dof_ocean_load, &
                            SIMULATION_TYPE,NSPEC2D_TOP(IREGION_CRUST_MANTLE))


!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!

! way 1:
!    do i=1,NGLOB_CRUST_MANTLE
!      veloc_crust_mantle(:,i) = veloc_crust_mantle(:,i) + deltatover2*accel_crust_mantle(:,i)
!    enddo
!
!    do i=1,NGLOB_INNER_CORE
!      accel_inner_core(1,i) = accel_inner_core(1,i)*rmass_inner_core(i) &
!             + two_omega_earth*veloc_inner_core(2,i)
!      accel_inner_core(2,i) = accel_inner_core(2,i)*rmass_inner_core(i) &
!             - two_omega_earth*veloc_inner_core(1,i)
!      accel_inner_core(3,i) = accel_inner_core(3,i)*rmass_inner_core(i)
!
!      veloc_inner_core(:,i) = veloc_inner_core(:,i) + deltatover2*accel_inner_core(:,i)
!    enddo

! way 2:
    do i=1,mod(NGLOB_CRUST_MANTLE,4)
      veloc_crust_mantle(:,i) = veloc_crust_mantle(:,i) + deltatover2*accel_crust_mantle(:,i)
    enddo
    do i=mod(NGLOB_CRUST_MANTLE,4)+1,NGLOB_CRUST_MANTLE,4
      veloc_crust_mantle(:,i) = veloc_crust_mantle(:,i) + deltatover2*accel_crust_mantle(:,i)
      veloc_crust_mantle(:,i+1) = veloc_crust_mantle(:,i+1) + deltatover2*accel_crust_mantle(:,i+1)
      veloc_crust_mantle(:,i+2) = veloc_crust_mantle(:,i+2) + deltatover2*accel_crust_mantle(:,i+2)
      veloc_crust_mantle(:,i+3) = veloc_crust_mantle(:,i+3) + deltatover2*accel_crust_mantle(:,i+3)
    enddo

    do i=1,mod(NGLOB_INNER_CORE,3)
      accel_inner_core(1,i) = accel_inner_core(1,i)*rmass_inner_core(i) &
             + two_omega_earth*veloc_inner_core(2,i)
      accel_inner_core(2,i) = accel_inner_core(2,i)*rmass_inner_core(i) &
             - two_omega_earth*veloc_inner_core(1,i)
      accel_inner_core(3,i) = accel_inner_core(3,i)*rmass_inner_core(i)

      veloc_inner_core(:,i) = veloc_inner_core(:,i) + deltatover2*accel_inner_core(:,i)
    enddo
    do i=mod(NGLOB_INNER_CORE,3)+1,NGLOB_INNER_CORE,3
      accel_inner_core(1,i) = accel_inner_core(1,i)*rmass_inner_core(i) &
             + two_omega_earth*veloc_inner_core(2,i)
      accel_inner_core(2,i) = accel_inner_core(2,i)*rmass_inner_core(i) &
             - two_omega_earth*veloc_inner_core(1,i)
      accel_inner_core(3,i) = accel_inner_core(3,i)*rmass_inner_core(i)

      accel_inner_core(1,i+1) = accel_inner_core(1,i+1)*rmass_inner_core(i+1) &
             + two_omega_earth*veloc_inner_core(2,i+1)
      accel_inner_core(2,i+1) = accel_inner_core(2,i+1)*rmass_inner_core(i+1) &
             - two_omega_earth*veloc_inner_core(1,i+1)
      accel_inner_core(3,i+1) = accel_inner_core(3,i+1)*rmass_inner_core(i+1)

      accel_inner_core(1,i+2) = accel_inner_core(1,i+2)*rmass_inner_core(i+2) &
             + two_omega_earth*veloc_inner_core(2,i+2)
      accel_inner_core(2,i+2) = accel_inner_core(2,i+2)*rmass_inner_core(i+2) &
             - two_omega_earth*veloc_inner_core(1,i+2)
      accel_inner_core(3,i+2) = accel_inner_core(3,i+2)*rmass_inner_core(i+2)

      veloc_inner_core(:,i) = veloc_inner_core(:,i) + deltatover2*accel_inner_core(:,i)
      veloc_inner_core(:,i+1) = veloc_inner_core(:,i+1) + deltatover2*accel_inner_core(:,i+1)
      veloc_inner_core(:,i+2) = veloc_inner_core(:,i+2) + deltatover2*accel_inner_core(:,i+2)
    enddo

    if (SIMULATION_TYPE == 3) then
! way 1:
!      do i=1,NGLOB_CRUST_MANTLE
!        b_veloc_crust_mantle(:,i) = b_veloc_crust_mantle(:,i) + b_deltatover2*b_accel_crust_mantle(:,i)
!      enddo
!
!      do i=1,NGLOB_INNER_CORE
!        b_accel_inner_core(1,i) = b_accel_inner_core(1,i)*rmass_inner_core(i) &
!         + b_two_omega_earth*b_veloc_inner_core(2,i)
!        b_accel_inner_core(2,i) = b_accel_inner_core(2,i)*rmass_inner_core(i) &
!         - b_two_omega_earth*b_veloc_inner_core(1,i)
!        b_accel_inner_core(3,i) = b_accel_inner_core(3,i)*rmass_inner_core(i)
!
!        b_veloc_inner_core(:,i) = b_veloc_inner_core(:,i) + b_deltatover2*b_accel_inner_core(:,i)
!      enddo

! way 2:
      do i=1,mod(NGLOB_CRUST_MANTLE,4)
        b_veloc_crust_mantle(:,i) = b_veloc_crust_mantle(:,i) + b_deltatover2*b_accel_crust_mantle(:,i)
      enddo
      do i=mod(NGLOB_CRUST_MANTLE,4)+1,NGLOB_CRUST_MANTLE,4
        b_veloc_crust_mantle(:,i) = b_veloc_crust_mantle(:,i) + b_deltatover2*b_accel_crust_mantle(:,i)
        b_veloc_crust_mantle(:,i+1) = b_veloc_crust_mantle(:,i+1) + b_deltatover2*b_accel_crust_mantle(:,i+1)
        b_veloc_crust_mantle(:,i+2) = b_veloc_crust_mantle(:,i+2) + b_deltatover2*b_accel_crust_mantle(:,i+2)
        b_veloc_crust_mantle(:,i+3) = b_veloc_crust_mantle(:,i+3) + b_deltatover2*b_accel_crust_mantle(:,i+3)
      enddo

      do i=1,mod(NGLOB_INNER_CORE,3)
        b_accel_inner_core(1,i) = b_accel_inner_core(1,i)*rmass_inner_core(i) &
         + b_two_omega_earth*b_veloc_inner_core(2,i)
        b_accel_inner_core(2,i) = b_accel_inner_core(2,i)*rmass_inner_core(i) &
         - b_two_omega_earth*b_veloc_inner_core(1,i)
        b_accel_inner_core(3,i) = b_accel_inner_core(3,i)*rmass_inner_core(i)

        b_veloc_inner_core(:,i) = b_veloc_inner_core(:,i) + b_deltatover2*b_accel_inner_core(:,i)
      enddo
      do i=mod(NGLOB_INNER_CORE,3)+1,NGLOB_INNER_CORE,3
        b_accel_inner_core(1,i) = b_accel_inner_core(1,i)*rmass_inner_core(i) &
         + b_two_omega_earth*b_veloc_inner_core(2,i)
        b_accel_inner_core(2,i) = b_accel_inner_core(2,i)*rmass_inner_core(i) &
         - b_two_omega_earth*b_veloc_inner_core(1,i)
        b_accel_inner_core(3,i) = b_accel_inner_core(3,i)*rmass_inner_core(i)

        b_accel_inner_core(1,i+1) = b_accel_inner_core(1,i+1)*rmass_inner_core(i+1) &
         + b_two_omega_earth*b_veloc_inner_core(2,i+1)
        b_accel_inner_core(2,i+1) = b_accel_inner_core(2,i+1)*rmass_inner_core(i+1) &
         - b_two_omega_earth*b_veloc_inner_core(1,i+1)
        b_accel_inner_core(3,i+1) = b_accel_inner_core(3,i+1)*rmass_inner_core(i+1)

        b_accel_inner_core(1,i+2) = b_accel_inner_core(1,i+2)*rmass_inner_core(i+2) &
         + b_two_omega_earth*b_veloc_inner_core(2,i+2)
        b_accel_inner_core(2,i+2) = b_accel_inner_core(2,i+2)*rmass_inner_core(i+2) &
         - b_two_omega_earth*b_veloc_inner_core(1,i+2)
        b_accel_inner_core(3,i+2) = b_accel_inner_core(3,i+2)*rmass_inner_core(i+2)

        b_veloc_inner_core(:,i) = b_veloc_inner_core(:,i) + b_deltatover2*b_accel_inner_core(:,i)
        b_veloc_inner_core(:,i+1) = b_veloc_inner_core(:,i+1) + b_deltatover2*b_accel_inner_core(:,i+1)
        b_veloc_inner_core(:,i+2) = b_veloc_inner_core(:,i+2) + b_deltatover2*b_accel_inner_core(:,i+2)
      enddo

    endif


    ! restores last time snapshot saved for backward/reconstruction of wavefields
    ! note: this is done here after the Newmark time scheme, otherwise the indexing for sources
    !          and adjoint sources will become more complicated
    !          that is, index it for adjoint sources will match index NSTEP - 1 for backward/reconstructed wavefields
    if( SIMULATION_TYPE == 3 .and. it == 1 ) then
      call read_forward_arrays(myrank, &
                    b_displ_crust_mantle,b_veloc_crust_mantle,b_accel_crust_mantle, &
                    b_displ_inner_core,b_veloc_inner_core,b_accel_inner_core, &
                    b_displ_outer_core,b_veloc_outer_core,b_accel_outer_core, &
                    b_R_memory_crust_mantle,b_R_memory_inner_core, &
                    b_epsilondev_crust_mantle,b_epsilondev_inner_core, &
                    b_A_array_rotation,b_B_array_rotation,LOCAL_PATH)
    endif

! write the seismograms with time shift

! store the seismograms only if there is at least one receiver located in this slice
  if (nrec_local > 0) then
    if (SIMULATION_TYPE == 1) then
      call compute_seismograms(nrec_local,nrec,displ_crust_mantle, &
                                nu,hxir_store,hetar_store,hgammar_store, &
                                scale_displ,ibool_crust_mantle, &
                                ispec_selected_rec,number_receiver_global, &
                                seismo_current,NTSTEP_BETWEEN_OUTPUT_SEISMOS, &
                                seismograms)

    else if (SIMULATION_TYPE == 2) then
      call compute_seismograms_adjoint(NSOURCES,nrec_local,displ_crust_mantle, &
                    eps_trace_over_3_crust_mantle,epsilondev_crust_mantle, &
                    nu_source,Mxx,Myy,Mzz,Mxy,Mxz,Myz, &
                    hxir_store,hetar_store,hgammar_store, &
                    hpxir_store,hpetar_store,hpgammar_store, &
                    tshift_cmt,hdur_gaussian,DT,t0,scale_displ, &
                    hprime_xx,hprime_yy,hprime_zz, &
                    xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
                    etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
                    gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
                    moment_der,sloc_der,stshift_der,shdur_der, &
                    NTSTEP_BETWEEN_OUTPUT_SEISMOS,seismograms,deltat, &
                    ibool_crust_mantle,ispec_selected_source,number_receiver_global, &
                    NSTEP,it,nit_written)

    else if (SIMULATION_TYPE == 3) then
      call compute_seismograms_backward(nrec_local,nrec,b_displ_crust_mantle, &
                                nu,hxir_store,hetar_store,hgammar_store, &
                                scale_displ,ibool_crust_mantle, &
                                ispec_selected_rec,number_receiver_global, &
                                seismo_current,NTSTEP_BETWEEN_OUTPUT_SEISMOS, &
                                seismograms)

    endif
  endif ! nrec_local

  ! write the current or final seismograms
  if(seismo_current == NTSTEP_BETWEEN_OUTPUT_SEISMOS .or. it == it_end) then
    if (SIMULATION_TYPE == 1 .or. SIMULATION_TYPE == 3) then
      call write_seismograms(myrank,seismograms,number_receiver_global,station_name, &
            network_name,stlat,stlon,stele,stbur, &
            nrec,nrec_local,ANGULAR_WIDTH_XI_IN_DEGREES,NEX_XI,DT,t0,it_end, &
            yr_SAC,jda_SAC,ho_SAC,mi_SAC,sec_SAC,t_cmt_SAC,t_shift_SAC, &
            elat_SAC,elon_SAC,depth_SAC,event_name_SAC,cmt_lat_SAC,cmt_lon_SAC,&
            cmt_depth_SAC,cmt_hdur_SAC,NPROCTOT_VAL, &
            OUTPUT_SEISMOS_ASCII_TEXT,OUTPUT_SEISMOS_SAC_ALPHANUM, &
            OUTPUT_SEISMOS_SAC_BINARY,ROTATE_SEISMOGRAMS_RT,NTSTEP_BETWEEN_OUTPUT_SEISMOS, &
            seismo_offset,seismo_current,WRITE_SEISMOGRAMS_BY_MASTER, &
            SAVE_ALL_SEISMOS_IN_ONE_FILE,USE_BINARY_FOR_LARGE_FILE)
      if(myrank==0) then
        write(IMAIN,*)
        write(IMAIN,*) ' Total number of time steps written: ', it-it_begin+1
        write(IMAIN,*)
      endif
    else
      if( nrec_local > 0 ) &
        call write_adj_seismograms(seismograms,number_receiver_global, &
                                  nrec_local,it,nit_written,DT, &
                                  NSTEP,NTSTEP_BETWEEN_OUTPUT_SEISMOS,t0,LOCAL_PATH)
        nit_written = it
    endif
    seismo_offset = seismo_offset + seismo_current
    seismo_current = 0
  endif

!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!

! kernel calculations
  if (SIMULATION_TYPE == 3) then
    ! crust mantle
    call compute_kernels_crust_mantle(ibool_crust_mantle, &
                          rho_kl_crust_mantle,beta_kl_crust_mantle, &
                          alpha_kl_crust_mantle,cijkl_kl_crust_mantle, &
                          accel_crust_mantle,b_displ_crust_mantle, &
                          epsilondev_crust_mantle,b_epsilondev_crust_mantle, &
                          eps_trace_over_3_crust_mantle,b_eps_trace_over_3_crust_mantle, &
                          deltat)

    ! outer core
    call compute_kernels_outer_core(ibool_outer_core, &
                        xix_outer_core,xiy_outer_core,xiz_outer_core, &
                        etax_outer_core,etay_outer_core,etaz_outer_core, &
                        gammax_outer_core,gammay_outer_core,gammaz_outer_core, &
                        hprime_xx,hprime_yy,hprime_zz, &
                        displ_outer_core,accel_outer_core, &
                        b_displ_outer_core,b_accel_outer_core, &
                        vector_accel_outer_core,vector_displ_outer_core, &
                        b_vector_displ_outer_core, &
                        div_displ_outer_core,b_div_displ_outer_core, &
                        rhostore_outer_core,kappavstore_outer_core, &
                        rho_kl_outer_core,alpha_kl_outer_core, &
                        deviatoric_outercore,nspec_beta_kl_outer_core,beta_kl_outer_core, &
                        deltat)

    ! inner core
    call compute_kernels_inner_core(ibool_inner_core, &
                          rho_kl_inner_core,beta_kl_inner_core, &
                          alpha_kl_inner_core, &
                          accel_inner_core,b_displ_inner_core, &
                          epsilondev_inner_core,b_epsilondev_inner_core, &
                          eps_trace_over_3_inner_core,b_eps_trace_over_3_inner_core, &
                          deltat)

!<YANGL
    ! NOISE TOMOGRAPHY --- source strength kernel
    if (NOISE_TOMOGRAPHY == 3)  &
       call compute_kernels_strength_noise(nmovie_points,ibool_crust_mantle, &
                          Sigma_kl_crust_mantle,displ_crust_mantle,deltat,it, &
                          normal_x_noise,normal_y_noise,normal_z_noise, &
                          NSPEC2D_TOP(IREGION_CRUST_MANTLE),noise_surface_movie, &
                          ibelm_top_crust_mantle)
!>YANGL

    ! --- boundary kernels ------
    if (SAVE_BOUNDARY_MESH) then
      fluid_solid_boundary = .false.
      iregion_code = IREGION_CRUST_MANTLE

      ! Moho
      if (.not. SUPPRESS_CRUSTAL_MESH .and. HONOR_1D_SPHERICAL_MOHO) then
        call compute_boundary_kernel(displ_crust_mantle,accel_crust_mantle, &
                 b_displ_crust_mantle,nspec_crust_mantle,iregion_code, &
                 ystore_crust_mantle,zstore_crust_mantle,ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
            ! -- idoubling_crust_mantle, &
                 xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
                 etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle,&
                 gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle,hprime_xx,hprime_yy,hprime_zz, &
                 rhostore_crust_mantle,kappavstore_crust_mantle,muvstore_crust_mantle, &
                 kappahstore_crust_mantle,muhstore_crust_mantle,eta_anisostore_crust_mantle, &
                 c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle,c14store_crust_mantle, &
                 c15store_crust_mantle,c16store_crust_mantle,c22store_crust_mantle, &
                 c23store_crust_mantle,c24store_crust_mantle,c25store_crust_mantle,c26store_crust_mantle, &
                 c33store_crust_mantle,c34store_crust_mantle,c35store_crust_mantle, &
                 c36store_crust_mantle,c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
                 c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
                 k_top,ibelm_moho_top,normal_moho,moho_kl_top,fluid_solid_boundary,NSPEC2D_MOHO)

        call compute_boundary_kernel(displ_crust_mantle,accel_crust_mantle, &
                 b_displ_crust_mantle,nspec_crust_mantle,iregion_code, &
                 ystore_crust_mantle,zstore_crust_mantle,ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
              ! --idoubling_crust_mantle, &
                 xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
                 etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle,&
                 gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle,hprime_xx,hprime_yy,hprime_zz, &
                 rhostore_crust_mantle,kappavstore_crust_mantle,muvstore_crust_mantle, &
                 kappahstore_crust_mantle,muhstore_crust_mantle,eta_anisostore_crust_mantle, &
                 c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle,c14store_crust_mantle, &
                 c15store_crust_mantle,c16store_crust_mantle,c22store_crust_mantle, &
                 c23store_crust_mantle,c24store_crust_mantle,c25store_crust_mantle,c26store_crust_mantle, &
                 c33store_crust_mantle,c34store_crust_mantle,c35store_crust_mantle, &
                 c36store_crust_mantle,c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
                 c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
                 k_bot,ibelm_moho_bot,normal_moho,moho_kl_bot,fluid_solid_boundary,NSPEC2D_MOHO)

        moho_kl = moho_kl + (moho_kl_top - moho_kl_bot) * deltat
      endif

      ! 400
      call compute_boundary_kernel(displ_crust_mantle,accel_crust_mantle, &
                 b_displ_crust_mantle,nspec_crust_mantle,iregion_code, &
                 ystore_crust_mantle,zstore_crust_mantle,ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
            ! --idoubling_crust_mantle, &
                 xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
                 etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle,&
                 gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle,hprime_xx,hprime_yy,hprime_zz, &
                 rhostore_crust_mantle,kappavstore_crust_mantle,muvstore_crust_mantle, &
                 kappahstore_crust_mantle,muhstore_crust_mantle,eta_anisostore_crust_mantle, &
                 c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle,c14store_crust_mantle, &
                 c15store_crust_mantle,c16store_crust_mantle,c22store_crust_mantle, &
                 c23store_crust_mantle,c24store_crust_mantle,c25store_crust_mantle,c26store_crust_mantle, &
                 c33store_crust_mantle,c34store_crust_mantle,c35store_crust_mantle, &
                 c36store_crust_mantle,c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
                 c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
                 k_top,ibelm_400_top,normal_400,d400_kl_top,fluid_solid_boundary,NSPEC2D_400)

      call compute_boundary_kernel(displ_crust_mantle,accel_crust_mantle, &
                 b_displ_crust_mantle,nspec_crust_mantle,iregion_code, &
                 ystore_crust_mantle,zstore_crust_mantle,ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
              ! --idoubling_crust_mantle, &
                 xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
                 etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle,&
                 gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle,hprime_xx,hprime_yy,hprime_zz, &
                 rhostore_crust_mantle,kappavstore_crust_mantle,muvstore_crust_mantle, &
                 kappahstore_crust_mantle,muhstore_crust_mantle,eta_anisostore_crust_mantle, &
                 c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle,c14store_crust_mantle, &
                 c15store_crust_mantle,c16store_crust_mantle,c22store_crust_mantle, &
                 c23store_crust_mantle,c24store_crust_mantle,c25store_crust_mantle,c26store_crust_mantle, &
                 c33store_crust_mantle,c34store_crust_mantle,c35store_crust_mantle, &
                 c36store_crust_mantle,c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
                 c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
                 k_bot,ibelm_400_bot,normal_400,d400_kl_bot,fluid_solid_boundary,NSPEC2D_400)

      d400_kl = d400_kl + (d400_kl_top - d400_kl_bot) * deltat

      ! 670
      call compute_boundary_kernel(displ_crust_mantle,accel_crust_mantle, &
                 b_displ_crust_mantle,nspec_crust_mantle,iregion_code, &
                 ystore_crust_mantle,zstore_crust_mantle,ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
              ! --idoubling_crust_mantle, &
                 xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
                 etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle,&
                 gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle,hprime_xx,hprime_yy,hprime_zz, &
                 rhostore_crust_mantle,kappavstore_crust_mantle,muvstore_crust_mantle, &
                 kappahstore_crust_mantle,muhstore_crust_mantle,eta_anisostore_crust_mantle, &
                 c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle,c14store_crust_mantle, &
                 c15store_crust_mantle,c16store_crust_mantle,c22store_crust_mantle, &
                 c23store_crust_mantle,c24store_crust_mantle,c25store_crust_mantle,c26store_crust_mantle, &
                 c33store_crust_mantle,c34store_crust_mantle,c35store_crust_mantle, &
                 c36store_crust_mantle,c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
                 c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
                 k_top,ibelm_670_top,normal_670,d670_kl_top,fluid_solid_boundary,NSPEC2D_670)

      call compute_boundary_kernel(displ_crust_mantle,accel_crust_mantle, &
                 b_displ_crust_mantle,nspec_crust_mantle,iregion_code, &
                 ystore_crust_mantle,zstore_crust_mantle,ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
              ! --idoubling_crust_mantle, &
                 xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
                 etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle,&
                 gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle,hprime_xx,hprime_yy,hprime_zz, &
                 rhostore_crust_mantle,kappavstore_crust_mantle,muvstore_crust_mantle, &
                 kappahstore_crust_mantle,muhstore_crust_mantle,eta_anisostore_crust_mantle, &
                 c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle,c14store_crust_mantle, &
                 c15store_crust_mantle,c16store_crust_mantle,c22store_crust_mantle, &
                 c23store_crust_mantle,c24store_crust_mantle,c25store_crust_mantle,c26store_crust_mantle, &
                 c33store_crust_mantle,c34store_crust_mantle,c35store_crust_mantle, &
                 c36store_crust_mantle,c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
                 c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
                 k_bot,ibelm_670_bot,normal_670,d670_kl_bot,fluid_solid_boundary,NSPEC2D_670)

      d670_kl = d670_kl + (d670_kl_top - d670_kl_bot) * deltat

      ! CMB
      fluid_solid_boundary = .true.
      iregion_code = IREGION_CRUST_MANTLE
      call compute_boundary_kernel(displ_crust_mantle,accel_crust_mantle, &
                 b_displ_crust_mantle,nspec_crust_mantle,iregion_code, &
                 ystore_crust_mantle,zstore_crust_mantle,ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
              ! -- idoubling_crust_mantle, &
                 xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
                 etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle,&
                 gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle,hprime_xx,hprime_yy,hprime_zz, &
                 rhostore_crust_mantle,kappavstore_crust_mantle, muvstore_crust_mantle, &
                 kappahstore_crust_mantle,muhstore_crust_mantle,eta_anisostore_crust_mantle, &
                 c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle,c14store_crust_mantle, &
                 c15store_crust_mantle,c16store_crust_mantle,c22store_crust_mantle, &
                 c23store_crust_mantle,c24store_crust_mantle,c25store_crust_mantle,c26store_crust_mantle, &
                 c33store_crust_mantle,c34store_crust_mantle,c35store_crust_mantle, &
                 c36store_crust_mantle,c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
                 c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
                 k_top,ibelm_bottom_crust_mantle,normal_top_outer_core, &
                 cmb_kl_top,fluid_solid_boundary,NSPEC2D_CMB)

      iregion_code = IREGION_OUTER_CORE
      call compute_boundary_kernel(vector_displ_outer_core,vector_accel_outer_core, &
                 b_vector_displ_outer_core,nspec_outer_core, &
                 iregion_code,ystore_outer_core,zstore_outer_core,ibool_outer_core,ispec_is_tiso_outer_core, &
              ! --idoubling_outer_core, &
                 xix_outer_core,xiy_outer_core,xiz_outer_core, &
                 etax_outer_core,etay_outer_core,etaz_outer_core,&
                 gammax_outer_core,gammay_outer_core,gammaz_outer_core,hprime_xx,hprime_yy,hprime_zz, &
                 rhostore_outer_core,kappavstore_outer_core,dummy_array, &
                 dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array, &
                 k_bot,ibelm_top_outer_core,normal_top_outer_core, &
                 cmb_kl_bot,fluid_solid_boundary,NSPEC2D_CMB)

      cmb_kl = cmb_kl + (cmb_kl_top - cmb_kl_bot) * deltat

      ! ICB
      fluid_solid_boundary = .true.
      call compute_boundary_kernel(vector_displ_outer_core,vector_accel_outer_core, &
                 b_vector_displ_outer_core,nspec_outer_core, &
                 iregion_code,ystore_outer_core,zstore_outer_core,ibool_outer_core,ispec_is_tiso_outer_core, &
              ! --idoubling_outer_core, &
                 xix_outer_core,xiy_outer_core,xiz_outer_core, &
                 etax_outer_core,etay_outer_core,etaz_outer_core,&
                 gammax_outer_core,gammay_outer_core,gammaz_outer_core,hprime_xx,hprime_yy,hprime_zz, &
                 rhostore_outer_core,kappavstore_outer_core,dummy_array, &
                 dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array, &
                 k_top,ibelm_bottom_outer_core,normal_bottom_outer_core, &
                 icb_kl_top,fluid_solid_boundary,NSPEC2D_ICB)

      iregion_code = IREGION_INNER_CORE
      call compute_boundary_kernel(displ_inner_core,accel_inner_core, &
                 b_displ_inner_core,nspec_inner_core,iregion_code, &
                 ystore_inner_core,zstore_inner_core,ibool_inner_core,ispec_is_tiso_inner_core, &
              ! -- idoubling_inner_core, &
                 xix_inner_core,xiy_inner_core,xiz_inner_core, &
                 etax_inner_core,etay_inner_core,etaz_inner_core,&
                 gammax_inner_core,gammay_inner_core,gammaz_inner_core,hprime_xx,hprime_yy,hprime_zz, &
                 rhostore_inner_core,kappavstore_inner_core,muvstore_inner_core, &
                 dummy_array,dummy_array,dummy_array, &
                 c11store_inner_core,c12store_inner_core,c13store_inner_core,dummy_array, &
                 dummy_array,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array,dummy_array, &
                 c33store_inner_core,dummy_array,dummy_array, &
                 dummy_array,c44store_inner_core,dummy_array,dummy_array, &
                 dummy_array,dummy_array,dummy_array, &
                 k_bot,ibelm_top_inner_core,normal_bottom_outer_core, &
                 icb_kl_bot,fluid_solid_boundary,NSPEC2D_ICB)

      icb_kl = icb_kl + (icb_kl_top - icb_kl_bot) * deltat
    endif

    ! approximate hessian
    if( APPROXIMATE_HESS_KL ) then
      call compute_kernels_hessian(ibool_crust_mantle, &
                          hess_kl_crust_mantle,&
                          accel_crust_mantle,b_accel_crust_mantle, &
                          deltat)
    endif

  endif ! end computing kernels

!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!

!<YANGL
  ! first step of noise tomography, i.e., save a surface movie at every time step
  ! modified from the subroutine 'write_movie_surface'
  if ( NOISE_TOMOGRAPHY == 1 ) then
        call noise_save_surface_movie(displ_crust_mantle, &
                            ibelm_top_crust_mantle,ibool_crust_mantle, &
                            NSPEC2D_TOP(IREGION_CRUST_MANTLE),noise_surface_movie,it)
  endif
!>YANGL

  ! save movie on surface
  if( MOVIE_SURFACE ) then
    if( mod(it,NTSTEP_BETWEEN_FRAMES) == 0) then
      ! save velocity here to avoid static offset on displacement for movies
      call write_movie_surface(myrank,nmovie_points,scale_veloc,veloc_crust_mantle, &
                    scale_displ,displ_crust_mantle, &
                    xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
                    store_val_x,store_val_y,store_val_z, &
                    store_val_x_all,store_val_y_all,store_val_z_all, &
                    store_val_ux,store_val_uy,store_val_uz, &
                    store_val_ux_all,store_val_uy_all,store_val_uz_all, &
                    ibelm_top_crust_mantle,ibool_crust_mantle, &
                    NSPEC2D_TOP(IREGION_CRUST_MANTLE), &
                    NIT,it,OUTPUT_FILES,MOVIE_VOLUME_TYPE)
    endif
  endif


  ! save movie in full 3D mesh
  if(MOVIE_VOLUME ) then
    if( mod(it-MOVIE_START,NTSTEP_BETWEEN_FRAMES) == 0  &
      .and. it >= MOVIE_START .and. it <= MOVIE_STOP) then

      if (MOVIE_VOLUME_TYPE == 1) then  ! output strains

        call  write_movie_volume_strains(myrank,npoints_3dmovie, &
                    LOCAL_PATH,MOVIE_VOLUME_TYPE,MOVIE_COARSE, &
                    it,eps_trace_over_3_crust_mantle,epsilondev_crust_mantle, &
                    muvstore_crust_mantle_3dmovie, &
                    mask_3dmovie,nu_3dmovie)

      else if (MOVIE_VOLUME_TYPE == 2 .or. MOVIE_VOLUME_TYPE == 3) then
        ! output the Time Integral of Strain, or \mu*TIS
        call  write_movie_volume_strains(myrank,npoints_3dmovie, &
                    LOCAL_PATH,MOVIE_VOLUME_TYPE,MOVIE_COARSE, &
                    it,Ieps_trace_over_3_crust_mantle,Iepsilondev_crust_mantle, &
                    muvstore_crust_mantle_3dmovie, &
                    mask_3dmovie,nu_3dmovie)

      else if (MOVIE_VOLUME_TYPE == 4) then ! output divergence and curl in whole volume

        call write_movie_volume_divcurl(myrank,it,eps_trace_over_3_crust_mantle,&
                    div_displ_outer_core,eps_trace_over_3_inner_core,epsilondev_crust_mantle,&
                    epsilondev_inner_core)

      else if (MOVIE_VOLUME_TYPE == 5) then !output displacement
        scalingval = scale_displ
        call write_movie_volume_vector(myrank,it,npoints_3dmovie, &
                    LOCAL_PATH,MOVIE_VOLUME_TYPE, &
                    MOVIE_COARSE,ibool_crust_mantle,displ_crust_mantle, &
                    scalingval,mask_3dmovie,nu_3dmovie)

      else if (MOVIE_VOLUME_TYPE == 6) then !output velocity
        scalingval = scale_veloc
        call write_movie_volume_vector(myrank,it,npoints_3dmovie, &
                    LOCAL_PATH,MOVIE_VOLUME_TYPE, &
                    MOVIE_COARSE,ibool_crust_mantle,veloc_crust_mantle, &
                    scalingval,mask_3dmovie,nu_3dmovie)

      else

        stop 'MOVIE_VOLUME_TYPE has to be 1,2,3,4'

      endif ! MOVIE_VOLUME_TYPE
    endif
  endif ! MOVIE_VOLUME

!---- end of time iteration loop
!
  enddo   ! end of main time loop
!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!

  ! synchronize all processes, waits until all processes have written their seismograms
  call MPI_BARRIER(MPI_COMM_WORLD,ier)
  if( ier /= 0 ) call exit_mpi(myrank,'error synchronize after time loop')

  ! closes Stacey absorbing boundary snapshots
  if( ABSORBING_CONDITIONS ) then
    ! crust mantle
    if (nspec2D_xmin_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(0)
    endif

    if (nspec2D_xmax_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(1)
    endif

    if (nspec2D_ymin_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(2)
    endif

    if (nspec2D_ymax_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(3)
    endif

    ! outer core
    if (nspec2D_xmin_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(4)
    endif

    if (nspec2D_xmax_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(5)
    endif

    if (nspec2D_ymin_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(6)
    endif

    if (nspec2D_ymax_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(7)
    endif

    if (NSPEC2D_BOTTOM(IREGION_OUTER_CORE) > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(8)
    endif

  endif

  ! save/read the surface movie using the same c routine as we do for absorbing boundaries (file ID is 9)
  if (NOISE_TOMOGRAPHY/=0) then
    call close_file_abs(9) 
    deallocate(noise_surface_movie)
  endif


  ! synchronize all processes
  call MPI_BARRIER(MPI_COMM_WORLD,ier)
  if( ier /= 0 ) call exit_mpi(myrank,'error synchronize closing snapshots')

  ! save files to local disk or tape system if restart file
  call save_forward_arrays(myrank,SIMULATION_TYPE,SAVE_FORWARD, &
                    NUMBER_OF_RUNS,NUMBER_OF_THIS_RUN, &
                    displ_crust_mantle,veloc_crust_mantle,accel_crust_mantle, &
                    displ_inner_core,veloc_inner_core,accel_inner_core, &
                    displ_outer_core,veloc_outer_core,accel_outer_core, &
                    R_memory_crust_mantle,R_memory_inner_core, &
                    epsilondev_crust_mantle,epsilondev_inner_core, &
                    A_array_rotation,B_array_rotation, &
                    LOCAL_PATH)

  ! synchronize all processes
  call MPI_BARRIER(MPI_COMM_WORLD,ier)
  if( ier /= 0 ) call exit_mpi(myrank,'error synchronize saving forward')

  ! dump kernel arrays
  if (SIMULATION_TYPE == 3) then
    ! crust mantle
    call save_kernels_crust_mantle(myrank,scale_t,scale_displ, &
                  cijkl_kl_crust_mantle,rho_kl_crust_mantle, &
                  alpha_kl_crust_mantle,beta_kl_crust_mantle, &
                  ystore_crust_mantle,zstore_crust_mantle, &
                  rhostore_crust_mantle,muvstore_crust_mantle, &
                  kappavstore_crust_mantle,ibool_crust_mantle, &
                  kappahstore_crust_mantle,muhstore_crust_mantle, &
                  eta_anisostore_crust_mantle,ispec_is_tiso_crust_mantle, &
              ! --idoubling_crust_mantle, &
                  LOCAL_PATH)

!<YANGL
    ! noise strength kernel
    if (NOISE_TOMOGRAPHY == 3) then
       call save_kernels_strength_noise(myrank,LOCAL_PATH,Sigma_kl_crust_mantle)
    endif
!>YANGL

    ! outer core
    call save_kernels_outer_core(myrank,scale_t,scale_displ, &
                        rho_kl_outer_core,alpha_kl_outer_core, &
                        rhostore_outer_core,kappavstore_outer_core, &
                        deviatoric_outercore,nspec_beta_kl_outer_core,beta_kl_outer_core, &
                        LOCAL_PATH)

    ! inner core
    call save_kernels_inner_core(myrank,scale_t,scale_displ, &
                          rho_kl_inner_core,beta_kl_inner_core,alpha_kl_inner_core, &
                          rhostore_inner_core,muvstore_inner_core,kappavstore_inner_core, &
                          LOCAL_PATH)

    ! boundary kernel
    if (SAVE_BOUNDARY_MESH) then
      call save_kernels_boundary_kl(myrank,scale_t,scale_displ, &
                                  moho_kl,d400_kl,d670_kl,cmb_kl,icb_kl, &
                                  LOCAL_PATH,HONOR_1D_SPHERICAL_MOHO)
    endif

    ! approximate hessian
    if( APPROXIMATE_HESS_KL ) then
      call save_kernels_hessian(myrank,scale_t,scale_displ, &
                                            hess_kl_crust_mantle,LOCAL_PATH)
    endif
  endif

  ! save source derivatives for adjoint simulations
  if (SIMULATION_TYPE == 2 .and. nrec_local > 0) then
    call save_kernels_source_derivatives(nrec_local,NSOURCES,scale_displ,scale_t, &
                                nu_source,moment_der,sloc_der,stshift_der,shdur_der,number_receiver_global)
  endif

  ! close the main output file
  if(myrank == 0) then
    write(IMAIN,*)
    write(IMAIN,*) 'End of the simulation'
    write(IMAIN,*)
    close(IMAIN)
  endif

  ! synchronize all the processes to make sure everybody has finished
  call MPI_BARRIER(MPI_COMM_WORLD,ier)
  if( ier /= 0 ) call exit_mpi(myrank,'error synchronize finishing simulation')

  ! stop all the MPI processes, and exit
  call MPI_FINALIZE(ier)

  end program xspecfem3D

