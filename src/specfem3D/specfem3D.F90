!=====================================================================
!
!          S p e c f e m 3 D  G l o b e  V e r s i o n  5 . 1
!          --------------------------------------------------
!
!          Main authors: Dimitri Komatitsch and Jeroen Tromp
!                        Princeton University, USA
!             and CNRS / INRIA / University of Pau, France
! (c) Princeton University and CNRS / INRIA / University of Pau
!                            April 2011
!
! This program is free software; you can redistribute it and/or modify
! it under the terms of the GNU General Public License as published by
! the Free Software Foundation; either version 2 of the License, or
! (at your option) any later version.
!
! This program is distributed in the hope that it will be useful,
! but WITHOUT ANY WARRANTY; without even the implied warranty of
! MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
! GNU General Public License for more details.
!
! You should have received a copy of the GNU General Public License along
! with this program; if not, write to the Free Software Foundation, Inc.,
! 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
!
!=====================================================================
!
! United States and French Government Sponsorship Acknowledged.

  program xspecfem3D

  use mpi

  implicit none

  include "constants.h"
  include "precision.h"

! include values created by the mesher
  include "OUTPUT_FILES/values_from_mesher.h"

!=======================================================================!
!                                                                       !
!   specfem3D is a 3-D spectral-element solver for the Earth.           !
!   It uses a mesh generated by program meshfem3D                       !
!                                                                       !
!=======================================================================!
!
! If you use this code for your own research, please cite at least one article
! written by the developers of the package, for instance:
!
! @ARTICLE{TrKoLi08,
! author = {Jeroen Tromp and Dimitri Komatitsch and Qinya Liu},
! title = {Spectral-Element and Adjoint Methods in Seismology},
! journal = {Communications in Computational Physics},
! year = {2008},
! volume = {3},
! pages = {1-32},
! number = {1}}
!
! @ARTICLE{PeKoLuMaLeCaLeMaLiBlNiBaTr11,
! author = {Daniel Peter and Dimitri Komatitsch and Yang Luo and Roland Martin
!     and Nicolas {Le Goff} and Emanuele Casarotti and Pieyre {Le Loher}
!     and Federica Magnoni and Qinya Liu and C\'eline Blitz and Tarje Nissen-Meyer
!     and Piero Basini and Jeroen Tromp},
! title = {Forward and adjoint simulations of seismic wave propagation on fully
!     unstructured hexahedral meshes},
! journal={Geophys. J. Int.},
! year = {2011},
! volume = {186},
! pages = {721-739},
! number = {2},
! doi = {10.1111/j.1365-246X.2011.05044.x}}
!
! or
!
! @ARTICLE{VaCaSaKoVi99,
! author = {R. Vai and J. M. Castillo-Covarrubias and F. J. S\'anchez-Sesma and
! D. Komatitsch and J. P. Vilotte},
! title = {Elastic wave propagation in an irregularly layered medium},
! journal = {Soil Dynamics and Earthquake Engineering},
! year = {1999},
! volume = {18},
! pages = {11-18},
! number = {1},
! doi = {10.1016/S0267-7261(98)00027-X}}
!
! @ARTICLE{LeChKoHuTr09,
! author = {Shiann Jong Lee and Yu Chang Chan and Dimitri Komatitsch and Bor
! Shouh Huang and Jeroen Tromp},
! title = {Effects of realistic surface topography on seismic ground motion
! in the {Y}angminshan region of {T}aiwan based upon the spectral-element
! method and {LiDAR DTM}},
! journal = {Bull. Seismol. Soc. Am.},
! year = {2009},
! volume = {99},
! pages = {681-693},
! number = {2A},
! doi = {10.1785/0120080264}}
!
! @ARTICLE{LeChLiKoHuTr08,
! author = {Shiann Jong Lee and How Wei Chen and Qinya Liu and Dimitri Komatitsch
! and Bor Shouh Huang and Jeroen Tromp},
! title = {Three-Dimensional Simulations of Seismic Wave Propagation in the
! {T}aipei Basin with Realistic Topography Based upon the Spectral-Element Method},
! journal = {Bull. Seismol. Soc. Am.},
! year = {2008},
! volume = {98},
! pages = {253-264},
! number = {1},
! doi = {10.1785/0120070033}}
!
! @ARTICLE{LeKoHuTr09,
! author = {S. J. Lee and Dimitri Komatitsch and B. S. Huang and J. Tromp},
! title = {Effects of topography on seismic wave propagation: An example from
! northern {T}aiwan},
! journal = {Bull. Seismol. Soc. Am.},
! year = {2009},
! volume = {99},
! pages = {314-325},
! number = {1},
! doi = {10.1785/0120080020}}
!
! @ARTICLE{KoErGoMi10,
! author = {Dimitri Komatitsch and Gordon Erlebacher and Dominik G\"oddeke and
! David Mich\'ea},
! title = {High-order finite-element seismic wave propagation modeling with
! {MPI} on a large {GPU} cluster},
! journal = {J. Comput. Phys.},
! year = {2010},
! volume = {229},
! pages = {7692-7714},
! number = {20},
! doi = {10.1016/j.jcp.2010.06.024}}
!
! @ARTICLE{KoGoErMi10,
! author = {Dimitri Komatitsch and Dominik G\"oddeke and Gordon Erlebacher and
! David Mich\'ea},
! title = {Modeling the propagation of elastic waves using spectral elements
! on a cluster of 192 {GPU}s},
! journal = {Computer Science Research and Development},
! year = {2010},
! volume = {25},
! pages = {75-82},
! number = {1-2},
! doi = {10.1007/s00450-010-0109-1}}
!
! @ARTICLE{KoMiEr09,
! author = {Dimitri Komatitsch and David Mich\'ea and Gordon Erlebacher},
! title = {Porting a high-order finite-element earthquake modeling application
! to {NVIDIA} graphics cards using {CUDA}},
! journal = {Journal of Parallel and Distributed Computing},
! year = {2009},
! volume = {69},
! pages = {451-460},
! number = {5},
! doi = {10.1016/j.jpdc.2009.01.006}}
!
! @INCOLLECTION{ChKoViCaVaFe07,
! author = {Emmanuel Chaljub and Dimitri Komatitsch and Jean-Pierre Vilotte and
! Yann Capdeville and Bernard Valette and Gaetano Festa},
! title = {Spectral Element Analysis in Seismology},
! booktitle = {Advances in Wave Propagation in Heterogeneous Media},
! publisher = {Elsevier - Academic Press},
! year = {2007},
! editor = {Ru-Shan Wu and Val\'erie Maupin},
! volume = {48},
! series = {Advances in Geophysics},
! pages = {365-419}}
!
! @ARTICLE{KoVi98,
! author={D. Komatitsch and J. P. Vilotte},
! title={The spectral-element method: an efficient tool to simulate the seismic response of 2{D} and 3{D} geological structures},
! journal={Bull. Seismol. Soc. Am.},
! year=1998,
! volume=88,
! number=2,
! pages={368-392}}
!
! @ARTICLE{KoTr99,
! author={D. Komatitsch and J. Tromp},
! year=1999,
! title={Introduction to the spectral-element method for 3-{D} seismic wave propagation},
! journal={Geophys. J. Int.},
! volume=139,
! number=3,
! pages={806-822},
! doi={10.1046/j.1365-246x.1999.00967.x}}
!
! @ARTICLE{KoRiTr02,
! author={D. Komatitsch and J. Ritsema and J. Tromp},
! year=2002,
! title={The Spectral-Element Method, {B}eowulf Computing, and Global Seismology},
! journal={Science},
! volume=298,
! number=5599,
! pages={1737-1742},
! doi={10.1126/science.1076024}}
!
! @ARTICLE{KoTr02a,
! author={D. Komatitsch and J. Tromp},
! year=2002,
! title={Spectral-Element Simulations of Global Seismic Wave Propagation{-I. V}alidation},
! journal={Geophys. J. Int.},
! volume=149,
! number=2,
! pages={390-412},
! doi={10.1046/j.1365-246X.2002.01653.x}}
!
! @ARTICLE{KoTr02b,
! author={D. Komatitsch and J. Tromp},
! year=2002,
! title={Spectral-Element Simulations of Global Seismic Wave Propagation{-II. 3-D} Models, Oceans, Rotation, and Self-Gravitation},
! journal={Geophys. J. Int.},
! volume=150,
! pages={303-318},
! number=1,
! doi={10.1046/j.1365-246X.2002.01716.x}}
!
! and/or another article from http://web.univ-pau.fr/~dkomati1/publications.html
!
!
! If you use the kernel capabilities of the code, please cite at least one article
! written by the developers of the package, for instance:
!
! @ARTICLE{TrKoLi08,
! author = {Jeroen Tromp and Dimitri Komatitsch and Qinya Liu},
! title = {Spectral-Element and Adjoint Methods in Seismology},
! journal = {Communications in Computational Physics},
! year = {2008},
! volume = {3},
! pages = {1-32},
! number = {1}}
!
! @ARTICLE{PeKoLuMaLeCaLeMaLiBlNiBaTr11,
! author = {Daniel Peter and Dimitri Komatitsch and Yang Luo and Roland Martin
!     and Nicolas {Le Goff} and Emanuele Casarotti and Pieyre {Le Loher}
!     and Federica Magnoni and Qinya Liu and C\'eline Blitz and Tarje Nissen-Meyer
!     and Piero Basini and Jeroen Tromp},
! title = {Forward and adjoint simulations of seismic wave propagation on fully
!     unstructured hexahedral meshes},
! journal={Geophys. J. Int.},
! year = {2011},
! volume = {186},
! pages = {721-739},
! number = {2},
! doi = {10.1111/j.1365-246X.2011.05044.x}}
!
! @ARTICLE{LiTr06,
! author={Qinya Liu and Jeroen Tromp},
! title={Finite-frequency kernels based on adjoint methods},
! journal={Bull. Seismol. Soc. Am.},
! year=2006,
! volume=96,
! number=6,
! pages={2383-2397},
! doi={10.1785/0120060041}}
!
! If you use 3-D model S20RTS, please cite:
!
! @ARTICLE{RiVa00,
! author={J. Ritsema and H. J. {Van Heijst}},
! year=2000,
! title={Seismic imaging of structural heterogeneity in {E}arth's mantle: Evidence for large-scale mantle flow},
! journal={Science Progress},
! volume=83,
! pages={243-259}}
!
! Reference frame - convention:
! ----------------------------
!
! The code uses the following convention for the reference frame:
!
!  - X axis is East
!  - Y axis is North
!  - Z axis is up
!
! Note that this convention is different from both the Aki-Richards convention
! and the Harvard CMT convention.
!
! Let us recall that the Aki-Richards convention is:
!
!  - X axis is North
!  - Y axis is East
!  - Z axis is down
!
! and that the Harvard CMT convention is:
!
!  - X axis is South
!  - Y axis is East
!  - Z axis is up
!
! To report bugs or suggest improvements to the code, please send an email
! to Jeroen Tromp <jtromp AT princeton.edu> and/or use our online
! bug tracking system at http://www.geodynamics.org/roundup .
!
! Evolution of the code:
! ---------------------
!
! v. 5.1, Dimitri Komatitsch, University of Toulouse, France and Ebru Bozdag, Princeton University, USA, February 2011:
!     non blocking MPI for much better scaling on large clusters;
!     new convention for the name of seismograms, to conform to the IRIS standard;
!     new directory structure
!
! v. 5.0, many developers, February 2010:
!     new moho mesh stretching honoring crust2.0 moho depths,
!     new attenuation assignment, new SAC headers, new general crustal models,
!     faster performance due to Deville routines and enhanced loop unrolling,
!     slight changes in code structure (see also trivia at program start)
!
! v. 4.0 David Michea and Dimitri Komatitsch, University of Pau, France, February 2008:
!      new doubling brick in the mesh, new perfectly load-balanced mesh,
!      more flexible routines for mesh design, new inflated central cube
!      with optimized shape, far fewer mesh files saved by the mesher,
!      global arrays sorted to speed up the simulation, seismos can be
!      written by the master, one more doubling level at the bottom
!      of the outer core if needed (off by default)
!
! v. 3.6 Many people, many affiliations, September 2006:
!      adjoint and kernel calculations, fixed IASP91 model,
!      added AK135 and 1066a, fixed topography/bathymetry routine,
!      new attenuation routines, faster and better I/Os on very large
!      systems, many small improvements and bug fixes, new "configure"
!      script, new user's manual etc.
!
! v. 3.5 Dimitri Komatitsch, Brian Savage and Jeroen Tromp, Caltech, July 2004:
!      any size of chunk, 3D attenuation, case of two chunks,
!      more precise topography/bathymetry model, new Par_file structure
!
! v. 3.4 Dimitri Komatitsch and Jeroen Tromp, Caltech, August 2003:
!      merged global and regional codes, no iterations in fluid, better movies
!
! v. 3.3 Dimitri Komatitsch, Caltech, September 2002:
!      flexible mesh doubling in outer core, inlined code, OpenDX support
!
! v. 3.2 Jeroen Tromp, Caltech, July 2002:
!      multiple sources and flexible PREM reading
!
! v. 3.1 Dimitri Komatitsch, Caltech, June 2002:
!      vectorized loops in solver and merged central cube
!
! v. 3.0 Dimitri Komatitsch and Jeroen Tromp, Caltech, May 2002:
!   ported to SGI and Compaq, double precision solver, more general anisotropy
!
! v. 2.3 Dimitri Komatitsch and Jeroen Tromp, Caltech, August 2001:
!                       gravity, rotation, oceans and 3-D models
!
! v. 2.2 Dimitri Komatitsch and Jeroen Tromp, Caltech, USA, March 2001:
!                       final MPI package
!
! v. 2.0 Dimitri Komatitsch, Harvard, USA, January 2000: MPI code for the globe
!
! v. 1.0 Dimitri Komatitsch, UNAM, Mexico, June 1999: first MPI code for a chunk
!
! Jeroen Tromp and Dimitri Komatitsch, Harvard, USA, July 1998: first chunk solver using OpenMP on a Sun machine
!
! Dimitri Komatitsch, IPG Paris, France, December 1996: first 3-D solver for the CM-5 Connection Machine,
!    parallelized on 128 processors using Connection Machine Fortran
!
! From Dahlen and Tromp (1998):
! ----------------------------
!
! Gravity is approximated by solving eq (3.259) without the Phi_E' term
! The ellipsoidal reference model is that of section 14.1
! The transversely isotropic expression for PREM is that of eq (8.190)
!
! Formulation in the fluid (acoustic) outer core:
! -----------------------------------------------
!
! In case of an acoustic medium, a displacement potential Chi is used
! as in Chaljub and Valette, Geophysical Journal International, vol. 158,
! p. 131-141 (2004) and *NOT* a velocity potential as in Komatitsch and Tromp,
! Geophysical Journal International, vol. 150, p. 303-318 (2002).
! This permits acoustic-elastic coupling based on a non-iterative time scheme.
! Displacement if we ignore gravity is then: u = grad(Chi)
! (In the context of the Cowling approximation displacement is
! u = grad(rho * Chi) / rho, *not* u = grad(Chi).)
! Velocity is then: v = grad(Chi_dot)       (Chi_dot being the time derivative of Chi)
! and pressure is: p = - rho * Chi_dot_dot  (Chi_dot_dot being the time second derivative of Chi).
! The source in an acoustic element is a pressure source.
! The potential in the outer core is called displ_outer_core for simplicity.
! Its first time derivative is called veloc_outer_core.
! Its second time derivative is called accel_outer_core.

! memory variables and standard linear solids for attenuation
  real(kind=CUSTOM_REAL), dimension(ATT1_VAL,ATT2_VAL,ATT3_VAL,ATT4_VAL) :: &
           one_minus_sum_beta_crust_mantle, factor_scale_crust_mantle
  real(kind=CUSTOM_REAL), dimension(ATT1_VAL,ATT2_VAL,ATT3_VAL,ATT5_VAL) :: &
           one_minus_sum_beta_inner_core, factor_scale_inner_core

  real(kind=CUSTOM_REAL), dimension(N_SLS) :: alphaval, betaval, gammaval
  real(kind=CUSTOM_REAL), dimension(N_SLS,ATT1_VAL,ATT2_VAL,ATT3_VAL,ATT4_VAL) :: factor_common_crust_mantle
  real(kind=CUSTOM_REAL), dimension(N_SLS,ATT1_VAL,ATT2_VAL,ATT3_VAL,ATT5_VAL) :: factor_common_inner_core

  real(kind=CUSTOM_REAL), dimension(5,N_SLS,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ATTENUAT) :: R_memory_crust_mantle
  real(kind=CUSTOM_REAL), dimension(:,:,:,:,:), allocatable :: epsilondev_crust_mantle
  real(kind=CUSTOM_REAL), dimension(:,:,:,:), allocatable :: eps_trace_over_3_crust_mantle

  real(kind=CUSTOM_REAL), dimension(5,NGLLX,NGLLY,NGLLZ) :: epsilondev_loc_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ) :: eps_trace_over_3_loc_crust_mantle

  real(kind=CUSTOM_REAL), dimension(5,N_SLS,NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE_ATTENUATION) :: R_memory_inner_core
  real(kind=CUSTOM_REAL), dimension(:,:,:,:,:), allocatable :: epsilondev_inner_core
  real(kind=CUSTOM_REAL), dimension(:,:,:,:), allocatable :: eps_trace_over_3_inner_core

! to save a significant amount of memory space, we equivalence these two arrays that are never used simultaneously
! (ibathy_topo is only used before the beginning of the time loop, while R_memory_crust_mantle is only used inside the time loop)
  equivalence(R_memory_crust_mantle,ibathy_topo)

! ADJOINT
  real(kind=CUSTOM_REAL), dimension(N_SLS) :: b_alphaval, b_betaval, b_gammaval

  real(kind=CUSTOM_REAL), dimension(5,N_SLS,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_STR_AND_ATT) :: b_R_memory_crust_mantle

  real(kind=CUSTOM_REAL), dimension(5,N_SLS,NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE_STR_AND_ATT) :: b_R_memory_inner_core

! for matching with central cube in inner core
  integer, dimension(:), allocatable :: sender_from_slices_to_cube
  integer, dimension(:,:), allocatable :: ibool_central_cube
  double precision, dimension(:,:), allocatable :: buffer_slices,b_buffer_slices,buffer_slices2
  double precision, dimension(:,:,:), allocatable :: buffer_all_cube_from_slices,b_buffer_all_cube_from_slices
  integer nb_msgs_theor_in_cube,non_zero_nb_msgs_theor_in_cube,npoin2D_cube_from_slices,receiver_cube_from_slices

  integer nspec2D_xmin_inner_core,nspec2D_xmax_inner_core,nspec2D_ymin_inner_core,nspec2D_ymax_inner_core

! to save movie frames
  integer nmovie_points,NIT
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: &
      store_val_x,store_val_y,store_val_z, &
      store_val_ux,store_val_uy,store_val_uz
  real(kind=CUSTOM_REAL), dimension(:,:), allocatable :: &
      store_val_x_all,store_val_y_all,store_val_z_all, &
      store_val_ux_all,store_val_uy_all,store_val_uz_all

! to save movie volume
  integer :: npoints_3dmovie,nspecel_3dmovie,ispec
  double precision :: scalingval
  integer, dimension(NGLOB_CRUST_MANTLE_3DMOVIE) :: num_ibool_3dmovie
  logical, dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_3DMOVIE) :: mask_3dmovie
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_3DMOVIE) :: muvstore_crust_mantle_3dmovie
  real(kind=CUSTOM_REAL), dimension(:,:,:), allocatable :: nu_3dmovie
  real(kind=CUSTOM_REAL), dimension(5,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_3DMOVIE) :: Iepsilondev_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_3DMOVIE) :: Ieps_trace_over_3_crust_mantle

! use integer array to store values
  integer, dimension(NX_BATHY_VAL,NY_BATHY_VAL) :: ibathy_topo

! for crust/oceans coupling
  integer, dimension(NSPEC2DMAX_XMIN_XMAX_CM) :: ibelm_xmin_crust_mantle,ibelm_xmax_crust_mantle
  integer, dimension(NSPEC2DMAX_YMIN_YMAX_CM) :: ibelm_ymin_crust_mantle,ibelm_ymax_crust_mantle
  integer, dimension(NSPEC2D_BOTTOM_CM) :: ibelm_bottom_crust_mantle
  integer, dimension(NSPEC2D_TOP_CM) :: ibelm_top_crust_mantle

! additional mass matrix for ocean load
  real(kind=CUSTOM_REAL), dimension(NGLOB_CRUST_MANTLE_OCEANS) :: rmass_ocean_load

! flag to mask ocean-bottom degrees of freedom for ocean load
  logical, dimension(NGLOB_CRUST_MANTLE_OCEANS) :: updated_dof_ocean_load

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_BOTTOM_CM) :: jacobian2D_bottom_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_TOP_CM) :: jacobian2D_top_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLLY,NGLLZ,NSPEC2DMAX_XMIN_XMAX_CM) :: jacobian2D_xmin_crust_mantle,&
  jacobian2D_xmax_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLZ,NSPEC2DMAX_YMIN_YMAX_CM) :: jacobian2D_ymin_crust_mantle,&
  jacobian2D_ymax_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLY,NGLLZ,NSPEC2DMAX_XMIN_XMAX_CM) :: &
  normal_xmin_crust_mantle,normal_xmax_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2DMAX_YMIN_YMAX_CM) :: &
  normal_ymin_crust_mantle,normal_ymax_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_BOTTOM_CM) :: normal_bottom_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_TOP_CM) :: normal_top_crust_mantle

! Stacey
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_STACEY) :: rho_vp_crust_mantle,rho_vs_crust_mantle
  integer nspec2D_xmin_crust_mantle,nspec2D_xmax_crust_mantle,nspec2D_ymin_crust_mantle,nspec2D_ymax_crust_mantle
  integer, dimension(2,NSPEC2DMAX_YMIN_YMAX_CM) :: nimin_crust_mantle,nimax_crust_mantle,nkmin_eta_crust_mantle
  integer, dimension(2,NSPEC2DMAX_XMIN_XMAX_CM) :: njmin_crust_mantle,njmax_crust_mantle,nkmin_xi_crust_mantle

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_STACEY) :: vp_outer_core
  integer nspec2D_xmin_outer_core,nspec2D_xmax_outer_core,nspec2D_ymin_outer_core,nspec2D_ymax_outer_core
  integer, dimension(2,NSPEC2DMAX_YMIN_YMAX_OC) :: nimin_outer_core,nimax_outer_core,nkmin_eta_outer_core
  integer, dimension(2,NSPEC2DMAX_XMIN_XMAX_OC) :: njmin_outer_core,njmax_outer_core,nkmin_xi_outer_core

! arrays to couple with the fluid regions by pointwise matching
  integer, dimension(NSPEC2DMAX_XMIN_XMAX_OC) :: ibelm_xmin_outer_core,ibelm_xmax_outer_core
  integer, dimension(NSPEC2DMAX_YMIN_YMAX_OC) :: ibelm_ymin_outer_core,ibelm_ymax_outer_core
  integer, dimension(NSPEC2D_BOTTOM_OC) :: ibelm_bottom_outer_core
  integer, dimension(NSPEC2D_TOP_OC) :: ibelm_top_outer_core

  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLY,NGLLZ,NSPEC2DMAX_XMIN_XMAX_OC) :: normal_xmin_outer_core,normal_xmax_outer_core
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLZ,NSPEC2DMAX_YMIN_YMAX_OC) :: normal_ymin_outer_core,normal_ymax_outer_core
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_BOTTOM_OC) :: normal_bottom_outer_core
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_TOP_OC) :: normal_top_outer_core

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_BOTTOM_OC) :: jacobian2D_bottom_outer_core
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_TOP_OC) :: jacobian2D_top_outer_core
  real(kind=CUSTOM_REAL), dimension(NGLLY,NGLLZ,NSPEC2DMAX_XMIN_XMAX_OC) :: jacobian2D_xmin_outer_core,jacobian2D_xmax_outer_core
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLZ,NSPEC2DMAX_YMIN_YMAX_OC) :: jacobian2D_ymin_outer_core,jacobian2D_ymax_outer_core


  integer, dimension(NSPEC2DMAX_XMIN_XMAX_IC) :: ibelm_xmin_inner_core,ibelm_xmax_inner_core
  integer, dimension(NSPEC2DMAX_YMIN_YMAX_IC) :: ibelm_ymin_inner_core,ibelm_ymax_inner_core
  integer, dimension(NSPEC2D_BOTTOM_IC) :: ibelm_bottom_inner_core
  integer, dimension(NSPEC2D_TOP_IC) :: ibelm_top_inner_core

! for ellipticity
  integer nspl
  double precision rspl(NR),espl(NR),espl2(NR)

! for conversion from x y z to r theta phi
  real(kind=CUSTOM_REAL) rval,thetaval,phival

! -------- arrays specific to each region here -----------

! ----------------- crust, mantle and oceans ---------------------

! mesh parameters
  integer, dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE) :: ibool_crust_mantle

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE) :: &
        xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle,&
        etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
        gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLOB_CRUST_MANTLE) :: &
        xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle

! arrays for isotropic elements stored only where needed to save space
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPECMAX_ISO_MANTLE) :: &
        rhostore_crust_mantle,kappavstore_crust_mantle,muvstore_crust_mantle

! arrays for anisotropic elements stored only where needed to save space
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPECMAX_TISO_MANTLE) :: &
        kappahstore_crust_mantle,muhstore_crust_mantle,eta_anisostore_crust_mantle

! arrays for full anisotropy only when needed
  integer nspec_iso,nspec_tiso,nspec_ani
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPECMAX_ANISO_MANTLE) :: &
        c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
        c14store_crust_mantle,c15store_crust_mantle,c16store_crust_mantle, &
        c22store_crust_mantle,c23store_crust_mantle,c24store_crust_mantle, &
        c25store_crust_mantle,c26store_crust_mantle,c33store_crust_mantle, &
        c34store_crust_mantle,c35store_crust_mantle,c36store_crust_mantle, &
        c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
        c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle

! local to global mapping
  logical, dimension(NSPEC_CRUST_MANTLE) :: ispec_is_tiso_crust_mantle

! mass matrices
!
! in the case of stacey boundary conditions, add C*delta/2 contribution to the mass matrix
! on the Stacey edges for the crust_mantle and outer_core regions but not for the inner_core region
! thus the mass matrix must be replaced by three mass matrices including the "C" damping matrix
!
! if absorbing_conditions are not set or if NCHUNKS=6, only one mass matrix is needed
! for the sake of performance, only "rmassz" array will be filled and "rmassx" & "rmassy" will be obsolete
!
! in the case of ROTATION, we should add two_omega_earth*deltat/2 contribution to  rmassx & rmassy
! thus in this case  rmassx & rmassy will be used
!
! in the case of ROTAION and SIMULATION_TYPE == 3, we should add b_two_omega_earth*deltat/2 contribution to  &
! b_rmassx & b_rmassy
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: rmassx_crust_mantle
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: rmassy_crust_mantle
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: b_rmassx_crust_mantle
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: b_rmassy_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLOB_CRUST_MANTLE) :: rmassz_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLOB_CRUST_MANTLE) :: b_rmassz_crust_mantle
  equivalence(rmassz_crust_mantle,b_rmassz_crust_mantle)

  integer :: NGLOB_XY_CM,NGLOB_XY_CM_BACKWARD

! displacement, velocity, acceleration
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLOB_CRUST_MANTLE) :: &
     displ_crust_mantle,veloc_crust_mantle,accel_crust_mantle

! ----------------- outer core ---------------------

! mesh parameters
  integer, dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE) :: ibool_outer_core

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE) :: &
        xix_outer_core,xiy_outer_core,xiz_outer_core,&
        etax_outer_core,etay_outer_core,etaz_outer_core, &
        gammax_outer_core,gammay_outer_core,gammaz_outer_core
  real(kind=CUSTOM_REAL), dimension(NGLOB_OUTER_CORE) :: &
        xstore_outer_core,ystore_outer_core,zstore_outer_core

 real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE) :: &
        rhostore_outer_core,kappavstore_outer_core

! local to global mapping
  integer, dimension(NSPEC_OUTER_CORE) :: idoubling_outer_core
  logical, dimension(NSPEC_OUTER_CORE) :: ispec_is_tiso_outer_core ! only needed for compute_boundary_kernel()

! mass matrix
  real(kind=CUSTOM_REAL), dimension(NGLOB_OUTER_CORE) :: rmass_outer_core

! velocity potential
  real(kind=CUSTOM_REAL), dimension(NGLOB_OUTER_CORE) :: displ_outer_core, &
    veloc_outer_core,accel_outer_core

! ----------------- inner core ---------------------

! mesh parameters
  integer, dimension(NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE) :: ibool_inner_core

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE) :: &
        xix_inner_core,xiy_inner_core,xiz_inner_core,&
        etax_inner_core,etay_inner_core,etaz_inner_core, &
        gammax_inner_core,gammay_inner_core,gammaz_inner_core, &
        rhostore_inner_core, kappavstore_inner_core,muvstore_inner_core
  real(kind=CUSTOM_REAL), dimension(NGLOB_INNER_CORE) :: &
        xstore_inner_core,ystore_inner_core,zstore_inner_core

! arrays for inner-core anisotropy only when needed
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPECMAX_ANISO_IC) :: &
        c11store_inner_core,c33store_inner_core,c12store_inner_core, &
        c13store_inner_core,c44store_inner_core

! local to global mapping
  integer, dimension(NSPEC_INNER_CORE) :: idoubling_inner_core
  logical, dimension(NSPEC_INNER_CORE) :: ispec_is_tiso_inner_core ! only needed for computer_boundary_kernel() routine

! mass matrix
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: rmassx_inner_core
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: rmassy_inner_core
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: b_rmassx_inner_core
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: b_rmassy_inner_core
  real(kind=CUSTOM_REAL), dimension(NGLOB_INNER_CORE) :: rmass_inner_core
  real(kind=CUSTOM_REAL), dimension(NGLOB_INNER_CORE) :: b_rmass_inner_core
  integer :: NGLOB_XY_IC,NGLOB_XY_IC_BACKWARD
  equivalence(rmass_inner_core,b_rmass_inner_core)

! displacement, velocity, acceleration
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLOB_INNER_CORE) :: &
     displ_inner_core,veloc_inner_core,accel_inner_core

! Newmark time scheme parameters and non-dimensionalization
  real(kind=CUSTOM_REAL) time,deltat,deltatover2,deltatsqover2
  double precision scale_t,scale_t_inv,scale_displ,scale_veloc

! ADJOINT
  real(kind=CUSTOM_REAL) b_deltat,b_deltatover2,b_deltatsqover2
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLOB_CRUST_MANTLE_ADJOINT) :: &
    b_displ_crust_mantle,b_veloc_crust_mantle,b_accel_crust_mantle
  real(kind=CUSTOM_REAL), dimension(NGLOB_OUTER_CORE_ADJOINT) :: &
    b_displ_outer_core,b_veloc_outer_core,b_accel_outer_core
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLOB_INNER_CORE_ADJOINT) :: &
    b_displ_inner_core,b_veloc_inner_core,b_accel_inner_core

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_ADJOINT) :: div_displ_outer_core
  real(kind=CUSTOM_REAL), dimension(1) :: b_div_displ_outer_core_dummy ! dummy array that needs to be there for subroutine calls

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ADJOINT) :: rho_kl_crust_mantle, &
     beta_kl_crust_mantle, alpha_kl_crust_mantle

! additional kernels computed locally in save_kernels() from the other ones
! depending on the case: iso, tiso, or aniso kernels
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ADJOINT) :: &
    mu_kl_crust_mantle, kappa_kl_crust_mantle, rhonotprime_kl_crust_mantle, &
    alphav_kl_crust_mantle,alphah_kl_crust_mantle, &
    betav_kl_crust_mantle,betah_kl_crust_mantle, &
    eta_kl_crust_mantle
  ! bulk parameterization
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ADJOINT) :: &
    bulk_c_kl_crust_mantle,bulk_beta_kl_crust_mantle, &
    bulk_betav_kl_crust_mantle,bulk_betah_kl_crust_mantle

! can equivalence the above arrays to save a significant amount of memory because they are used only once at the end to save
! the final kernels in save_kernels_crust_mantle(), once the Jacobian matrix elements xix xiy xiz are never needed any more,
! nor the displacement vector.
! In the first statements we can equivalence three arrays instead of two because one is used only in the isotropic kernel
! calculation case while the other is used only in the transversely isotropic kernel calculation case,
! and these two options are never both true, thus only one of the two arrays is actually used.
  equivalence(mu_kl_crust_mantle, alphav_kl_crust_mantle,    xix_crust_mantle)
  equivalence(kappa_kl_crust_mantle, alphah_kl_crust_mantle, xiy_crust_mantle)
  equivalence(rhonotprime_kl_crust_mantle,                   xiz_crust_mantle)
  equivalence(bulk_c_kl_crust_mantle,                        etax_crust_mantle)
  equivalence(bulk_beta_kl_crust_mantle,                     etay_crust_mantle)
  equivalence(betav_kl_crust_mantle,                         etaz_crust_mantle)
  equivalence(betah_kl_crust_mantle,                         gammax_crust_mantle)
  equivalence(bulk_betav_kl_crust_mantle,                    gammay_crust_mantle)
  equivalence(bulk_betah_kl_crust_mantle,                    gammaz_crust_mantle)
  equivalence(eta_kl_crust_mantle,                           displ_crust_mantle)

! For anisotropic kernels (see compute_kernels.f90 for a definition of the array)
  real(kind=CUSTOM_REAL), dimension(21,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ADJOINT_ANISO_KL) :: cijkl_kl_crust_mantle

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_ADJOINT) :: rho_kl_outer_core, &
     alpha_kl_outer_core

! for noise kernel
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ADJOINT_NOISE) :: Sigma_kl_crust_mantle

  ! approximate hessian
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ADJOINT_HESS) :: hess_kl_crust_mantle

  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE_ADJOINT) :: rho_kl_inner_core, &
     beta_kl_inner_core, alpha_kl_inner_core

! For saving kernels on a regular grid
  type kl_reg_grid_variables
    sequence
    real dlat
    real dlon
    integer nlayer
    real rlayer(NM_KL_REG_LAYER)
    integer ndoubling(NM_KL_REG_LAYER)
    integer nlat(NM_KL_REG_LAYER)
    integer nlon(NM_KL_REG_LAYER)
    integer npts_total
    integer npts_before_layer(NM_KL_REG_LAYER+1)
  end type kl_reg_grid_variables
  type (kl_reg_grid_variables) KL_REG_GRID

  integer isp, npoints_slice
  integer, dimension(:), allocatable :: slice_number
  integer, dimension(NM_KL_REG_PTS_VAL) :: points_slice
  integer, dimension(NM_KL_REG_PTS_VAL) :: ispec_reg
  real, dimension(NGLLX, NM_KL_REG_PTS_VAL) :: hxir_reg
  real, dimension(NGLLY, NM_KL_REG_PTS_VAL) :: hetar_reg
  real, dimension(NGLLZ, NM_KL_REG_PTS_VAL) :: hgammar_reg

  real(kind=CUSTOM_REAL), dimension(:,:,:,:,:), allocatable :: absorb_xmin_crust_mantle5, &
     absorb_xmax_crust_mantle5, absorb_ymin_crust_mantle5, absorb_ymax_crust_mantle5

  real(kind=CUSTOM_REAL), dimension(:,:,:), allocatable :: absorb_xmin_outer_core, &
     absorb_xmax_outer_core, absorb_ymin_outer_core, absorb_ymax_outer_core, &
     absorb_zmin_outer_core
  integer nabs_xmin_cm,nabs_xmax_cm,nabs_ymin_cm,nabs_ymax_cm
  integer nabs_xmin_oc,nabs_xmax_oc,nabs_ymin_oc,nabs_ymax_oc,nabs_zmin_oc

  integer reclen_xmin_crust_mantle, reclen_xmax_crust_mantle, reclen_ymin_crust_mantle, &
     reclen_ymax_crust_mantle, reclen_xmin_outer_core, reclen_xmax_outer_core, &
     reclen_ymin_outer_core, reclen_ymax_outer_core, reclen_zmin

! real(kind=CUSTOM_REAL), dimension(NDIM,NGLOB_OUTER_CORE_ADJOINT) :: vector_accel_outer_core, &
!            vector_displ_outer_core, b_vector_displ_outer_core
!! DK DK July 2013: to save a significant amount of memory, no need for these arrays to be global, a local version is sufficient
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NGLLZ) :: vector_accel_outer_core, &
             vector_displ_outer_core, b_vector_displ_outer_core

  integer npoin2D_faces_crust_mantle(NUMFACES_SHARED)
  integer npoin2D_faces_outer_core(NUMFACES_SHARED)
  integer npoin2D_faces_inner_core(NUMFACES_SHARED)

! ---- arrays to assemble between chunks

! communication pattern for faces between chunks
  integer, dimension(NUMMSGS_FACES_VAL) :: iprocfrom_faces,iprocto_faces,imsg_type

! communication pattern for corners between chunks
  integer, dimension(NCORNERSCHUNKS_VAL) :: iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners

! indirect addressing for each message for faces and corners of the chunks
! a given slice can belong to at most one corner and at most two faces
  integer NGLOB2DMAX_XY
  integer, dimension(NGLOB2DMAX_XY_CM_VAL,NUMFACES_SHARED) :: iboolfaces_crust_mantle
  integer, dimension(NGLOB2DMAX_XY_OC_VAL,NUMFACES_SHARED) :: iboolfaces_outer_core
  integer, dimension(NGLOB2DMAX_XY_IC_VAL,NUMFACES_SHARED) :: iboolfaces_inner_core

! this for non blocking MPI

! buffers for send and receive between faces of the slices and the chunks
! we use the same buffers to assemble scalars and vectors because vectors are
! always three times bigger and therefore scalars can use the first part
! of the vector buffer in memory even if it has an additional index here
  integer :: npoin2D_max_all_CM_IC
  real(kind=CUSTOM_REAL), dimension(:,:,:), allocatable :: buffer_send_faces,buffer_received_faces, &
                                                           b_buffer_send_faces,b_buffer_received_faces

! for non blocking communications
  logical, dimension(NSPEC_CRUST_MANTLE) :: is_on_a_slice_edge_crust_mantle
  logical, dimension(NSPEC_OUTER_CORE) :: is_on_a_slice_edge_outer_core
  logical, dimension(NSPEC_INNER_CORE) :: is_on_a_slice_edge_inner_core
  logical, dimension(NGLOB_CRUST_MANTLE) :: mask_ibool
! added this to save memory, since this logical mask is not used inside the time loop
  equivalence(mask_ibool,accel_crust_mantle)
  real :: percentage_edge

! assembling phase number for non blocking MPI
! iphase is for the crust_mantle, outer_core and inner_core regions
! iphase_CC is for the central cube
  integer :: iphase,iphase_CC,icall
  integer :: b_iphase,b_iphase_CC,b_icall

! parameters for the source
  integer it
  integer, dimension(:), allocatable :: islice_selected_source,ispec_selected_source
  real(kind=CUSTOM_REAL), dimension(:,:,:,:,:), allocatable :: sourcearrays
  double precision, dimension(:,:,:) ,allocatable:: nu_source
  double precision sec
  double precision, dimension(:), allocatable :: Mxx,Myy,Mzz,Mxy,Mxz,Myz
  double precision, dimension(:), allocatable :: xi_source,eta_source,gamma_source
  double precision, dimension(:), allocatable :: tshift_cmt,hdur,hdur_gaussian
  double precision, dimension(:), allocatable :: theta_source,phi_source
  double precision, external :: comp_source_time_function
  double precision t0

! receiver information
  integer nrec,nrec_local
  integer, dimension(:), allocatable :: islice_selected_rec,ispec_selected_rec,number_receiver_global
  double precision, dimension(:), allocatable :: xi_receiver,eta_receiver,gamma_receiver
  character(len=150) :: STATIONS,rec_filename
  double precision, dimension(:,:,:), allocatable :: nu
  double precision, allocatable, dimension(:) :: stlat,stlon,stele,stbur
  character(len=MAX_LENGTH_STATION_NAME), dimension(:), allocatable  :: station_name
  character(len=MAX_LENGTH_NETWORK_NAME), dimension(:), allocatable :: network_name

!ADJOINT
  real(kind=CUSTOM_REAL), dimension(:,:,:,:,:,:), allocatable :: adj_sourcearrays
  integer nrec_simulation, nadj_rec_local
  integer NSTEP_SUB_ADJ  ! to read input in chunks
  integer, dimension(:,:), allocatable :: iadjsrc ! to read input in chunks
  integer, dimension(:), allocatable :: iadjsrc_len,iadj_vec
! source frechet derivatives
  real(kind=CUSTOM_REAL), dimension(:,:,:), allocatable :: moment_der
  real(kind=CUSTOM_REAL), dimension(:,:), allocatable :: sloc_der
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: stshift_der, shdur_der
  double precision, dimension(:,:), allocatable :: hpxir_store,hpetar_store,hpgammar_store
  integer :: nadj_hprec_local

! seismograms
  integer it_begin,it_end,nit_written
  real(kind=CUSTOM_REAL), dimension(:,:,:), allocatable :: seismograms
  integer :: seismo_offset, seismo_current

! non-dimensionalized rotation rate of the Earth times two
  real(kind=CUSTOM_REAL) two_omega_earth

! for the Euler scheme for rotation
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_ROTATION) :: &
    A_array_rotation,B_array_rotation

! number of faces between chunks
  integer NUMMSGS_FACES

! number of corners between chunks
  integer NCORNERSCHUNKS

! number of message types
  integer NUM_MSG_TYPES

! indirect addressing for each corner of the chunks
  integer, dimension(NGLOB1D_RADIAL_CM,NUMCORNERS_SHARED) :: iboolcorner_crust_mantle
  integer, dimension(NGLOB1D_RADIAL_OC,NUMCORNERS_SHARED) :: iboolcorner_outer_core
  integer, dimension(NGLOB1D_RADIAL_IC,NUMCORNERS_SHARED) :: iboolcorner_inner_core

! buffers for send and receive between corners of the chunks
  real(kind=CUSTOM_REAL), dimension(NGLOB1D_RADIAL_CM) :: buffer_send_chunkcorn_scalar,buffer_recv_chunkcorn_scalar, &
                                                          b_buffer_send_chunkcorn_scalar,b_buffer_recv_chunkcorn_scalar
! size of buffers is the sum of two sizes because we handle two regions in the same MPI call
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLOB1D_RADIAL_CM + NGLOB1D_RADIAL_IC) :: &
     buffer_send_chunkcorn_vector,buffer_recv_chunkcorn_vector, &
     b_buffer_send_chunkcorn_vector,b_buffer_recv_chunkcorn_vector

! Gauss-Lobatto-Legendre points of integration and weights
  double precision, dimension(NGLLX) :: xigll,wxgll
  double precision, dimension(NGLLY) :: yigll,wygll
  double precision, dimension(NGLLZ) :: zigll,wzgll

! product of weights for gravity term
  double precision, dimension(NGLLX,NGLLY,NGLLZ) :: wgll_cube

! array with derivatives of Lagrange polynomials and precalculated products
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLX) :: hprime_xx,hprimewgll_xx
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLX) :: hprime_xxT,hprimewgll_xxT
  real(kind=CUSTOM_REAL), dimension(NGLLY,NGLLY) :: hprime_yy,hprimewgll_yy
  real(kind=CUSTOM_REAL), dimension(NGLLZ,NGLLZ) :: hprime_zz,hprimewgll_zz
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY) :: wgllwgll_xy
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLZ) :: wgllwgll_xz
  real(kind=CUSTOM_REAL), dimension(NGLLY,NGLLZ) :: wgllwgll_yz

! Lagrange interpolators at receivers
  double precision, dimension(:,:), allocatable :: hxir_store,hetar_store,hgammar_store

! 2-D addressing and buffers for summation between slices
  integer, dimension(NGLOB2DMAX_XMIN_XMAX_CM) :: iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle
  integer, dimension(NGLOB2DMAX_YMIN_YMAX_CM) :: iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle

  integer, dimension(NGLOB2DMAX_XMIN_XMAX_OC) :: iboolleft_xi_outer_core,iboolright_xi_outer_core
  integer, dimension(NGLOB2DMAX_YMIN_YMAX_OC) :: iboolleft_eta_outer_core,iboolright_eta_outer_core

  integer, dimension(NGLOB2DMAX_XMIN_XMAX_IC) :: iboolleft_xi_inner_core,iboolright_xi_inner_core
  integer, dimension(NGLOB2DMAX_YMIN_YMAX_IC) :: iboolleft_eta_inner_core,iboolright_eta_inner_core

! for addressing of the slices
  integer, dimension(NCHUNKS_VAL,0:NPROC_XI_VAL-1,0:NPROC_ETA_VAL-1) :: addressing
  integer, dimension(0:NPROCTOT_VAL-1) :: ichunk_slice,iproc_xi_slice,iproc_eta_slice

! proc numbers for MPI
  integer myrank

  integer, dimension(NB_SQUARE_EDGES_ONEDIR) :: npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle
  integer, dimension(NB_SQUARE_EDGES_ONEDIR) :: npoin2D_xi_outer_core,npoin2D_eta_outer_core
  integer, dimension(NB_SQUARE_EDGES_ONEDIR) :: npoin2D_xi_inner_core,npoin2D_eta_inner_core

  integer ichunk,iproc_xi,iproc_eta

!ADJOINT
  real(kind=CUSTOM_REAL) b_two_omega_earth
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_ROT_ADJOINT) :: &
    b_A_array_rotation,b_B_array_rotation

  double precision :: time_start

! parameters read from parameter file
  integer MIN_ATTENUATION_PERIOD,MAX_ATTENUATION_PERIOD,NER_CRUST, &
          NER_80_MOHO,NER_220_80,NER_400_220,NER_600_400,NER_670_600,NER_771_670, &
          NER_TOPDDOUBLEPRIME_771,NER_CMB_TOPDDOUBLEPRIME,NER_OUTER_CORE, &
          NER_TOP_CENTRAL_CUBE_ICB,NEX_XI,NEX_ETA, &
          NTSTEP_BETWEEN_OUTPUT_SEISMOS,&
          NTSTEP_BETWEEN_READ_ADJSRC,NSTEP,NSOURCES,NTSTEP_BETWEEN_FRAMES, &
          NTSTEP_BETWEEN_OUTPUT_INFO,NUMBER_OF_RUNS,NUMBER_OF_THIS_RUN,SIMULATION_TYPE, &
          MOVIE_VOLUME_TYPE,MOVIE_START,MOVIE_STOP,NOISE_TOMOGRAPHY,NT_DUMP_ATTENUATION, &
          ATT1,ATT2,ATT3,ATT4,ATT5

  double precision DT,ROCEAN,RMIDDLE_CRUST, &
          RMOHO,R80,R220,R400,R600,R670,R771,RTOPDDOUBLEPRIME,RCMB,RICB, &
          RHO_TOP_OC,RHO_BOTTOM_OC,RHO_OCEANS,HDUR_MOVIE, &
          MOVIE_TOP,MOVIE_BOTTOM,MOVIE_WEST,MOVIE_EAST,MOVIE_NORTH,MOVIE_SOUTH, &
          ANGULAR_WIDTH_XI_IN_DEGREES,RATIO_BY_WHICH_TO_INCREASE_IT

  logical ONE_CRUST,TOPOGRAPHY,MOVIE_SURFACE,MOVIE_VOLUME,MOVIE_COARSE, &
          RECEIVERS_CAN_BE_BURIED,PRINT_SOURCE_TIME_FUNCTION, &
          SAVE_MESH_FILES,ABSORBING_CONDITIONS,INCLUDE_CENTRAL_CUBE,SAVE_FORWARD, &
          OUTPUT_SEISMOS_ASCII_TEXT,OUTPUT_SEISMOS_SAC_ALPHANUM,OUTPUT_SEISMOS_SAC_BINARY, &
          ROTATE_SEISMOGRAMS_RT,HONOR_1D_SPHERICAL_MOHO,WRITE_SEISMOGRAMS_BY_MASTER,&
          SAVE_ALL_SEISMOS_IN_ONE_FILE,USE_BINARY_FOR_LARGE_FILE,SAVE_REGULAR_KL, &
          PARTIAL_PHYS_DISPERSION_ONLY,UNDO_ATTENUATION, &
          USE_LDDRK,INCREASE_CFL_FOR_LDDRK,ANISOTROPIC_KL,SAVE_TRANSVERSE_KL_ONLY,APPROXIMATE_HESS_KL, &
          USE_FULL_TISO_MANTLE,SAVE_SOURCE_MASK,GPU_MODE,ADIOS_ENABLED,ADIOS_FOR_FORWARD_ARRAYS, &
          ADIOS_FOR_MPI_ARRAYS,ADIOS_FOR_ARRAYS_SOLVER,ADIOS_FOR_AVS_DX, &
          EXACT_MASS_MATRIX_FOR_ROTATION

  character(len=150) OUTPUT_FILES,LOCAL_PATH,MODEL

! for SAC headers for seismograms
  integer yr_SAC,jda_SAC,ho_SAC,mi_SAC
  real mb_SAC
  double precision t_cmt_SAC,t_shift_SAC,elat_SAC,elon_SAC,depth_SAC, &
    cmt_lat_SAC,cmt_lon_SAC,cmt_depth_SAC,cmt_hdur_SAC,sec_SAC
  character(len=20) event_name_SAC

! this for all the regions
  integer, dimension(MAX_NUM_REGIONS) :: NSPEC2DMAX_XMIN_XMAX,NSPEC2DMAX_YMIN_YMAX, &
               NSPEC2D_BOTTOM,NSPEC2D_TOP, &
               NGLOB1D_RADIAL, &
               NGLOB2DMAX_XMIN_XMAX,NGLOB2DMAX_YMIN_YMAX

  character(len=150) prname

! lookup table every km for gravity
  real(kind=CUSTOM_REAL) minus_g_cmb,minus_g_icb
  double precision, dimension(NRAD_GRAVITY) :: minus_gravity_table, &
    minus_deriv_gravity_table,density_table,d_ln_density_dr_table,minus_rho_g_over_kappa_fluid

! dummy array that does not need to be actually read
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NGLLZ,1) :: dummy_array

  integer, dimension(MAX_NUMBER_OF_MESH_LAYERS) :: ner,ratio_sampling_array
  integer, dimension(MAX_NUMBER_OF_MESH_LAYERS) :: doubling_index
  double precision, dimension(MAX_NUMBER_OF_MESH_LAYERS) :: r_bottom,r_top
  logical, dimension(MAX_NUMBER_OF_MESH_LAYERS) :: this_region_has_a_doubling
  double precision, dimension(MAX_NUMBER_OF_MESH_LAYERS) :: rmins,rmaxs

! Boundary Mesh and Kernels
  integer k_top,k_bot,iregion_code
  integer, dimension(NSPEC2D_MOHO) :: ibelm_moho_top,ibelm_moho_bot
  integer, dimension(NSPEC2D_400) :: ibelm_400_top,ibelm_400_bot
  integer, dimension(NSPEC2D_670) :: ibelm_670_top,ibelm_670_bot
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_MOHO) :: normal_moho
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_400) :: normal_400
  real(kind=CUSTOM_REAL), dimension(NDIM,NGLLX,NGLLY,NSPEC2D_670) :: normal_670
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_MOHO) :: moho_kl, moho_kl_top, moho_kl_bot
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_400) :: d400_kl, d400_kl_top, d400_kl_bot
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_670) ::  d670_kl, d670_kl_top, d670_kl_bot
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_CMB) :: cmb_kl, cmb_kl_top, cmb_kl_bot
  real(kind=CUSTOM_REAL), dimension(NGLLX,NGLLY,NSPEC2D_ICB) :: icb_kl, icb_kl_top, icb_kl_bot
  logical :: fluid_solid_boundary

  integer :: i,ier

! NOISE_TOMOGRAPHY
  real(kind=CUSTOM_REAL), dimension(:,:,:,:,:), allocatable :: noise_sourcearray
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: &
             normal_x_noise,normal_y_noise,normal_z_noise, mask_noise
  real(kind=CUSTOM_REAL), dimension(:,:,:,:), allocatable :: noise_surface_movie
  integer :: irec_master_noise

#ifdef USE_SERIAL_CASCADE_FOR_IOs
  logical :: you_can_start_doing_IOs
#endif

! this is for LDDRK
  real(kind=CUSTOM_REAL), dimension(:,:), allocatable :: &
            displ_crust_mantle_lddrk,veloc_crust_mantle_lddrk
  real(kind=CUSTOM_REAL), dimension(:), allocatable :: &
            displ_outer_core_lddrk,veloc_outer_core_lddrk
  real(kind=CUSTOM_REAL), dimension(:,:), allocatable :: &
            displ_inner_core_lddrk,veloc_inner_core_lddrk
  real(kind=CUSTOM_REAL), dimension(:,:,:,:), allocatable :: &
            A_array_rotation_lddrk,B_array_rotation_lddrk
  real(kind=CUSTOM_REAL),dimension(:,:,:,:,:,:), allocatable :: R_memory_crust_mantle_lddrk
  real(kind=CUSTOM_REAL),dimension(:,:,:,:,:,:), allocatable :: R_memory_inner_core_lddrk
  integer :: NSTAGE_TIME_SCHEME,istage
  double precision, dimension(N_SLS) :: tau_sigma_dble
  real(kind=CUSTOM_REAL),dimension(N_SLS) :: tau_sigma_CUSTOM_REAL

  integer msg_status(MPI_STATUS_SIZE)

  real(kind=CUSTOM_REAL), dimension(:,:,:), allocatable :: b_displ_crust_mantle_store_buffer
  real(kind=CUSTOM_REAL), dimension(:,:), allocatable :: b_displ_outer_core_store_buffer,&
                                                         b_accel_outer_core_store_buffer
  real(kind=CUSTOM_REAL), dimension(:,:,:), allocatable :: b_displ_inner_core_store_buffer

  integer :: iteration_on_subset,it_of_this_subset,j,irec_local,k
  integer :: it_temp,seismo_current_temp
  real(kind=CUSTOM_REAL), dimension(3) :: seismograms_temp

! to switch between simulation type 1 mode and simulation type 3 mode
! in exact undoing of attenuation
  logical :: undo_att_sim_type_3

! *************************************************
! ************** PROGRAM STARTS HERE **************
! *************************************************
!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!
! trivia about the programming style adopted here:
!
! note 1: for performance reasons, we try to use as much from the stack memory as possible.
!             This is done to avoid memory fragmentation and also to optimize performance.
!             Stack memory is a place in computer memory where all the variables that are declared
!             and initialized **before** runtime are stored. Our static array allocation will use that one.
!             All variables declared within our main routine also will be stored on the stack.
!
!             the heap is the section of computer memory where all the variables created or initialized
!             **at** runtime are stored. it is used for dynamic memory allocation.
!
!             stack is much faster than the heap.
!
!             when calling a function, additional storage will be allocated for the variables in that function.
!             that storage will be allocated in the heap memory segment.
!
!             most routine calls here will have rather long argument lists, probably because of this performance criteria.
!             using modules/common data blocks together with dynamic allocation will put data into heap memory,
!             thus it has longer latency to access variables than stack memory variables.
!
!             however, declaring the static arrays needed in compute_forces_crust_mantle_Dev()
!             like e.g. sum_terms, tempx1,...B1_m1_m2_5points,... in this main routine and
!             passing them along as arguments to the routine makes the code slower.
!             it seems that this stack/heap criterion is more complicated.
!
!             another reason why the use of modules is restricted is to make the code thread safe.
!             having different threads access the same data structure and modifying it at the same time
!             would lead to problems. passing arguments is a way to avoid such complications.
!
! note 2: Most of the computation time is spent
!             inside the time loop (mainly in the compute_forces_crust_mantle_Dev() routine).
!             Any code performance tuning will be most effective in there.
!
! note 3: Fortran is a code language that uses column-first ordering for arrays,
!             e.g., it stores a(i,j) in this order: a(1,1),a(2,1),a(3,1),...,a(1,2),a(2,2),a(3,2),..
!             it is therefore more efficient to have the inner-loop over i, and the outer loop over j
!
! note 4: Deville et al. (2002) routines significantly reduce the total number of memory accesses
!             required to perform matrix-matrix products at the spectral element level.
!             For most compilers and hardware, will result in a significant speedup (> 30% or more, sometimes twice faster).
!
! note 5: whenever adding some new code, please make sure to use
!             spaces rather than tabs. Tabulators are in principle not allowed in Fortran95.
!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!
  ! initialize the MPI communicator and start the NPROCTOT MPI processes.
  call MPI_INIT(ier)

  ! force Flush-To-Zero if available to avoid very slow Gradual Underflow trapping
  call force_ftz()

  ! initializes simulation parameters
  call initialize_simulation(myrank,MIN_ATTENUATION_PERIOD,MAX_ATTENUATION_PERIOD,NER_CRUST, &
                NER_80_MOHO,NER_220_80,NER_400_220,NER_600_400,NER_670_600,NER_771_670, &
                NER_TOPDDOUBLEPRIME_771,NER_CMB_TOPDDOUBLEPRIME,NER_OUTER_CORE, &
                NER_TOP_CENTRAL_CUBE_ICB,ANGULAR_WIDTH_XI_IN_DEGREES,NEX_XI,NEX_ETA, &
                NTSTEP_BETWEEN_OUTPUT_SEISMOS, &
                NTSTEP_BETWEEN_READ_ADJSRC,NSTEP,NSOURCES,NTSTEP_BETWEEN_FRAMES, &
                NTSTEP_BETWEEN_OUTPUT_INFO,NUMBER_OF_RUNS,NUMBER_OF_THIS_RUN,SIMULATION_TYPE, &
                DT,ROCEAN,RMIDDLE_CRUST,RMOHO,R80,R220,R400,R600,R670,R771,&
                RTOPDDOUBLEPRIME,RCMB,RICB, &
                RHO_TOP_OC,RHO_BOTTOM_OC,RHO_OCEANS, &
                MOVIE_VOLUME_TYPE,MOVIE_START,MOVIE_STOP, &
                HDUR_MOVIE,MOVIE_TOP,MOVIE_BOTTOM,MOVIE_WEST,MOVIE_EAST, &
                MOVIE_NORTH,MOVIE_SOUTH,MOVIE_SURFACE,MOVIE_VOLUME, &
                RECEIVERS_CAN_BE_BURIED,PRINT_SOURCE_TIME_FUNCTION, &
                SAVE_MESH_FILES,ABSORBING_CONDITIONS,INCLUDE_CENTRAL_CUBE,SAVE_FORWARD, &
                SAVE_ALL_SEISMOS_IN_ONE_FILE,MOVIE_COARSE,OUTPUT_SEISMOS_ASCII_TEXT, &
                OUTPUT_SEISMOS_SAC_ALPHANUM,OUTPUT_SEISMOS_SAC_BINARY, &
                ROTATE_SEISMOGRAMS_RT,WRITE_SEISMOGRAMS_BY_MASTER,USE_BINARY_FOR_LARGE_FILE, &
                LOCAL_PATH,MODEL,OUTPUT_FILES, &
                ratio_sampling_array, ner, doubling_index,r_bottom,r_top, &
                this_region_has_a_doubling,rmins,rmaxs, &
                TOPOGRAPHY,HONOR_1D_SPHERICAL_MOHO,ONE_CRUST, &
                nspl,rspl,espl,espl2,ibathy_topo, &
                NSPEC2DMAX_XMIN_XMAX,NSPEC2DMAX_YMIN_YMAX,NSPEC2D_BOTTOM,NSPEC2D_TOP, &
                NGLOB1D_RADIAL,NGLOB2DMAX_XMIN_XMAX,NGLOB2DMAX_YMIN_YMAX, &
                xigll,yigll,zigll,wxgll,wygll,wzgll,wgll_cube, &
                hprime_xx,hprime_yy,hprime_zz,hprime_xxT, &
                hprimewgll_xx,hprimewgll_yy,hprimewgll_zz,hprimewgll_xxT, &
                wgllwgll_xy,wgllwgll_xz,wgllwgll_yz, &
                rec_filename,STATIONS,nrec,NOISE_TOMOGRAPHY,SAVE_REGULAR_KL, &
                PARTIAL_PHYS_DISPERSION_ONLY,UNDO_ATTENUATION,NT_DUMP_ATTENUATION, &
          USE_LDDRK,INCREASE_CFL_FOR_LDDRK,ANISOTROPIC_KL,SAVE_TRANSVERSE_KL_ONLY,APPROXIMATE_HESS_KL, &
          USE_FULL_TISO_MANTLE,SAVE_SOURCE_MASK,GPU_MODE,ADIOS_ENABLED,ADIOS_FOR_FORWARD_ARRAYS, &
          ADIOS_FOR_MPI_ARRAYS,ADIOS_FOR_ARRAYS_SOLVER,ADIOS_FOR_AVS_DX,RATIO_BY_WHICH_TO_INCREASE_IT, &
          ATT1,ATT2,ATT3,ATT4,ATT5,EXACT_MASS_MATRIX_FOR_ROTATION)

! to switch between simulation type 1 mode and simulation type 3 mode
! in exact undoing of attenuation
  undo_att_sim_type_3 = .false.

! ZN if we want to storing the strain to acclerate the code but cost more memory then
  if(ATTENUATION_VAL .and. COMPUTE_AND_STORE_STRAIN_VAL)then
    allocate(epsilondev_crust_mantle(5,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ATTENUAT),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating epsilondev_crust_mantle')
    allocate(eps_trace_over_3_crust_mantle(NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ATTENUAT),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating eps_trace_over_3_crust_mantle')
    allocate(epsilondev_inner_core(5,NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE_ATTENUATION),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating epsilondev_inner_core')
    allocate(eps_trace_over_3_inner_core(NGLLX,NGLLY,NGLLZ,NSPEC_INNER_CORE_ATTENUATION),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating eps_trace_over_3_inner_core')
    epsilondev_crust_mantle(:,:,:,:,:) = 0._CUSTOM_REAL
    eps_trace_over_3_crust_mantle(:,:,:,:) = 0._CUSTOM_REAL
    epsilondev_inner_core(:,:,:,:,:) = 0._CUSTOM_REAL
    eps_trace_over_3_inner_core(:,:,:,:) = 0._CUSTOM_REAL
    if(FIX_UNDERFLOW_PROBLEM) then
      epsilondev_crust_mantle(:,:,:,:,:) = VERYSMALLVAL
      eps_trace_over_3_crust_mantle(:,:,:,:) = VERYSMALLVAL
      epsilondev_inner_core(:,:,:,:,:) = VERYSMALLVAL
      eps_trace_over_3_inner_core(:,:,:,:) = VERYSMALLVAL
    endif
  else
    allocate(epsilondev_crust_mantle(5,NGLLX,NGLLY,NGLLZ,1),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating epsilondev_crust_mantle')
    allocate(eps_trace_over_3_crust_mantle(NGLLX,NGLLY,NGLLZ,1),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating eps_trace_over_3_crust_mantle')
    allocate(epsilondev_inner_core(5,NGLLX,NGLLY,NGLLZ,1),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating epsilondev_inner_core')
    allocate(eps_trace_over_3_inner_core(NGLLX,NGLLY,NGLLZ,1),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating eps_trace_over_3_inner_core')
    epsilondev_crust_mantle(:,:,:,:,:) = 0._CUSTOM_REAL
    eps_trace_over_3_crust_mantle(:,:,:,:) = 0._CUSTOM_REAL
    epsilondev_inner_core(:,:,:,:,:) = 0._CUSTOM_REAL
    eps_trace_over_3_inner_core(:,:,:,:) = 0._CUSTOM_REAL
    if(FIX_UNDERFLOW_PROBLEM) then
      epsilondev_crust_mantle(:,:,:,:,:) = VERYSMALLVAL
      eps_trace_over_3_crust_mantle(:,:,:,:) = VERYSMALLVAL
      epsilondev_inner_core(:,:,:,:,:) = VERYSMALLVAL
      eps_trace_over_3_inner_core(:,:,:,:) = VERYSMALLVAL
    endif
  endif

!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!
! starts reading the databases
#ifdef USE_SERIAL_CASCADE_FOR_IOs
    you_can_start_doing_IOs = .false.
    if (myrank > 0) call MPI_RECV(you_can_start_doing_IOs, 1, MPI_LOGICAL, myrank-1, itag, MPI_COMM_WORLD, msg_status,ier)
#endif

  ! allocates mass matrices in this slice (will be fully assembled in the solver)
  !
  ! in the case of stacey boundary conditions, add C*delta/2 contribution to the mass matrix
  ! on the Stacey edges for the crust_mantle and outer_core regions but not for the inner_core region
  ! thus the mass matrix must be replaced by three mass matrices including the "C" damping matrix
  !
  ! if absorbing_conditions are not set or if NCHUNKS=6, only one mass matrix is needed
  ! for the sake of performance, only "rmassz" array will be filled and "rmassx" & "rmassy" will be obsolete

  NGLOB_XY_CM = 1
  NGLOB_XY_IC = 1
  NGLOB_XY_CM_BACKWARD = 1
  NGLOB_XY_IC_BACKWARD = 1

  if(NCHUNKS_VAL /= 6 .and. ABSORBING_CONDITIONS .and. (.not. USE_LDDRK)) then
     NGLOB_XY_CM = NGLOB_CRUST_MANTLE
  else
     NGLOB_XY_CM = 1
  endif

  if(SIMULATION_TYPE /=3  .and. (.not. USE_LDDRK) .and. EXACT_MASS_MATRIX_FOR_ROTATION)then
    if(ROTATION_VAL)then
      NGLOB_XY_CM = NGLOB_CRUST_MANTLE
      NGLOB_XY_IC = NGLOB_INNER_CORE
    endif
  endif

  if(SIMULATION_TYPE ==3  .and. (.not. USE_LDDRK) .and. EXACT_MASS_MATRIX_FOR_ROTATION )then
    if(ROTATION_VAL)then
      NGLOB_XY_CM = NGLOB_CRUST_MANTLE
      NGLOB_XY_IC = NGLOB_INNER_CORE
      NGLOB_XY_CM_BACKWARD = NGLOB_CRUST_MANTLE
      NGLOB_XY_IC_BACKWARD = NGLOB_INNER_CORE
    endif
  endif

  allocate(rmassx_crust_mantle(NGLOB_XY_CM),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating rmassx_crust_mantle')
  allocate(rmassy_crust_mantle(NGLOB_XY_CM),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating rmassy_crust_mantle')

  allocate(b_rmassx_crust_mantle(NGLOB_XY_CM_BACKWARD),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating b_rmassx_crust_mantle')
  allocate(b_rmassy_crust_mantle(NGLOB_XY_CM_BACKWARD),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating b_rmassy_crust_mantle')

  allocate(rmassx_inner_core(NGLOB_XY_IC),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating rmassx_inner_core')
  allocate(rmassy_inner_core(NGLOB_XY_IC),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating rmassy_inner_core')

  allocate(b_rmassx_inner_core(NGLOB_XY_IC_BACKWARD),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating b_rmassx_inner_core')
  allocate(b_rmassy_inner_core(NGLOB_XY_IC_BACKWARD),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating b_rmassy_inner_core')

  call read_mesh_databases(myrank,rho_vp_crust_mantle,rho_vs_crust_mantle, &
              xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
              xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
              etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
              gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
              rhostore_crust_mantle,kappavstore_crust_mantle,muvstore_crust_mantle, &
              kappahstore_crust_mantle,muhstore_crust_mantle,eta_anisostore_crust_mantle, &
              nspec_iso,nspec_tiso,nspec_ani, &
              c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
              c14store_crust_mantle,c15store_crust_mantle,c16store_crust_mantle, &
              c22store_crust_mantle,c23store_crust_mantle,c24store_crust_mantle, &
              c25store_crust_mantle,c26store_crust_mantle,c33store_crust_mantle, &
              c34store_crust_mantle,c35store_crust_mantle,c36store_crust_mantle, &
              c44store_crust_mantle,c45store_crust_mantle,c46store_crust_mantle, &
              c55store_crust_mantle,c56store_crust_mantle,c66store_crust_mantle, &
              ibool_crust_mantle,ispec_is_tiso_crust_mantle, &
              is_on_a_slice_edge_crust_mantle,rmass_ocean_load, &
              rmassx_crust_mantle,rmassy_crust_mantle,rmassz_crust_mantle, &
              vp_outer_core,xstore_outer_core,ystore_outer_core,zstore_outer_core, &
              xix_outer_core,xiy_outer_core,xiz_outer_core, &
              etax_outer_core,etay_outer_core,etaz_outer_core, &
              gammax_outer_core,gammay_outer_core,gammaz_outer_core, &
              rhostore_outer_core,kappavstore_outer_core, &
              ibool_outer_core,idoubling_outer_core,ispec_is_tiso_outer_core, &
              is_on_a_slice_edge_outer_core,rmass_outer_core, &
              xstore_inner_core,ystore_inner_core,zstore_inner_core, &
              xix_inner_core,xiy_inner_core,xiz_inner_core, &
              etax_inner_core,etay_inner_core,etaz_inner_core, &
              gammax_inner_core,gammay_inner_core,gammaz_inner_core, &
              rhostore_inner_core,kappavstore_inner_core,muvstore_inner_core, &
              c11store_inner_core,c12store_inner_core,c13store_inner_core, &
              c33store_inner_core,c44store_inner_core, &
              ibool_inner_core,idoubling_inner_core,ispec_is_tiso_inner_core, &
              is_on_a_slice_edge_inner_core,rmass_inner_core, &
              ABSORBING_CONDITIONS,LOCAL_PATH,NGLOB_XY_CM,&
              SIMULATION_TYPE,NGLOB_XY_CM_BACKWARD,EXACT_MASS_MATRIX_FOR_ROTATION,USE_LDDRK, &
              b_rmassx_crust_mantle,b_rmassy_crust_mantle,&
              NGLOB_XY_IC,rmassx_inner_core,rmassy_inner_core,&
              NGLOB_XY_IC_BACKWARD,b_rmassx_inner_core,b_rmassy_inner_core)

  ! read 2-D addressing for summation between slices with MPI
  call read_mesh_databases_addressing(myrank, &
              iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle, &
              iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
              npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
              iboolfaces_crust_mantle,npoin2D_faces_crust_mantle, &
              iboolcorner_crust_mantle, &
              iboolleft_xi_outer_core,iboolright_xi_outer_core, &
              iboolleft_eta_outer_core,iboolright_eta_outer_core, &
              npoin2D_xi_outer_core,npoin2D_eta_outer_core,&
              iboolfaces_outer_core,npoin2D_faces_outer_core, &
              iboolcorner_outer_core, &
              iboolleft_xi_inner_core,iboolright_xi_inner_core, &
              iboolleft_eta_inner_core,iboolright_eta_inner_core, &
              npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
              iboolfaces_inner_core,npoin2D_faces_inner_core, &
              iboolcorner_inner_core, &
              iprocfrom_faces,iprocto_faces,imsg_type, &
              iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
              LOCAL_PATH,OUTPUT_FILES, &
              NGLOB2DMAX_XMIN_XMAX,NGLOB2DMAX_YMIN_YMAX,NGLOB1D_RADIAL, &
              NGLOB2DMAX_XY,NUMMSGS_FACES,NUM_MSG_TYPES,NCORNERSCHUNKS, &
              addressing,ichunk_slice,iproc_xi_slice,iproc_eta_slice, &
              ichunk,iproc_xi,iproc_eta)

  ! to couple mantle with outer core
  call read_mesh_databases_coupling(myrank, &
              nspec2D_xmin_crust_mantle,nspec2D_xmax_crust_mantle, &
              nspec2D_ymin_crust_mantle,nspec2D_ymax_crust_mantle, &
              ibelm_xmin_crust_mantle,ibelm_xmax_crust_mantle,ibelm_ymin_crust_mantle, &
              ibelm_ymax_crust_mantle,ibelm_bottom_crust_mantle,ibelm_top_crust_mantle, &
              normal_xmin_crust_mantle,normal_xmax_crust_mantle,normal_ymin_crust_mantle, &
              normal_ymax_crust_mantle,normal_bottom_crust_mantle,normal_top_crust_mantle, &
              jacobian2D_xmin_crust_mantle,jacobian2D_xmax_crust_mantle,jacobian2D_ymin_crust_mantle, &
              jacobian2D_ymax_crust_mantle,jacobian2D_bottom_crust_mantle,jacobian2D_top_crust_mantle, &
              nspec2D_xmin_outer_core,nspec2D_xmax_outer_core, &
              nspec2D_ymin_outer_core,nspec2D_ymax_outer_core, &
              ibelm_xmin_outer_core,ibelm_xmax_outer_core,ibelm_ymin_outer_core, &
              ibelm_ymax_outer_core,ibelm_bottom_outer_core,ibelm_top_outer_core, &
              normal_xmin_outer_core,normal_xmax_outer_core,normal_ymin_outer_core, &
              normal_ymax_outer_core,normal_bottom_outer_core,normal_top_outer_core, &
              jacobian2D_xmin_outer_core,jacobian2D_xmax_outer_core,jacobian2D_ymin_outer_core, &
              jacobian2D_ymax_outer_core,jacobian2D_bottom_outer_core,jacobian2D_top_outer_core, &
              nspec2D_xmin_inner_core,nspec2D_xmax_inner_core, &
              nspec2D_ymin_inner_core,nspec2D_ymax_inner_core, &
              ibelm_xmin_inner_core,ibelm_xmax_inner_core,ibelm_ymin_inner_core, &
              ibelm_ymax_inner_core,ibelm_bottom_inner_core,ibelm_top_inner_core, &
              ibelm_moho_top,ibelm_moho_bot,ibelm_400_top,ibelm_400_bot, &
              ibelm_670_top,ibelm_670_bot,normal_moho,normal_400,normal_670, &
              k_top,k_bot,moho_kl,d400_kl,d670_kl,cmb_kl,icb_kl, &
              LOCAL_PATH,SIMULATION_TYPE)

! added this to reduce the size of the buffers
! size of buffers is the sum of two sizes because we handle two regions in the same MPI call
  npoin2D_max_all_CM_IC = max(maxval(npoin2D_xi_crust_mantle(:) + npoin2D_xi_inner_core(:)), &
                        maxval(npoin2D_eta_crust_mantle(:) + npoin2D_eta_inner_core(:)))

  allocate(buffer_send_faces(NDIM,npoin2D_max_all_CM_IC,NUMFACES_SHARED), &
           buffer_received_faces(NDIM,npoin2D_max_all_CM_IC,NUMFACES_SHARED),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating mpi buffer')

  if(SIMULATION_TYPE > 1) then
    allocate(b_buffer_send_faces(NDIM,npoin2D_max_all_CM_IC,NUMFACES_SHARED), &
             b_buffer_received_faces(NDIM,npoin2D_max_all_CM_IC,NUMFACES_SHARED),stat=ier)
  else
    allocate(b_buffer_send_faces(1,1,1), &
             b_buffer_received_faces(1,1,1),stat=ier)
  endif
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating mpi b_buffer')

  call fix_non_blocking_slices(is_on_a_slice_edge_crust_mantle,iboolright_xi_crust_mantle, &
         iboolleft_xi_crust_mantle,iboolright_eta_crust_mantle,iboolleft_eta_crust_mantle, &
         npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle,ibool_crust_mantle, &
         mask_ibool,NSPEC_CRUST_MANTLE,NGLOB_CRUST_MANTLE,NGLOB2DMAX_XMIN_XMAX_CM,NGLOB2DMAX_YMIN_YMAX_CM)

  call fix_non_blocking_slices(is_on_a_slice_edge_outer_core,iboolright_xi_outer_core, &
         iboolleft_xi_outer_core,iboolright_eta_outer_core,iboolleft_eta_outer_core, &
         npoin2D_xi_outer_core,npoin2D_eta_outer_core,ibool_outer_core, &
         mask_ibool,NSPEC_OUTER_CORE,NGLOB_OUTER_CORE,NGLOB2DMAX_XMIN_XMAX_OC,NGLOB2DMAX_YMIN_YMAX_OC)

  call fix_non_blocking_slices(is_on_a_slice_edge_inner_core,iboolright_xi_inner_core, &
         iboolleft_xi_inner_core,iboolright_eta_inner_core,iboolleft_eta_inner_core, &
         npoin2D_xi_inner_core,npoin2D_eta_inner_core,ibool_inner_core, &
         mask_ibool,NSPEC_INNER_CORE,NGLOB_INNER_CORE,NGLOB2DMAX_XMIN_XMAX_IC,NGLOB2DMAX_YMIN_YMAX_IC)

  ! absorbing boundaries
  if(ABSORBING_CONDITIONS) then
    ! crust_mantle
    if (nspec2D_xmin_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_xmin_cm = nspec2D_xmin_crust_mantle
    else
      nabs_xmin_cm = 1
    endif
    allocate(absorb_xmin_crust_mantle5(NDIM,NGLLY,NGLLZ,nabs_xmin_cm,8),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb xmin')

    if (nspec2D_xmax_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_xmax_cm = nspec2D_xmax_crust_mantle
    else
      nabs_xmax_cm = 1
    endif
    allocate(absorb_xmax_crust_mantle5(NDIM,NGLLY,NGLLZ,nabs_xmax_cm,8),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb xmax')

    if (nspec2D_ymin_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_ymin_cm = nspec2D_ymin_crust_mantle
    else
      nabs_ymin_cm = 1
    endif
    allocate(absorb_ymin_crust_mantle5(NDIM,NGLLX,NGLLZ,nabs_ymin_cm,8),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb ymin')

    if (nspec2D_ymax_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_ymax_cm = nspec2D_ymax_crust_mantle
    else
      nabs_ymax_cm = 1
    endif
    allocate(absorb_ymax_crust_mantle5(NDIM,NGLLX,NGLLZ,nabs_ymax_cm,8),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb ymax')

    ! outer_core
    if (nspec2D_xmin_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_xmin_oc = nspec2D_xmin_outer_core
    else
      nabs_xmin_oc = 1
    endif
    allocate(absorb_xmin_outer_core(NGLLY,NGLLZ,nabs_xmin_oc),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb xmin')

    if (nspec2D_xmax_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_xmax_oc = nspec2D_xmax_outer_core
    else
      nabs_xmax_oc = 1
    endif
    allocate(absorb_xmax_outer_core(NGLLY,NGLLZ,nabs_xmax_oc),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb xmax')

    if (nspec2D_ymin_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_ymin_oc = nspec2D_ymin_outer_core
    else
      nabs_ymin_oc = 1
    endif
    allocate(absorb_ymin_outer_core(NGLLX,NGLLZ,nabs_ymin_oc),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb ymin')

    if (nspec2D_ymax_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_ymax_oc = nspec2D_ymax_outer_core
    else
      nabs_ymax_oc = 1
    endif
    allocate(absorb_ymax_outer_core(NGLLX,NGLLZ,nabs_ymax_oc),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb ymax')

    if (NSPEC2D_BOTTOM(IREGION_OUTER_CORE) > 0 .and. &
       (SIMULATION_TYPE == 3 .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      nabs_zmin_oc = NSPEC2D_BOTTOM(IREGION_OUTER_CORE)
    else
      nabs_zmin_oc = 1
    endif
    allocate(absorb_zmin_outer_core(NGLLX,NGLLY,nabs_zmin_oc),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating absorb zmin')

    ! read arrays for Stacey conditions
    call read_mesh_databases_stacey(myrank, &
                      nimin_crust_mantle,nimax_crust_mantle,njmin_crust_mantle, &
                      njmax_crust_mantle,nkmin_xi_crust_mantle,nkmin_eta_crust_mantle, &
                      nspec2D_xmin_crust_mantle,nspec2D_xmax_crust_mantle, &
                      nspec2D_ymin_crust_mantle,nspec2D_ymax_crust_mantle, &
                      reclen_xmin_crust_mantle,reclen_xmax_crust_mantle, &
                      reclen_ymin_crust_mantle,reclen_ymax_crust_mantle, &
                      nimin_outer_core,nimax_outer_core,njmin_outer_core, &
                      njmax_outer_core,nkmin_xi_outer_core,nkmin_eta_outer_core, &
                      nspec2D_xmin_outer_core,nspec2D_xmax_outer_core, &
                      nspec2D_ymin_outer_core,nspec2D_ymax_outer_core, &
                      reclen_xmin_outer_core,reclen_xmax_outer_core, &
                      reclen_ymin_outer_core,reclen_ymax_outer_core, &
                      reclen_zmin,NSPEC2D_BOTTOM, &
                      SIMULATION_TYPE,SAVE_FORWARD,LOCAL_PATH,NSTEP)

  endif

  if (SAVE_REGULAR_KL) then
    call read_kl_regular_grid(myrank, KL_REG_GRID)

    if (myrank==0) then
      allocate(slice_number(KL_REG_GRID%npts_total))

!      print *, 'slice npts =', KL_REG_GRID%npts_total
      call find_regular_grid_slice_number(slice_number, KL_REG_GRID, NCHUNKS_VAL, &
                                          NPROC_XI_VAL, NPROC_ETA_VAL)
      do i = NPROCTOT_VAL-1,0,-1
        npoints_slice = 0
        do isp = 1,KL_REG_GRID%npts_total
          if (slice_number(isp) == i) then
            npoints_slice = npoints_slice + 1
            if (npoints_slice > NM_KL_REG_PTS) stop 'Exceeding NM_KL_REG_PTS limit'
            points_slice(npoints_slice) = isp
          endif
        enddo

        if (i /= 0) then
          call MPI_Send(npoints_slice,1,MPI_INTEGER,i,i,MPI_COMM_WORLD,ier)
          if (npoints_slice > 0) then
            call MPI_Send(points_slice,npoints_slice,MPI_INTEGER,i,2*i,MPI_COMM_WORLD,ier)
          endif
        endif
      enddo

      open(unit=IOUT,file=trim(OUTPUT_FILES)//'/kl_grid_slice.txt',status='unknown',action='write')
      write(IOUT,*) slice_number
      close(IOUT)

      deallocate(slice_number)
    else
      call MPI_Recv(npoints_slice,1,MPI_INTEGER,0,myrank,MPI_COMM_WORLD,msg_status,ier)
      if (npoints_slice > 0) then
        call MPI_Recv(points_slice,npoints_slice,MPI_INTEGER,0,2*myrank,MPI_COMM_WORLD,msg_status,ier)
      endif
    endif

    ! this is the core part that takes up most of the computation time,
    ! and presumably the more processors involved the faster.
    if (npoints_slice > 0) then
      call locate_regular_points(npoints_slice, points_slice, KL_REG_GRID, &
                             NEX_XI, NSPEC_CRUST_MANTLE, &
                             xstore_crust_mantle, ystore_crust_mantle, zstore_crust_mantle, &
                             ibool_crust_mantle, &
                             xigll, yigll, zigll, &
                             ispec_reg, hxir_reg, hetar_reg, hgammar_reg)
    endif

    if (myrank==0) then
      write(IMAIN,*) ' '
      write(IMAIN,*) 'Finished locating kernel output regular grid'
      write(IMAIN,*) ' '
    endif
  endif

#ifdef USE_SERIAL_CASCADE_FOR_IOs
    you_can_start_doing_IOs = .true.
    if (myrank < NPROC_XI_VAL*NPROC_ETA_VAL-1) &
      call MPI_SEND(you_can_start_doing_IOs, 1, MPI_LOGICAL, myrank+1, itag, MPI_COMM_WORLD, ier)
#endif

!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!
! source and receivers

  ! allocate arrays for source
  allocate(islice_selected_source(NSOURCES), &
          ispec_selected_source(NSOURCES), &
          Mxx(NSOURCES), &
          Myy(NSOURCES), &
          Mzz(NSOURCES), &
          Mxy(NSOURCES), &
          Mxz(NSOURCES), &
          Myz(NSOURCES), &
          xi_source(NSOURCES), &
          eta_source(NSOURCES), &
          gamma_source(NSOURCES), &
          tshift_cmt(NSOURCES), &
          hdur(NSOURCES), &
          hdur_gaussian(NSOURCES), &
          theta_source(NSOURCES), &
          phi_source(NSOURCES), &
          nu_source(NDIM,NDIM,NSOURCES),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating source arrays')

  ! allocate memory for receiver arrays
  allocate(islice_selected_rec(nrec), &
          ispec_selected_rec(nrec), &
          xi_receiver(nrec), &
          eta_receiver(nrec), &
          gamma_receiver(nrec), &
          station_name(nrec), &
          network_name(nrec), &
          stlat(nrec), &
          stlon(nrec), &
          stele(nrec), &
          stbur(nrec), &
          nu(NDIM,NDIM,nrec),stat=ier)
  if( ier /= 0 ) call exit_MPI(myrank,'error allocating receiver arrays')

  ! locates sources and receivers
  call setup_sources_receivers(NSOURCES,myrank,ibool_crust_mantle, &
                      xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
                      xigll,yigll,zigll,TOPOGRAPHY, &
                      sec,tshift_cmt,theta_source,phi_source, &
                      NSTEP,DT,hdur,hdur_gaussian,t0,Mxx,Myy,Mzz,Mxy,Mxz,Myz, &
                      islice_selected_source,ispec_selected_source, &
                      xi_source,eta_source,gamma_source,nu_source, &
                      rspl,espl,espl2,nspl,ibathy_topo,NEX_XI,PRINT_SOURCE_TIME_FUNCTION, &
                      rec_filename,nrec,islice_selected_rec,ispec_selected_rec, &
                      xi_receiver,eta_receiver,gamma_receiver,station_name,network_name, &
                      stlat,stlon,stele,stbur,nu, &
                      nrec_local,nadj_rec_local,nrec_simulation, &
                      SIMULATION_TYPE,RECEIVERS_CAN_BE_BURIED,MOVIE_SURFACE,MOVIE_VOLUME, &
                      HDUR_MOVIE,OUTPUT_FILES,LOCAL_PATH,SAVE_SOURCE_MASK)

  ! allocates source arrays
  if (SIMULATION_TYPE == 1  .or. SIMULATION_TYPE == 3) then
    allocate(sourcearrays(NDIM,NGLLX,NGLLY,NGLLZ,NSOURCES),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating sourcearrays')

    ! stores source arrays
    call setup_sources_receivers_srcarr(NSOURCES,myrank, &
                      ispec_selected_source,islice_selected_source, &
                      xi_source,eta_source,gamma_source, &
                      Mxx,Myy,Mzz,Mxy,Mxz,Myz, &
                      xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle, &
                      etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle, &
                      gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle, &
                      xigll,yigll,zigll,sourcearrays)
  endif


  if (SIMULATION_TYPE == 2 .or. SIMULATION_TYPE == 3) then
    NSTEP_SUB_ADJ = ceiling( dble(NSTEP)/dble(NTSTEP_BETWEEN_READ_ADJSRC) )
    allocate(iadj_vec(NSTEP),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating iadj_vec')

    ! initializes iadj_vec
    do it=1,NSTEP
       iadj_vec(it) = NSTEP-it+1  ! default is for reversing entire record
    enddo

    if(nadj_rec_local > 0) then
      ! allocate adjoint source arrays
      allocate(adj_sourcearrays(NDIM,NGLLX,NGLLY,NGLLZ,nadj_rec_local,NTSTEP_BETWEEN_READ_ADJSRC),stat=ier)
      if( ier /= 0 ) call exit_MPI(myrank,'error allocating adjoint sourcearrays')
      adj_sourcearrays(:,:,:,:,:,:) = 0._CUSTOM_REAL

      ! allocate indexing arrays
      allocate(iadjsrc(NSTEP_SUB_ADJ,2), &
              iadjsrc_len(NSTEP_SUB_ADJ),stat=ier)
      if( ier /= 0 ) call exit_MPI(myrank,'error allocating adjoint indexing arrays')
      ! initializes iadjsrc, iadjsrc_len and iadj_vec
      call setup_sources_receivers_adjindx(NSTEP,NSTEP_SUB_ADJ, &
                      NTSTEP_BETWEEN_READ_ADJSRC, &
                      iadjsrc,iadjsrc_len,iadj_vec)
    endif
  endif

  ! allocates receiver interpolators
  if (nrec_local > 0) then
    ! allocate Lagrange interpolators for receivers
    allocate(hxir_store(nrec_local,NGLLX), &
            hetar_store(nrec_local,NGLLY), &
            hgammar_store(nrec_local,NGLLZ),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating receiver interpolators')
    ! define local to global receiver numbering mapping
    allocate(number_receiver_global(nrec_local),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating global receiver numbering')
    ! define and store Lagrange interpolators at all the receivers
    if (SIMULATION_TYPE == 2) then
      nadj_hprec_local = nrec_local
    else
      nadj_hprec_local = 1
    endif
    allocate(hpxir_store(nadj_hprec_local,NGLLX), &
            hpetar_store(nadj_hprec_local,NGLLY), &
            hpgammar_store(nadj_hprec_local,NGLLZ),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating derivative interpolators')

    ! stores interpolators for receiver positions
    call setup_sources_receivers_intp(NSOURCES,myrank, &
                      islice_selected_source, &
                      xi_source,eta_source,gamma_source, &
                      xigll,yigll,zigll, &
                      SIMULATION_TYPE,nrec,nrec_local, &
                      islice_selected_rec,number_receiver_global, &
                      xi_receiver,eta_receiver,gamma_receiver, &
                      hxir_store,hetar_store,hgammar_store, &
                      nadj_hprec_local,hpxir_store,hpetar_store,hpgammar_store)

    ! allocate seismogram array
    if (SIMULATION_TYPE == 1 .or. SIMULATION_TYPE == 3) then
      allocate(seismograms(NDIM,nrec_local,NTSTEP_BETWEEN_OUTPUT_SEISMOS),stat=ier)
      if(ier /= 0) stop 'error while allocating seismograms'
    else
      allocate(seismograms(NDIM*NDIM,nrec_local,NTSTEP_BETWEEN_OUTPUT_SEISMOS),stat=ier)
      if(ier /= 0) stop 'error while allocating seismograms'
      ! allocate Frechet derivatives array
      allocate(moment_der(NDIM,NDIM,nrec_local),sloc_der(NDIM,nrec_local), &
              stshift_der(nrec_local),shdur_der(nrec_local),stat=ier)
      if( ier /= 0 ) call exit_MPI(myrank,'error allocating frechet derivatives arrays')

      moment_der(:,:,:) = 0._CUSTOM_REAL
      sloc_der(:,:) = 0._CUSTOM_REAL
      stshift_der(:) = 0._CUSTOM_REAL
      shdur_der(:) = 0._CUSTOM_REAL

    endif
    ! initialize seismograms
    seismograms(:,:,:) = 0._CUSTOM_REAL
    nit_written = 0
  else
    ! allocate dummy array since we need it to pass as argument e.g. in write_seismograms() routine
    ! note: nrec_local is zero, Fortran 90/95 should allow zero-sized array allocation...
    allocate(seismograms(NDIM,nrec_local,NTSTEP_BETWEEN_OUTPUT_SEISMOS),stat=ier)
    if( ier /= 0) stop 'error while allocating zero seismograms'
    allocate(number_receiver_global(nrec_local),stat=ier)
    if( ier /= 0) stop 'error while allocating zero number_receiver_global'
  endif

  ! get information about event name and location for SAC seismograms

  ! The following line is added for get_event_info subroutine.
  ! Because the way NSOURCES_SAC was declared has been changed.
  ! The rest of the changes in this program is just the updates of the subroutines that
  ! I did changes, e.g., adding/removing parameters. by Ebru Bozdag
  call get_event_info_parallel(myrank,yr_SAC,jda_SAC,ho_SAC,mi_SAC,sec_SAC,&
                              event_name_SAC,t_cmt_SAC,t_shift_SAC, &
                              elat_SAC,elon_SAC,depth_SAC,mb_SAC,cmt_lat_SAC,&
                              cmt_lon_SAC,cmt_depth_SAC,cmt_hdur_SAC,NSOURCES)

!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!

  ! user output
  if(myrank == 0) then

    write(IMAIN,*)
    write(IMAIN,*) 'Reference radius of the Earth used is ',R_EARTH_KM,' km'
    write(IMAIN,*)

    write(IMAIN,*)
    if(OCEANS_VAL) then
      write(IMAIN,*) 'incorporating the oceans using equivalent load'
    else
      write(IMAIN,*) 'no oceans'
    endif

    write(IMAIN,*)
    if(ELLIPTICITY_VAL) then
      write(IMAIN,*) 'incorporating ellipticity'
    else
      write(IMAIN,*) 'no ellipticity'
    endif

    write(IMAIN,*)
    if(TOPOGRAPHY) then
      write(IMAIN,*) 'incorporating surface topography'
    else
      write(IMAIN,*) 'no surface topography'
    endif

    write(IMAIN,*)
    if(GRAVITY_VAL) then
      write(IMAIN,*) 'incorporating self-gravitation (Cowling approximation)'
    else
      write(IMAIN,*) 'no self-gravitation'
    endif

    write(IMAIN,*)
    if(ROTATION_VAL) then
      write(IMAIN,*) 'incorporating rotation'
    else
      write(IMAIN,*) 'no rotation'
    endif

    write(IMAIN,*)
    if(ATTENUATION_VAL) then
      write(IMAIN,*) 'incorporating attenuation using ',N_SLS,' standard linear solids'

      if(ATTENUATION_3D_VAL) write(IMAIN,*) 'using 3D attenuation'

      if(PARTIAL_PHYS_DISPERSION_ONLY) write(IMAIN,*) 'mimicking physical dispersion effects on velocity only'
    else
      write(IMAIN,*) 'no attenuation'
    endif

    write(IMAIN,*)
    write(IMAIN,*)
    write(IMAIN,*)

  endif

  ! the mass matrix needs to be assembled with MPI here once and for all
  call prepare_timerun_rmass(myrank,rmass_ocean_load,rmassx_crust_mantle,rmassy_crust_mantle, &
                      rmassz_crust_mantle,rmass_outer_core,rmass_inner_core, &
                      iproc_xi,iproc_eta,ichunk,addressing, &
                      iboolleft_xi_crust_mantle,iboolright_xi_crust_mantle, &
                      iboolleft_eta_crust_mantle,iboolright_eta_crust_mantle, &
                      npoin2D_faces_crust_mantle,npoin2D_xi_crust_mantle,npoin2D_eta_crust_mantle, &
                      iboolfaces_crust_mantle,iboolcorner_crust_mantle, &
                      iboolleft_xi_outer_core,iboolright_xi_outer_core, &
                      iboolleft_eta_outer_core,iboolright_eta_outer_core, &
                      npoin2D_faces_outer_core,npoin2D_xi_outer_core,npoin2D_eta_outer_core, &
                      iboolfaces_outer_core,iboolcorner_outer_core, &
                      iboolleft_xi_inner_core,iboolright_xi_inner_core, &
                      iboolleft_eta_inner_core,iboolright_eta_inner_core, &
                      npoin2D_faces_inner_core,npoin2D_xi_inner_core,npoin2D_eta_inner_core, &
                      iboolfaces_inner_core,iboolcorner_inner_core, &
                      iprocfrom_faces,iprocto_faces,imsg_type, &
                      iproc_master_corners,iproc_worker1_corners,iproc_worker2_corners, &
                      buffer_send_faces,buffer_received_faces, &
                      buffer_send_chunkcorn_scalar,buffer_recv_chunkcorn_scalar, &
                      NUMMSGS_FACES,NUM_MSG_TYPES,NCORNERSCHUNKS,NGLOB_XY_CM,ABSORBING_CONDITIONS, &
                      NGLOB1D_RADIAL,NGLOB2DMAX_XMIN_XMAX,NGLOB2DMAX_YMIN_YMAX,npoin2D_max_all_CM_IC,&
                      SIMULATION_TYPE,EXACT_MASS_MATRIX_FOR_ROTATION,USE_LDDRK,NGLOB_XY_CM_BACKWARD,&
                      b_rmassx_crust_mantle,b_rmassy_crust_mantle,&
                      NGLOB_XY_IC,rmassx_inner_core,rmassy_inner_core,&
                      NGLOB_XY_IC_BACKWARD,b_rmassx_inner_core,b_rmassy_inner_core)

  ! mass matrix including central cube
  if(INCLUDE_CENTRAL_CUBE) then

    if(myrank == 0) write(IMAIN,*) 'including central cube'

    ! compute number of messages to expect in cube as well as their size
    call comp_central_cube_buffer_size(iproc_xi,iproc_eta,ichunk, &
                NPROC_XI_VAL,NPROC_ETA_VAL,NSPEC2D_BOTTOM(IREGION_INNER_CORE), &
                nb_msgs_theor_in_cube,npoin2D_cube_from_slices)

    ! this value is used for dynamic memory allocation, therefore make sure it is never zero
    if(nb_msgs_theor_in_cube > 0) then
      non_zero_nb_msgs_theor_in_cube = nb_msgs_theor_in_cube
    else
      non_zero_nb_msgs_theor_in_cube = 1
    endif

    ! allocate buffers for cube and slices
    allocate(sender_from_slices_to_cube(non_zero_nb_msgs_theor_in_cube), &
            buffer_all_cube_from_slices(non_zero_nb_msgs_theor_in_cube,npoin2D_cube_from_slices,NDIM), &
            buffer_slices(npoin2D_cube_from_slices,NDIM), &
            buffer_slices2(npoin2D_cube_from_slices,NDIM), &
            ibool_central_cube(non_zero_nb_msgs_theor_in_cube,npoin2D_cube_from_slices),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating cube buffers')

    if(SIMULATION_TYPE > 1) then
      allocate(b_buffer_all_cube_from_slices(non_zero_nb_msgs_theor_in_cube,npoin2D_cube_from_slices,NDIM), &
               b_buffer_slices(npoin2D_cube_from_slices,NDIM))
    else
! dummy allocation of unusued arrays
      allocate(b_buffer_all_cube_from_slices(1,1,1), &
               b_buffer_slices(1,1))
    endif
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating backward cube buffers')

    ! handles the communications with the central cube if it was included in the mesh
    call prepare_timerun_centralcube(myrank,rmass_inner_core, &
                      iproc_xi,iproc_eta,ichunk, &
                      NSPEC2DMAX_XMIN_XMAX,NSPEC2DMAX_YMIN_YMAX,NSPEC2D_BOTTOM, &
                      addressing,ibool_inner_core,idoubling_inner_core, &
                      xstore_inner_core,ystore_inner_core,zstore_inner_core, &
                      nspec2D_xmin_inner_core,nspec2D_xmax_inner_core, &
                      nspec2D_ymin_inner_core,nspec2D_ymax_inner_core, &
                      ibelm_xmin_inner_core,ibelm_xmax_inner_core, &
                      ibelm_ymin_inner_core,ibelm_ymax_inner_core,ibelm_bottom_inner_core, &
                      nb_msgs_theor_in_cube,non_zero_nb_msgs_theor_in_cube, &
                      npoin2D_cube_from_slices,receiver_cube_from_slices, &
                      sender_from_slices_to_cube,ibool_central_cube, &
                      buffer_slices,buffer_slices2,buffer_all_cube_from_slices)

  if(ROTATION_VAL .and. (.not. USE_LDDRK)  .and. EXACT_MASS_MATRIX_FOR_ROTATION &
     .and. NGLOB_XY_IC > 0)then

    call prepare_timerun_centralcube(myrank,rmassx_inner_core, &
                      iproc_xi,iproc_eta,ichunk, &
                      NSPEC2DMAX_XMIN_XMAX,NSPEC2DMAX_YMIN_YMAX,NSPEC2D_BOTTOM, &
                      addressing,ibool_inner_core,idoubling_inner_core, &
                      xstore_inner_core,ystore_inner_core,zstore_inner_core, &
                      nspec2D_xmin_inner_core,nspec2D_xmax_inner_core, &
                      nspec2D_ymin_inner_core,nspec2D_ymax_inner_core, &
                      ibelm_xmin_inner_core,ibelm_xmax_inner_core, &
                      ibelm_ymin_inner_core,ibelm_ymax_inner_core,ibelm_bottom_inner_core, &
                      nb_msgs_theor_in_cube,non_zero_nb_msgs_theor_in_cube, &
                      npoin2D_cube_from_slices,receiver_cube_from_slices, &
                      sender_from_slices_to_cube,ibool_central_cube, &
                      buffer_slices,buffer_slices2,buffer_all_cube_from_slices)

    call prepare_timerun_centralcube(myrank,rmassy_inner_core, &
                      iproc_xi,iproc_eta,ichunk, &
                      NSPEC2DMAX_XMIN_XMAX,NSPEC2DMAX_YMIN_YMAX,NSPEC2D_BOTTOM, &
                      addressing,ibool_inner_core,idoubling_inner_core, &
                      xstore_inner_core,ystore_inner_core,zstore_inner_core, &
                      nspec2D_xmin_inner_core,nspec2D_xmax_inner_core, &
                      nspec2D_ymin_inner_core,nspec2D_ymax_inner_core, &
                      ibelm_xmin_inner_core,ibelm_xmax_inner_core, &
                      ibelm_ymin_inner_core,ibelm_ymax_inner_core,ibelm_bottom_inner_core, &
                      nb_msgs_theor_in_cube,non_zero_nb_msgs_theor_in_cube, &
                      npoin2D_cube_from_slices,receiver_cube_from_slices, &
                      sender_from_slices_to_cube,ibool_central_cube, &
                      buffer_slices,buffer_slices2,buffer_all_cube_from_slices)

    if(SIMULATION_TYPE == 3  .and. NGLOB_XY_IC_BACKWARD > 0)then

    call prepare_timerun_centralcube(myrank,b_rmassx_inner_core, &
                      iproc_xi,iproc_eta,ichunk, &
                      NSPEC2DMAX_XMIN_XMAX,NSPEC2DMAX_YMIN_YMAX,NSPEC2D_BOTTOM, &
                      addressing,ibool_inner_core,idoubling_inner_core, &
                      xstore_inner_core,ystore_inner_core,zstore_inner_core, &
                      nspec2D_xmin_inner_core,nspec2D_xmax_inner_core, &
                      nspec2D_ymin_inner_core,nspec2D_ymax_inner_core, &
                      ibelm_xmin_inner_core,ibelm_xmax_inner_core, &
                      ibelm_ymin_inner_core,ibelm_ymax_inner_core,ibelm_bottom_inner_core, &
                      nb_msgs_theor_in_cube,non_zero_nb_msgs_theor_in_cube, &
                      npoin2D_cube_from_slices,receiver_cube_from_slices, &
                      sender_from_slices_to_cube,ibool_central_cube, &
                      buffer_slices,buffer_slices2,buffer_all_cube_from_slices)

    call prepare_timerun_centralcube(myrank,b_rmassy_inner_core, &
                      iproc_xi,iproc_eta,ichunk, &
                      NSPEC2DMAX_XMIN_XMAX,NSPEC2DMAX_YMIN_YMAX,NSPEC2D_BOTTOM, &
                      addressing,ibool_inner_core,idoubling_inner_core, &
                      xstore_inner_core,ystore_inner_core,zstore_inner_core, &
                      nspec2D_xmin_inner_core,nspec2D_xmax_inner_core, &
                      nspec2D_ymin_inner_core,nspec2D_ymax_inner_core, &
                      ibelm_xmin_inner_core,ibelm_xmax_inner_core, &
                      ibelm_ymin_inner_core,ibelm_ymax_inner_core,ibelm_bottom_inner_core, &
                      nb_msgs_theor_in_cube,non_zero_nb_msgs_theor_in_cube, &
                      npoin2D_cube_from_slices,receiver_cube_from_slices, &
                      sender_from_slices_to_cube,ibool_central_cube, &
                      buffer_slices,buffer_slices2,buffer_all_cube_from_slices)
    endif
  endif

    call fix_non_blocking_central_cube(is_on_a_slice_edge_inner_core, &
         ibool_inner_core,NSPEC_INNER_CORE,NGLOB_INNER_CORE,nb_msgs_theor_in_cube,ibelm_bottom_inner_core, &
         idoubling_inner_core,npoin2D_cube_from_slices,ibool_central_cube, &
         NSPEC2D_BOTTOM(IREGION_INNER_CORE),ichunk)


  else

    ! allocate fictitious buffers for cube and slices with a dummy size
    ! just to be able to use them as arguments in subroutine calls
    allocate(sender_from_slices_to_cube(1), &
         buffer_all_cube_from_slices(1,1,1), &
         b_buffer_all_cube_from_slices(1,1,1), &
         buffer_slices(1,1), &
         b_buffer_slices(1,1), &
         buffer_slices2(1,1), &
         ibool_central_cube(1,1),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating dummy buffers')

  endif

  ! check that all the mass matrices are positive
  if(OCEANS_VAL) then
    if(minval(rmass_ocean_load) <= 0.) call exit_MPI(myrank,'negative mass matrix term for the oceans')
  endif

  ! add C*delta/2 contribution to the mass matrices on the Stacey edges
  if(((NCHUNKS_VAL /= 6 .and. ABSORBING_CONDITIONS) .or. &
      (ROTATION_VAL .and. EXACT_MASS_MATRIX_FOR_ROTATION)) &
      .and. (.not. USE_LDDRK)) then
     if(minval(rmassx_crust_mantle) <= 0._CUSTOM_REAL) &
          call exit_MPI(myrank,'negative mass matrix term for the crust_mantle')
     if(minval(rmassy_crust_mantle) <= 0._CUSTOM_REAL) &
          call exit_MPI(myrank,'negative mass matrix term for the crust_mantle')
  endif

  if(minval(rmassz_crust_mantle) <= 0._CUSTOM_REAL) &
       call exit_MPI(myrank,'negative mass matrix term for the crust_mantle')
  if(minval(rmass_inner_core) <= 0._CUSTOM_REAL) &
       call exit_MPI(myrank,'negative mass matrix term for the inner core')
  if(minval(rmass_outer_core) <= 0._CUSTOM_REAL) &
       call exit_MPI(myrank,'negative mass matrix term for the outer core')

  ! for efficiency, invert final mass matrix once and for all on each slice
  if(OCEANS_VAL) rmass_ocean_load = 1._CUSTOM_REAL / rmass_ocean_load

 ! add C*delta/2 contribution to the mass matrices on the Stacey edges
  if(((NCHUNKS_VAL /= 6 .and. ABSORBING_CONDITIONS) .or. &
      (ROTATION_VAL .and. EXACT_MASS_MATRIX_FOR_ROTATION)) &
      .and. (.not. USE_LDDRK)) then
     rmassx_crust_mantle = 1._CUSTOM_REAL / rmassx_crust_mantle
     rmassy_crust_mantle = 1._CUSTOM_REAL / rmassy_crust_mantle
  endif

  if(.not. USE_LDDRK)then
    if(ROTATION_VAL .and. EXACT_MASS_MATRIX_FOR_ROTATION .and. NGLOB_XY_IC > 0) then
       if(minval(rmassx_inner_core) <= 0._CUSTOM_REAL) &
            call exit_MPI(myrank,'negative mass matrix term for the rmassx_inner_core')
       if(minval(rmassy_inner_core) <= 0._CUSTOM_REAL) &
            call exit_MPI(myrank,'negative mass matrix term for the rmassy_inner_core')
       rmassx_inner_core = 1._CUSTOM_REAL / rmassx_inner_core
       rmassy_inner_core = 1._CUSTOM_REAL / rmassy_inner_core
       if(SIMULATION_TYPE == 3 .and. NGLOB_XY_IC_BACKWARD > 0)then
         if(minval(b_rmassx_inner_core) <= 0._CUSTOM_REAL) &
              call exit_MPI(myrank,'negative mass matrix term for the b_rmassx_inner_core')
         if(minval(b_rmassy_inner_core) <= 0._CUSTOM_REAL) &
              call exit_MPI(myrank,'negative mass matrix term for the b_rmassy_inner_core')
         b_rmassx_inner_core = 1._CUSTOM_REAL / b_rmassx_inner_core
         b_rmassy_inner_core = 1._CUSTOM_REAL / b_rmassy_inner_core
       endif
    endif

    if(ROTATION_VAL .and. EXACT_MASS_MATRIX_FOR_ROTATION &
      .and. (.not. USE_LDDRK) .and. SIMULATION_TYPE == 3 .and. NGLOB_XY_CM_BACKWARD > 0)then
      if(minval(b_rmassx_crust_mantle) <= 0._CUSTOM_REAL) &
           call exit_MPI(myrank,'negative mass matrix term for the b_crust_mantle')
      if(minval(b_rmassy_crust_mantle) <= 0._CUSTOM_REAL) &
           call exit_MPI(myrank,'negative mass matrix term for the b_crust_mantle')
      b_rmassx_crust_mantle = 1._CUSTOM_REAL / b_rmassx_crust_mantle
      b_rmassy_crust_mantle = 1._CUSTOM_REAL / b_rmassy_crust_mantle
    endif
  endif

  rmassz_crust_mantle = 1._CUSTOM_REAL / rmassz_crust_mantle
  rmass_outer_core = 1._CUSTOM_REAL / rmass_outer_core
  rmass_inner_core = 1._CUSTOM_REAL / rmass_inner_core

  ! change x, y, z to r, theta and phi once and for all
  ! IMPROVE dangerous: old name kept (xstore ystore zstore) for new values

  ! convert in the crust and mantle
  do i = 1,NGLOB_CRUST_MANTLE
    call xyz_2_rthetaphi(xstore_crust_mantle(i), &
                        ystore_crust_mantle(i), &
                        zstore_crust_mantle(i),rval,thetaval,phival)
    xstore_crust_mantle(i) = rval
    ystore_crust_mantle(i) = thetaval
    zstore_crust_mantle(i) = phival
  enddo

  ! convert in the outer core
  do i = 1,NGLOB_OUTER_CORE
    call xyz_2_rthetaphi(xstore_outer_core(i), &
                        ystore_outer_core(i), &
                        zstore_outer_core(i),rval,thetaval,phival)
    xstore_outer_core(i) = rval
    ystore_outer_core(i) = thetaval
    zstore_outer_core(i) = phival
  enddo

  ! convert in the inner core
  do i = 1,NGLOB_INNER_CORE
    call xyz_2_rthetaphi(xstore_inner_core(i), &
                        ystore_inner_core(i), &
                        zstore_inner_core(i),rval,thetaval,phival)
    xstore_inner_core(i) = rval
    ystore_inner_core(i) = thetaval
    zstore_inner_core(i) = phival
  enddo

  ! allocate files to save movies
  if(MOVIE_SURFACE .or. NOISE_TOMOGRAPHY /=0) then    ! for noise tomography, store_val_x/y/z/ux/uy/uz needed for 'surface movie'
    if(MOVIE_COARSE .and. NOISE_TOMOGRAPHY ==0) then  ! only output corners !for noise tomography, must NOT be coarse
       nmovie_points = 2 * 2 * NSPEC2D_TOP(IREGION_CRUST_MANTLE)
       if(NGLLX /= NGLLY) &
        call exit_MPI(myrank,'MOVIE_COARSE together with MOVIE_SURFACE requires NGLLX=NGLLY')
       NIT = NGLLX - 1
    else
       nmovie_points = NGLLX * NGLLY * NSPEC2D_TOP(IREGION_CRUST_MANTLE)
       NIT = 1
    endif
    allocate(store_val_x(nmovie_points), &
            store_val_y(nmovie_points), &
            store_val_z(nmovie_points), &
            store_val_ux(nmovie_points), &
            store_val_uy(nmovie_points), &
            store_val_uz(nmovie_points),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating movie surface arrays')

    if (MOVIE_SURFACE) then  ! those arrays are not neccessary for noise tomography, so only allocate them in MOVIE_SURFACE case
       allocate(store_val_x_all(nmovie_points,0:NPROCTOT_VAL-1), &
              store_val_y_all(nmovie_points,0:NPROCTOT_VAL-1), &
              store_val_z_all(nmovie_points,0:NPROCTOT_VAL-1), &
              store_val_ux_all(nmovie_points,0:NPROCTOT_VAL-1), &
              store_val_uy_all(nmovie_points,0:NPROCTOT_VAL-1), &
              store_val_uz_all(nmovie_points,0:NPROCTOT_VAL-1),stat=ier)
       if( ier /= 0 ) call exit_MPI(myrank,'error allocating movie surface all arrays')
    endif
    if(myrank == 0) then
      write(IMAIN,*)
      write(IMAIN,*) 'Movie surface:'
      write(IMAIN,*) '  Writing to moviedata*** files in output directory'
      if(MOVIE_VOLUME_TYPE == 5) then
        write(IMAIN,*) '  movie output: displacement'
      else
        write(IMAIN,*) '  movie output: velocity'
      endif
      write(IMAIN,*) '  time steps every: ',NTSTEP_BETWEEN_FRAMES
    endif
  endif


  ! output point and element information for 3D movies
  if(MOVIE_VOLUME) then
    ! the following has to be true for the the array dimensions of eps to match with those of xstore etc..
    ! note that epsilondev and eps_trace_over_3 don't have the same dimensions.. could cause trouble
    if (NSPEC_CRUST_MANTLE_STR_OR_ATT /= NSPEC_CRUST_MANTLE) &
      stop 'NSPEC_CRUST_MANTLE_STRAINS_ATT /= NSPEC_CRUST_MANTLE'
    if (NSPEC_CRUST_MANTLE_STRAIN_ONLY /= NSPEC_CRUST_MANTLE) &
      stop 'NSPEC_CRUST_MANTLE_STRAIN_ONLY /= NSPEC_CRUST_MANTLE'

    write(prname,'(a,i6.6,a)') trim(LOCAL_PATH)//'/'//'proc',myrank,'_'
    call count_points_movie_volume(prname,ibool_crust_mantle, xstore_crust_mantle,ystore_crust_mantle, &
                zstore_crust_mantle,MOVIE_TOP,MOVIE_BOTTOM,MOVIE_WEST,MOVIE_EAST,MOVIE_NORTH,MOVIE_SOUTH, &
                MOVIE_COARSE,npoints_3dmovie,nspecel_3dmovie,num_ibool_3dmovie,mask_ibool,mask_3dmovie)


    allocate(nu_3dmovie(3,3,npoints_3dmovie),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating nu for 3d movie')

    call write_movie_volume_mesh(npoints_3dmovie,prname,ibool_crust_mantle,xstore_crust_mantle, &
                           ystore_crust_mantle,zstore_crust_mantle, muvstore_crust_mantle_3dmovie, &
                           mask_3dmovie,mask_ibool,num_ibool_3dmovie,nu_3dmovie,MOVIE_COARSE)

    if(myrank == 0) then
      write(IMAIN,*)
      write(IMAIN,*) 'Movie volume:'
      write(IMAIN,*) '  Writing to movie3D*** files on local disk databases directory'
      if(MOVIE_VOLUME_TYPE == 1) then
        write(IMAIN,*) '  movie output: strain'
      else if(MOVIE_VOLUME_TYPE == 2) then
        write(IMAIN,*) '  movie output: time integral of strain'
      else if(MOVIE_VOLUME_TYPE == 3) then
        write(IMAIN,*) '  movie output: potency or integral of strain'
      else if(MOVIE_VOLUME_TYPE == 4) then
        write(IMAIN,*) '  movie output: divergence and curl'
      else if(MOVIE_VOLUME_TYPE == 5) then
        write(IMAIN,*) '  movie output: displacement'
      else if(MOVIE_VOLUME_TYPE == 6) then
        write(IMAIN,*) '  movie output: velocity'
      endif
      write(IMAIN,*) '  depth(T,B):',MOVIE_TOP,MOVIE_BOTTOM
      write(IMAIN,*) '  lon(W,E)  :',MOVIE_WEST,MOVIE_EAST
      write(IMAIN,*) '  lat(S,N)  :',MOVIE_SOUTH,MOVIE_NORTH
      write(IMAIN,*) '  Starting at time step:',MOVIE_START, 'ending at:',MOVIE_STOP,'every: ',NTSTEP_BETWEEN_FRAMES
    endif

    if( MOVIE_VOLUME_TYPE < 1 .or. MOVIE_VOLUME_TYPE > 6) &
        call exit_MPI(myrank, 'MOVIE_VOLUME_TYPE has to be 1,2,3,4,5 or 6')

  endif ! MOVIE_VOLUME

  ! sets up time increments and rotation constants
  call prepare_timerun_constants(myrank,NSTEP, &
                    DT,t0,scale_t,scale_t_inv,scale_displ,scale_veloc, &
                    deltat,deltatover2,deltatsqover2, &
                    b_deltat,b_deltatover2,b_deltatsqover2, &
                    two_omega_earth,A_array_rotation,B_array_rotation, &
                    b_two_omega_earth, SIMULATION_TYPE)

  if(UNDO_ATTENUATION) then
   b_deltat = deltat
   b_deltatover2 = deltatover2
   b_deltatsqover2 = deltatsqover2
   b_two_omega_earth = two_omega_earth
  endif

  ! precomputes gravity factors
  call prepare_timerun_gravity(myrank, &
                    minus_g_cmb,minus_g_icb, &
                    minus_gravity_table,minus_deriv_gravity_table, &
                    density_table,d_ln_density_dr_table,minus_rho_g_over_kappa_fluid, &
                    ONE_CRUST,RICB,RCMB,RTOPDDOUBLEPRIME, &
                    R600,R670,R220,R771,R400,R80,RMOHO,RMIDDLE_CRUST,ROCEAN)

  ! precomputes attenuation factors
  if(ATTENUATION_VAL) then
    call prepare_timerun_attenuation(myrank, &
                factor_scale_crust_mantle,one_minus_sum_beta_crust_mantle,factor_common_crust_mantle, &
                factor_scale_inner_core,one_minus_sum_beta_inner_core,factor_common_inner_core, &
                c11store_crust_mantle,c12store_crust_mantle,c13store_crust_mantle, &
                c22store_crust_mantle,c23store_crust_mantle, &
                c33store_crust_mantle,c44store_crust_mantle, &
                c55store_crust_mantle,c66store_crust_mantle, &
                muvstore_crust_mantle,muhstore_crust_mantle,ispec_is_tiso_crust_mantle, &
                muvstore_inner_core, &
                SIMULATION_TYPE,MOVIE_VOLUME,muvstore_crust_mantle_3dmovie, &
                c11store_inner_core,c12store_inner_core,c13store_inner_core, &
                c33store_inner_core,c44store_inner_core, &
                alphaval,betaval,gammaval,b_alphaval,b_betaval,b_gammaval, &
                deltat,b_deltat,LOCAL_PATH,tau_sigma_dble)
    if(CUSTOM_REAL == SIZE_REAL) then
      tau_sigma_CUSTOM_REAL(:) = sngl(tau_sigma_dble(:))
    else
      tau_sigma_CUSTOM_REAL(:) = tau_sigma_dble(:)
    endif

  if(UNDO_ATTENUATION) then
   b_alphaval = alphaval
   b_betaval = betaval
   b_gammaval = gammaval
  endif

  endif

  if(myrank == 0) then

  write(IMAIN,*) 'for overlapping of communications with calculations:'
  write(IMAIN,*)

  percentage_edge = 100.*count(is_on_a_slice_edge_crust_mantle(:))/real(NSPEC_CRUST_MANTLE)
  write(IMAIN,*) 'percentage of edge elements in crust/mantle ',percentage_edge,'%'
  write(IMAIN,*) 'percentage of volume elements in crust/mantle ',100. - percentage_edge,'%'
  write(IMAIN,*)

  percentage_edge = 100.*count(is_on_a_slice_edge_outer_core(:))/real(NSPEC_OUTER_CORE)
  write(IMAIN,*) 'percentage of edge elements in outer core ',percentage_edge,'%'
  write(IMAIN,*) 'percentage of volume elements in outer core ',100. - percentage_edge,'%'
  write(IMAIN,*)

  percentage_edge = 100.*count(is_on_a_slice_edge_inner_core(:))/real(NSPEC_INNER_CORE)
  write(IMAIN,*) 'percentage of edge elements in inner core ',percentage_edge,'%'
  write(IMAIN,*) 'percentage of volume elements in inner core ',100. - percentage_edge,'%'
  write(IMAIN,*)

  endif

  ! initialize arrays to zero
  displ_crust_mantle(:,:) = 0._CUSTOM_REAL
  veloc_crust_mantle(:,:) = 0._CUSTOM_REAL
  accel_crust_mantle(:,:) = 0._CUSTOM_REAL

  displ_outer_core(:) = 0._CUSTOM_REAL
  veloc_outer_core(:) = 0._CUSTOM_REAL
  accel_outer_core(:) = 0._CUSTOM_REAL

  displ_inner_core(:,:) = 0._CUSTOM_REAL
  veloc_inner_core(:,:) = 0._CUSTOM_REAL
  accel_inner_core(:,:) = 0._CUSTOM_REAL

  if(USE_LDDRK)then
    if(SIMULATION_TYPE /= 1 .or. SAVE_FORWARD .or. NOISE_TOMOGRAPHY /= 0) &
        stop 'error: LDDRK is not implemented for adjoint tomography'
    NSTAGE_TIME_SCHEME = 6
    allocate(displ_crust_mantle_lddrk(NDIM,NGLOB_CRUST_MANTLE),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array displ_crust_mantle_lddrk'
    allocate(veloc_crust_mantle_lddrk(NDIM,NGLOB_CRUST_MANTLE),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array veloc_crust_mantle_lddrk'
    allocate(displ_outer_core_lddrk(NGLOB_OUTER_CORE),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array displ_outer_core_lddrk'
    allocate(veloc_outer_core_lddrk(NGLOB_OUTER_CORE),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array veloc_outer_core_lddrk'
    allocate(displ_inner_core_lddrk(NDIM,NGLOB_INNER_CORE),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array displ_inner_core_lddrk'
    allocate(veloc_inner_core_lddrk(NDIM,NGLOB_INNER_CORE),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array veloc_inner_core_lddrk'

    displ_crust_mantle_lddrk(:,:) = 0._CUSTOM_REAL
    veloc_crust_mantle_lddrk(:,:) = 0._CUSTOM_REAL
    displ_outer_core_lddrk(:) = 0._CUSTOM_REAL
    veloc_outer_core_lddrk(:) = 0._CUSTOM_REAL
    displ_inner_core_lddrk(:,:) = 0._CUSTOM_REAL
    veloc_inner_core_lddrk(:,:) = 0._CUSTOM_REAL

    allocate(A_array_rotation_lddrk(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_ROTATION),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array A_array_rotation_lddrk'
    allocate(B_array_rotation_lddrk(NGLLX,NGLLY,NGLLZ,NSPEC_OUTER_CORE_ROTATION),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array B_array_rotation_lddrk'

    A_array_rotation_lddrk(:,:,:,:) = 0._CUSTOM_REAL
    B_array_rotation_lddrk(:,:,:,:) = 0._CUSTOM_REAL

    allocate(R_memory_crust_mantle_lddrk(5,N_SLS,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ATTENUAT),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array R_memory_crust_mantle_lddrk'
    allocate(R_memory_inner_core_lddrk(5,N_SLS,NGLLX,NGLLY,NGLLZ,NSPEC_CRUST_MANTLE_ATTENUAT),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array R_memory_inner_core_lddrk'

    R_memory_crust_mantle_lddrk(:,:,:,:,:,:) = 0._CUSTOM_REAL
    R_memory_inner_core_lddrk(:,:,:,:,:,:) = 0._CUSTOM_REAL

    if(FIX_UNDERFLOW_PROBLEM) then
      displ_crust_mantle_lddrk(:,:) = VERYSMALLVAL
      veloc_crust_mantle_lddrk(:,:) = VERYSMALLVAL
      displ_outer_core_lddrk(:) = VERYSMALLVAL
      veloc_outer_core_lddrk(:) = VERYSMALLVAL
      displ_inner_core_lddrk(:,:) = VERYSMALLVAL
      veloc_inner_core_lddrk(:,:) = VERYSMALLVAL
      A_array_rotation_lddrk(:,:,:,:) = VERYSMALLVAL
      B_array_rotation_lddrk(:,:,:,:) = VERYSMALLVAL
      R_memory_crust_mantle_lddrk(:,:,:,:,:,:) = VERYSMALLVAL
      R_memory_inner_core_lddrk(:,:,:,:,:,:) = VERYSMALLVAL
    endif
  else
    NSTAGE_TIME_SCHEME = 1
    allocate(displ_crust_mantle_lddrk(NDIM,1),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array displ_crust_mantle_lddrk'
    allocate(veloc_crust_mantle_lddrk(NDIM,1),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array veloc_crust_mantle_lddrk'
    allocate(displ_outer_core_lddrk(1),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array displ_outer_core_lddrk'
    allocate(veloc_outer_core_lddrk(1),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array veloc_outer_core_lddrk'
    allocate(displ_inner_core_lddrk(NDIM,1),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array displ_inner_core_lddrk'
    allocate(veloc_inner_core_lddrk(NDIM,1),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array veloc_inner_core_lddrk'

    displ_crust_mantle_lddrk(:,:) = 0._CUSTOM_REAL
    veloc_crust_mantle_lddrk(:,:) = 0._CUSTOM_REAL
    displ_outer_core_lddrk(:) = 0._CUSTOM_REAL
    veloc_outer_core_lddrk(:) = 0._CUSTOM_REAL
    displ_inner_core_lddrk(:,:) = 0._CUSTOM_REAL
    veloc_inner_core_lddrk(:,:) = 0._CUSTOM_REAL

    allocate(A_array_rotation_lddrk(NGLLX,NGLLY,NGLLZ,1),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array A_array_rotation_lddrk'
    allocate(B_array_rotation_lddrk(NGLLX,NGLLY,NGLLZ,1),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array B_array_rotation_lddrk'

    A_array_rotation_lddrk(:,:,:,:) = 0._CUSTOM_REAL
    B_array_rotation_lddrk(:,:,:,:) = 0._CUSTOM_REAL

    allocate(R_memory_crust_mantle_lddrk(5,N_SLS,NGLLX,NGLLY,NGLLZ,1),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array R_memory_crust_mantle_lddrk'
    allocate(R_memory_inner_core_lddrk(5,N_SLS,NGLLX,NGLLY,NGLLZ,1),stat=ier)
    if(ier /= 0) stop 'error: not enough memory to allocate array R_memory_inner_core_lddrk'

    R_memory_crust_mantle_lddrk(:,:,:,:,:,:) = 0._CUSTOM_REAL
    R_memory_inner_core_lddrk(:,:,:,:,:,:) = 0._CUSTOM_REAL
  endif

  ! put negligible initial value to avoid very slow underflow trapping
  if(FIX_UNDERFLOW_PROBLEM) then
    displ_crust_mantle(:,:) = VERYSMALLVAL
    displ_outer_core(:) = VERYSMALLVAL
    displ_inner_core(:,:) = VERYSMALLVAL
  endif

! if doing benchmark runs to measure scaling of the code,
! set the initial field to 1 to make sure gradual underflow trapping does not slow down the code
  if (DO_BENCHMARK_RUN_ONLY .and. SET_INITIAL_FIELD_TO_1_IN_BENCH) then
    displ_crust_mantle(:,:) = 1._CUSTOM_REAL
    veloc_crust_mantle(:,:) = 1._CUSTOM_REAL
    accel_crust_mantle(:,:) = 1._CUSTOM_REAL

    displ_outer_core(:) = 1._CUSTOM_REAL
    veloc_outer_core(:) = 1._CUSTOM_REAL
    accel_outer_core(:) = 1._CUSTOM_REAL

    displ_inner_core(:,:) = 1._CUSTOM_REAL
    veloc_inner_core(:,:) = 1._CUSTOM_REAL
    accel_inner_core(:,:) = 1._CUSTOM_REAL
  endif

  if (SIMULATION_TYPE == 3) then
    rho_kl_crust_mantle(:,:,:,:) = 0._CUSTOM_REAL
    beta_kl_crust_mantle(:,:,:,:) = 0._CUSTOM_REAL
    alpha_kl_crust_mantle(:,:,:,:) = 0._CUSTOM_REAL
    if (NOISE_TOMOGRAPHY == 3) Sigma_kl_crust_mantle(:,:,:,:) = 0._CUSTOM_REAL

    ! For anisotropic kernels (in crust_mantle only)
    cijkl_kl_crust_mantle(:,:,:,:,:) = 0._CUSTOM_REAL

    rho_kl_outer_core(:,:,:,:) = 0._CUSTOM_REAL
    alpha_kl_outer_core(:,:,:,:) = 0._CUSTOM_REAL

    rho_kl_inner_core(:,:,:,:) = 0._CUSTOM_REAL
    beta_kl_inner_core(:,:,:,:) = 0._CUSTOM_REAL
    alpha_kl_inner_core(:,:,:,:) = 0._CUSTOM_REAL

    div_displ_outer_core(:,:,:,:) = 0._CUSTOM_REAL
  endif

  if (COMPUTE_AND_STORE_STRAIN_VAL) then
    if(MOVIE_VOLUME .and. (MOVIE_VOLUME_TYPE == 2 .or. MOVIE_VOLUME_TYPE == 3)) then
      Iepsilondev_crust_mantle(:,:,:,:,:) = 0._CUSTOM_REAL
      Ieps_trace_over_3_crust_mantle(:,:,:,:)=0._CUSTOM_REAL
    endif
  endif

  ! clear memory variables if attenuation
  if(ATTENUATION_VAL) then
    R_memory_crust_mantle(:,:,:,:,:,:) = 0._CUSTOM_REAL
    R_memory_inner_core(:,:,:,:,:,:) = 0._CUSTOM_REAL
    if(FIX_UNDERFLOW_PROBLEM) then
      R_memory_crust_mantle(:,:,:,:,:,:) = VERYSMALLVAL
      R_memory_inner_core(:,:,:,:,:,:) = VERYSMALLVAL
    endif
  endif

  ! reads files back from local disk or MT tape system if restart file
  ! note: for SIMULATION_TYPE 3 simulations, the stored wavefields
  !          will be read in the time loop after the Newmark time scheme update.
  !          this makes indexing and timing easier to match with adjoint wavefields indexing.
if(UNDO_ATTENUATION) then
  if(NUMBER_OF_THIS_RUN > 1) stop 'we currently do not support NUMBER_OF_THIS_RUN > 1 in the case of UNDO_ATTENUATION'
  ! define correct time steps if restart files
  if(NUMBER_OF_RUNS < 1 .or. NUMBER_OF_RUNS > NSTEP) &
    stop 'number of restart runs can not be less than 1 or greater than NSTEP'
  if(NUMBER_OF_THIS_RUN < 1 .or. NUMBER_OF_THIS_RUN > NUMBER_OF_RUNS) stop 'incorrect run number'
  if (SIMULATION_TYPE /= 1 .and. NUMBER_OF_RUNS /= 1) stop 'Only 1 run for SIMULATION_TYPE = 2/3'

  it_begin = (NUMBER_OF_THIS_RUN - 1) * (NSTEP / NUMBER_OF_RUNS) + 1
  if (NUMBER_OF_THIS_RUN < NUMBER_OF_RUNS) then
    it_end = NUMBER_OF_THIS_RUN * (NSTEP / NUMBER_OF_RUNS)
  else
    ! Last run may be a bit larger
    it_end = NSTEP
  endif
else
  call read_forward_arrays_startrun(myrank,NSTEP, &
                    SIMULATION_TYPE,NUMBER_OF_RUNS,NUMBER_OF_THIS_RUN, &
                    it_begin,it_end, &
                    displ_crust_mantle,veloc_crust_mantle,accel_crust_mantle, &
                    displ_inner_core,veloc_inner_core,accel_inner_core, &
                    displ_outer_core,veloc_outer_core,accel_outer_core, &
                    R_memory_crust_mantle,R_memory_inner_core, &
                    A_array_rotation,B_array_rotation, &
                    b_displ_crust_mantle,b_veloc_crust_mantle,b_accel_crust_mantle, &
                    b_displ_inner_core,b_veloc_inner_core,b_accel_inner_core, &
                    b_displ_outer_core,b_veloc_outer_core,b_accel_outer_core, &
                    b_R_memory_crust_mantle,b_R_memory_inner_core, &
                    b_A_array_rotation,b_B_array_rotation,LOCAL_PATH)
endif


  ! NOISE TOMOGRAPHY
  if ( NOISE_TOMOGRAPHY /= 0 ) then
    allocate(noise_sourcearray(NDIM,NGLLX,NGLLY,NGLLZ,NSTEP), &
            normal_x_noise(nmovie_points), &
            normal_y_noise(nmovie_points), &
            normal_z_noise(nmovie_points), &
            mask_noise(nmovie_points), &
            noise_surface_movie(NDIM,NGLLX,NGLLY,NSPEC2D_TOP(IREGION_CRUST_MANTLE)),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating noise arrays')

    noise_sourcearray(:,:,:,:,:) = 0._CUSTOM_REAL
    normal_x_noise(:)            = 0._CUSTOM_REAL
    normal_y_noise(:)            = 0._CUSTOM_REAL
    normal_z_noise(:)            = 0._CUSTOM_REAL
    mask_noise(:)                = 0._CUSTOM_REAL
    noise_surface_movie(:,:,:,:) = 0._CUSTOM_REAL

    call read_parameters_noise(myrank,nrec,NSTEP,nmovie_points, &
                              islice_selected_rec,xi_receiver,eta_receiver,gamma_receiver,nu, &
                              noise_sourcearray,xigll,yigll,zigll,NSPEC2D_TOP(IREGION_CRUST_MANTLE), &
                              NIT, ibool_crust_mantle, ibelm_top_crust_mantle, &
                              xstore_crust_mantle,ystore_crust_mantle,zstore_crust_mantle, &
                              irec_master_noise,normal_x_noise,normal_y_noise,normal_z_noise,mask_noise)

    call check_parameters_noise(myrank,NOISE_TOMOGRAPHY,SIMULATION_TYPE,SAVE_FORWARD, &
                              NUMBER_OF_RUNS, NUMBER_OF_THIS_RUN,ROTATE_SEISMOGRAMS_RT, &
                              SAVE_ALL_SEISMOS_IN_ONE_FILE, USE_BINARY_FOR_LARGE_FILE, &
                              MOVIE_COARSE,LOCAL_PATH,NSPEC2D_TOP(IREGION_CRUST_MANTLE),NSTEP)
  endif

!
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!

!
!   s t a r t   t i m e   i t e r a t i o n s
!

! synchronize all processes to make sure everybody is ready to start time loop
  call MPI_BARRIER(MPI_COMM_WORLD,ier)
  if(myrank == 0) write(IMAIN,*) 'All processes are synchronized before time loop'

  if(myrank == 0) then
    write(IMAIN,*)
    write(IMAIN,*) 'Starting time iteration loop...'
    write(IMAIN,*)
  endif

! create an empty file to monitor the start of the simulation
  if(myrank == 0) then
    open(unit=IOUT,file=trim(OUTPUT_FILES)//'/starttimeloop.txt',status='unknown',action='write')
    write(IOUT,*) 'hello, starting time loop'
    close(IOUT)
  endif

! initialize variables for writing seismograms
  seismo_offset = it_begin-1
  seismo_current = 0

! get MPI starting time
  time_start = MPI_WTIME()

#ifdef FORCE_VECTORIZATION
  if(ATTENUATION_VAL .and. .not. PARTIAL_PHYS_DISPERSION_ONLY_VAL .and. N_SLS /= 3) &
      stop 'FORCE_VECTORIZATION can only be used with N_SLS == 3 when ATTENUATION .and. .not. PARTIAL_PHYS_DISPERSION_ONLY&
              & because N_SLS is assumed to be equal to 3 when vectorizing compute_element_iso,tiso,aniso'
#endif

! *********************************************************
! ************* MAIN LOOP OVER THE TIME STEPS *************
! *********************************************************

if(.not. UNDO_ATTENUATION) then

  do it = it_begin,it_end

    ! update position in seismograms
    seismo_current = seismo_current + 1

!! DK DK
!! DK DK this first part handles the cases SIMULATION_TYPE == 1 and SIMULATION_TYPE == 2
!! DK DK it also handles the cases NOISE_TOMOGRAPHY == 1 and NOISE_TOMOGRAPHY == 2
!! DK DK
    if(USE_LDDRK .or. EXACT_MASS_MATRIX_FOR_ROTATION)then
      include "part1_undo_att.f90"
    else
      include "part1_classical.f90"
    endif

!! DK DK
!! DK DK this first part handles the case SIMULATION_TYPE == 3
!! DK DK it also handles the case NOISE_TOMOGRAPHY == 3
!! DK DK
    include "part2_classical.f90"

!! DK DK empty file for now
    include "part3_kernel_computation.f90"

!
!---- end of time iteration loop
!
  enddo   ! end of main time loop

else ! if UNDO_ATTENUATION

!! DK DK this should not be difficult to fix and test, but not done yet by lack of time
  if(NUMBER_OF_RUNS /= 1) stop 'NUMBER_OF_RUNS should be == 1 for now when using UNDO_ATTENUATION'

!
!-------------------------------------------------------------------------------
!

  if(SIMULATION_TYPE == 1) then
    it = 0
    do iteration_on_subset = 1, NSTEP / NT_DUMP_ATTENUATION
      if(SAVE_FORWARD) then
        call save_forward_arrays_undoatt(myrank,SIMULATION_TYPE,SAVE_FORWARD,NUMBER_OF_RUNS, &
                    displ_crust_mantle,veloc_crust_mantle,accel_crust_mantle, &
                    displ_inner_core,veloc_inner_core,accel_inner_core, &
                    displ_outer_core,veloc_outer_core,accel_outer_core, &
                    R_memory_crust_mantle,R_memory_inner_core, &
                    A_array_rotation,B_array_rotation,LOCAL_PATH,iteration_on_subset)
      endif

      do it_of_this_subset = 1, NT_DUMP_ATTENUATION

        it = it + 1

        seismo_current = seismo_current + 1

        include "part1_undo_att.f90"

      enddo
    enddo

  endif

  if(SIMULATION_TYPE == 2) then

    it = 0
    do iteration_on_subset = 1, NSTEP / NT_DUMP_ATTENUATION

      do it_of_this_subset = 1, NT_DUMP_ATTENUATION

        it = it + 1

        seismo_current = seismo_current + 1

        include "part1_undo_att.f90"

      enddo
    enddo
  endif

  if(SIMULATION_TYPE == 3) then

! to switch between simulation type 1 mode and simulation type 3 mode
! in exact undoing of attenuation
    undo_att_sim_type_3 = .true.

    allocate(b_displ_crust_mantle_store_buffer(NDIM,NGLOB_CRUST_MANTLE,NT_DUMP_ATTENUATION),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating b_displ_crust_mantle_store_buffer')
    allocate(b_displ_outer_core_store_buffer(NGLOB_OUTER_CORE,NT_DUMP_ATTENUATION),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating b_displ_outer_core_store_buffer')
    allocate(b_accel_outer_core_store_buffer(NGLOB_OUTER_CORE,NT_DUMP_ATTENUATION),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating b_displ_outer_core_store_buffer')
    allocate(b_displ_inner_core_store_buffer(NDIM,NGLOB_INNER_CORE,NT_DUMP_ATTENUATION),stat=ier)
    if( ier /= 0 ) call exit_MPI(myrank,'error allocating b_displ_inner_core_store_buffer')

    it = 0

    do iteration_on_subset = 1, NSTEP / NT_DUMP_ATTENUATION

       call read_forward_arrays_undoatt(myrank, &
                    b_displ_crust_mantle,b_veloc_crust_mantle,b_accel_crust_mantle, &
                    b_displ_inner_core,b_veloc_inner_core,b_accel_inner_core, &
                    b_displ_outer_core,b_veloc_outer_core,b_accel_outer_core, &
                    b_R_memory_crust_mantle,b_R_memory_inner_core, &
                    b_A_array_rotation,b_B_array_rotation,LOCAL_PATH, NSTEP/NT_DUMP_ATTENUATION-iteration_on_subset+1)

      it_temp = it
      seismo_current_temp = seismo_current

        if(COMPUTE_AND_STORE_STRAIN_VAL) then
          if(.not. USE_DEVILLE_PRODUCTS_VAL) &
             call exit_MPI(myrank,'COMPUTE_AND_STORE_STRAIN_VAL is not implemented without USE_DEVILLE_PRODUCTS_VAL')
! after reading the restart files of displacement back from disk, recompute the strain from displacement;
! this is better than storing the strain to disk as well, which would drastically increase I/O volume
          do ispec = 1, NSPEC_INNER_CORE
            call compute_element_strain_att_Dev(ispec,NGLOB_INNER_CORE,NSPEC_INNER_CORE,b_displ_inner_core,&
                                            b_veloc_inner_core,0._CUSTOM_REAL,ibool_inner_core,hprime_xx,hprime_xxT,&
                                            xix_inner_core,xiy_inner_core,xiz_inner_core,&
                                            etax_inner_core,etay_inner_core,etaz_inner_core,&
                                            gammax_inner_core,gammay_inner_core,gammaz_inner_core,&
                                            epsilondev_inner_core(1,1,1,1,ispec),eps_trace_over_3_inner_core(1,1,1,ispec))
          enddo

          do ispec = 1, NSPEC_crust_mantle
            call compute_element_strain_att_Dev(ispec,NGLOB_crust_mantle,NSPEC_crust_mantle,b_displ_crust_mantle,&
                                            b_veloc_crust_mantle,0._CUSTOM_REAL,ibool_crust_mantle,hprime_xx,hprime_xxT,&
                                            xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle,&
                                            etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle,&
                                            gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle,&
                                            epsilondev_crust_mantle(1,1,1,1,ispec),eps_trace_over_3_crust_mantle(1,1,1,ispec))
          enddo
        endif

      do it_of_this_subset = 1, NT_DUMP_ATTENUATION

        it = it + 1
        seismo_current = seismo_current + 1
        include "part2_undo_att.f90"

        b_displ_crust_mantle_store_buffer(:,:,it_of_this_subset) = b_displ_crust_mantle(:,:)
        b_displ_outer_core_store_buffer(:,it_of_this_subset) = b_displ_outer_core(:)
        b_accel_outer_core_store_buffer(:,it_of_this_subset) = b_accel_outer_core(:)
        b_displ_inner_core_store_buffer(:,:,it_of_this_subset) = b_displ_inner_core(:,:)

      enddo

      it = it_temp
      seismo_current = seismo_current_temp

      if(COMPUTE_AND_STORE_STRAIN_VAL) then
        if(.not. USE_DEVILLE_PRODUCTS_VAL) &
           call exit_MPI(myrank,'COMPUTE_AND_STORE_STRAIN_VAL is not implemented without USE_DEVILLE_PRODUCTS_VAL')
! after reading the restart files of displacement back from disk, recompute the strain from displacement;
! this is better than storing the strain to disk as well, which would drastically increase I/O volume
        do ispec = 1, NSPEC_INNER_CORE
          call compute_element_strain_att_Dev(ispec,NGLOB_INNER_CORE,NSPEC_INNER_CORE,displ_inner_core,&
                                            veloc_inner_core,0._CUSTOM_REAL,ibool_inner_core,hprime_xx,hprime_xxT,&
                                            xix_inner_core,xiy_inner_core,xiz_inner_core,&
                                            etax_inner_core,etay_inner_core,etaz_inner_core,&
                                            gammax_inner_core,gammay_inner_core,gammaz_inner_core,&
                                            epsilondev_inner_core(1,1,1,1,ispec),eps_trace_over_3_inner_core(1,1,1,ispec))
        enddo

        do ispec = 1, NSPEC_crust_mantle
          call compute_element_strain_att_Dev(ispec,NGLOB_crust_mantle,NSPEC_crust_mantle,displ_crust_mantle,&
                                          veloc_crust_mantle,0._CUSTOM_REAL,ibool_crust_mantle,hprime_xx,hprime_xxT,&
                                          xix_crust_mantle,xiy_crust_mantle,xiz_crust_mantle,&
                                          etax_crust_mantle,etay_crust_mantle,etaz_crust_mantle,&
                                          gammax_crust_mantle,gammay_crust_mantle,gammaz_crust_mantle,&
                                          epsilondev_crust_mantle(1,1,1,1,ispec),eps_trace_over_3_crust_mantle(1,1,1,ispec))
        enddo
      endif

      do it_of_this_subset = 1, NT_DUMP_ATTENUATION
        do i = 1, NDIM
          do j =1,NGLOB_CRUST_MANTLE_ADJOINT
            b_displ_crust_mantle(i,j) = b_displ_crust_mantle_store_buffer(i,j,NT_DUMP_ATTENUATION-it_of_this_subset+1)
          enddo
        enddo

        do j =1,NGLOB_OUTER_CORE_ADJOINT
            b_displ_outer_core(j) = b_displ_outer_core_store_buffer(j,NT_DUMP_ATTENUATION-it_of_this_subset+1)
            b_accel_outer_core(j) = b_accel_outer_core_store_buffer(j,NT_DUMP_ATTENUATION-it_of_this_subset+1)
        enddo

        do i = 1, NDIM
          do j =1,NGLOB_INNER_CORE_ADJOINT
            b_displ_inner_core(i,j) = b_displ_inner_core_store_buffer(i,j,NT_DUMP_ATTENUATION-it_of_this_subset+1)
          enddo
        enddo

        it = it + 1

        seismo_current = seismo_current + 1

        include "part1_undo_att.f90"

        include "part3_kernel_computation.f90"

      enddo

    enddo   ! end of main time loop
  endif

endif

!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------
!-------------------------------------------------------------------------------------------------

  ! synchronize all processes, waits until all processes have written their seismograms
  call MPI_BARRIER(MPI_COMM_WORLD,ier)
  if( ier /= 0 ) call exit_mpi(myrank,'error synchronize after time loop')

  ! closes Stacey absorbing boundary snapshots
  if( ABSORBING_CONDITIONS ) then
    ! crust mantle
    if (nspec2D_xmin_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(0)
    endif

    if (nspec2D_xmax_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(1)
    endif

    if (nspec2D_ymin_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(2)
    endif

    if (nspec2D_ymax_crust_mantle > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(3)
    endif

    ! outer core
    if (nspec2D_xmin_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(4)
    endif

    if (nspec2D_xmax_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(5)
    endif

    if (nspec2D_ymin_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(6)
    endif

    if (nspec2D_ymax_outer_core > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(7)
    endif

    if (NSPEC2D_BOTTOM(IREGION_OUTER_CORE) > 0 .and. (SIMULATION_TYPE == 3 &
      .or. (SIMULATION_TYPE == 1 .and. SAVE_FORWARD))) then
      call close_file_abs(8)
    endif

    ! frees memory
    deallocate(absorb_xmin_crust_mantle5, &
               absorb_xmax_crust_mantle5, &
               absorb_ymin_crust_mantle5, &
               absorb_ymax_crust_mantle5, &
               absorb_xmin_outer_core, &
               absorb_xmax_outer_core, &
               absorb_ymin_outer_core, &
               absorb_ymax_outer_core, &
               absorb_zmin_outer_core)
  endif

  ! save/read the surface movie using the same c routine as we do for absorbing boundaries (file ID is 9)
  if (NOISE_TOMOGRAPHY/=0) then
    call close_file_abs(9)
  endif

  ! synchronize all processes
  call MPI_BARRIER(MPI_COMM_WORLD,ier)
  if( ier /= 0 ) call exit_mpi(myrank,'error synchronize closing snapshots')

  ! save files to local disk or tape system if restart file
  if(.not. UNDO_ATTENUATION) call save_forward_arrays(myrank,SIMULATION_TYPE,SAVE_FORWARD, &
                    NUMBER_OF_RUNS,NUMBER_OF_THIS_RUN, &
                    displ_crust_mantle,veloc_crust_mantle,accel_crust_mantle, &
                    displ_inner_core,veloc_inner_core,accel_inner_core, &
                    displ_outer_core,veloc_outer_core,accel_outer_core, &
                    R_memory_crust_mantle,R_memory_inner_core, &
                    A_array_rotation,B_array_rotation,LOCAL_PATH)

  ! synchronize all processes
  call MPI_BARRIER(MPI_COMM_WORLD,ier)
  if( ier /= 0 ) call exit_mpi(myrank,'error synchronize saving forward')

  ! dump kernel arrays
  if (SIMULATION_TYPE == 3) then

    ! crust mantle
    if (SAVE_REGULAR_KL) then
      call save_regular_kernels_crust_mantle(myrank, &
                  npoints_slice,hxir_reg,hetar_reg,hgammar_reg,ispec_reg, &
                  scale_t,scale_displ, &
                  cijkl_kl_crust_mantle,rho_kl_crust_mantle, &
                  alpha_kl_crust_mantle,beta_kl_crust_mantle, &
                  ystore_crust_mantle,zstore_crust_mantle, &
                  rhostore_crust_mantle,muvstore_crust_mantle, &
                  kappavstore_crust_mantle,ibool_crust_mantle, &
                  kappahstore_crust_mantle,muhstore_crust_mantle, &
                  eta_anisostore_crust_mantle,ispec_is_tiso_crust_mantle,LOCAL_PATH,ANISOTROPIC_KL,SAVE_TRANSVERSE_KL_ONLY)
    else
      if(ANISOTROPIC_KL .and. .not. SAVE_TRANSVERSE_KL_ONLY) then
        call save_kernels_crust_mantle_ani(myrank,scale_t,scale_displ, &
                  cijkl_kl_crust_mantle,rho_kl_crust_mantle, &
                  ystore_crust_mantle,zstore_crust_mantle, &
                  ibool_crust_mantle, &
                  LOCAL_PATH)
      else if(ANISOTROPIC_KL .and. SAVE_TRANSVERSE_KL_ONLY) then
        call save_kernels_crust_mantle_tiso(myrank,scale_t,scale_displ, &
                  cijkl_kl_crust_mantle,rho_kl_crust_mantle, &
                  alpha_kl_crust_mantle,beta_kl_crust_mantle, &
                  rhonotprime_kl_crust_mantle, &
                  alphav_kl_crust_mantle,alphah_kl_crust_mantle, &
                  betav_kl_crust_mantle,betah_kl_crust_mantle, &
                  eta_kl_crust_mantle, &
                  bulk_c_kl_crust_mantle,bulk_beta_kl_crust_mantle, &
                  bulk_betav_kl_crust_mantle,bulk_betah_kl_crust_mantle, &
                  ystore_crust_mantle,zstore_crust_mantle, &
                  rhostore_crust_mantle,muvstore_crust_mantle, &
                  kappavstore_crust_mantle,ibool_crust_mantle, &
                  kappahstore_crust_mantle,muhstore_crust_mantle, &
                  eta_anisostore_crust_mantle,ispec_is_tiso_crust_mantle, &
                  LOCAL_PATH)
      else
        call save_kernels_crust_mantle_iso(myrank,scale_t,scale_displ, &
                  rho_kl_crust_mantle, &
                  alpha_kl_crust_mantle,beta_kl_crust_mantle, &
                  mu_kl_crust_mantle,kappa_kl_crust_mantle,rhonotprime_kl_crust_mantle, &
                  bulk_c_kl_crust_mantle,bulk_beta_kl_crust_mantle, &
                  rhostore_crust_mantle,muvstore_crust_mantle, &
                  kappavstore_crust_mantle, &
                  LOCAL_PATH)
      endif
    endif

    ! noise strength kernel
    if (NOISE_TOMOGRAPHY == 3) then
       call save_kernels_strength_noise(myrank,LOCAL_PATH,Sigma_kl_crust_mantle)
    endif

    ! outer core
    call save_kernels_outer_core(myrank,scale_t,scale_displ, &
                        rho_kl_outer_core,alpha_kl_outer_core, &
                        rhostore_outer_core,kappavstore_outer_core, &
                        LOCAL_PATH)

    ! inner core
    call save_kernels_inner_core(myrank,scale_t,scale_displ, &
                          rho_kl_inner_core,beta_kl_inner_core,alpha_kl_inner_core, &
                          rhostore_inner_core,muvstore_inner_core,kappavstore_inner_core,LOCAL_PATH)

    ! boundary kernel
    if (SAVE_BOUNDARY_MESH) then
      call save_kernels_boundary_kl(myrank,scale_t,scale_displ, &
                                  moho_kl,d400_kl,d670_kl,cmb_kl,icb_kl,LOCAL_PATH,HONOR_1D_SPHERICAL_MOHO)
    endif

    ! approximate hessian
    if( APPROXIMATE_HESS_KL ) then
      call save_kernels_hessian(myrank,scale_t,scale_displ,hess_kl_crust_mantle,LOCAL_PATH)
    endif
  endif

  ! save source derivatives for adjoint simulations
  if (SIMULATION_TYPE == 2 .and. nrec_local > 0) then
    call save_kernels_source_derivatives(nrec_local,NSOURCES,scale_displ,scale_t, &
                                nu_source,moment_der,sloc_der,stshift_der,shdur_der,number_receiver_global)
  endif

  ! frees dynamically allocated memory
  ! mpi buffers
  deallocate(buffer_send_faces, &
            buffer_received_faces, &
            b_buffer_send_faces, &
            b_buffer_received_faces)

  ! central cube buffers
  deallocate(sender_from_slices_to_cube, &
            buffer_all_cube_from_slices, &
            b_buffer_all_cube_from_slices, &
            buffer_slices, &
            b_buffer_slices, &
            buffer_slices2, &
            ibool_central_cube)

  ! sources
  deallocate(islice_selected_source, &
          ispec_selected_source, &
          Mxx, &
          Myy, &
          Mzz, &
          Mxy, &
          Mxz, &
          Myz, &
          xi_source, &
          eta_source, &
          gamma_source, &
          tshift_cmt, &
          hdur, &
          hdur_gaussian, &
          theta_source, &
          phi_source, &
          nu_source)
  if (SIMULATION_TYPE == 1  .or. SIMULATION_TYPE == 3) deallocate(sourcearrays)
  if (SIMULATION_TYPE == 2 .or. SIMULATION_TYPE == 3) then
    deallocate(iadj_vec)
    if(nadj_rec_local > 0) then
      deallocate(adj_sourcearrays)
      deallocate(iadjsrc,iadjsrc_len)
    endif
  endif

  ! receivers
  deallocate(islice_selected_rec, &
          ispec_selected_rec, &
          xi_receiver, &
          eta_receiver, &
          gamma_receiver, &
          station_name, &
          network_name, &
          stlat, &
          stlon, &
          stele, &
          stbur, &
          nu, &
          number_receiver_global)
  if( nrec_local > 0 ) then
    deallocate(hxir_store, &
              hetar_store, &
              hgammar_store)
    if( SIMULATION_TYPE == 2 ) then
      deallocate(moment_der,stshift_der)
    endif
  endif
  deallocate(seismograms)

  ! movies
  if(MOVIE_SURFACE .or. NOISE_TOMOGRAPHY /= 0 ) then
    deallocate(store_val_x, &
              store_val_y, &
              store_val_z, &
              store_val_ux, &
              store_val_uy, &
              store_val_uz)
    if (MOVIE_SURFACE) then
      deallocate(store_val_x_all, &
            store_val_y_all, &
            store_val_z_all, &
            store_val_ux_all, &
            store_val_uy_all, &
            store_val_uz_all)
    endif
  endif
  if(MOVIE_VOLUME) then
    deallocate(nu_3dmovie)
  endif

  ! noise simulations
  if ( NOISE_TOMOGRAPHY /= 0 ) then
    deallocate(noise_sourcearray, &
            normal_x_noise, &
            normal_y_noise, &
            normal_z_noise, &
            mask_noise, &
            noise_surface_movie)
  endif

  ! mass matrices
  deallocate(rmassx_crust_mantle)
  deallocate(rmassy_crust_mantle)

  ! close the main output file
  if(myrank == 0) then
    write(IMAIN,*)
    write(IMAIN,*) 'End of the simulation'
    write(IMAIN,*)
    close(IMAIN)
  endif

  ! synchronize all the processes to make sure everybody has finished
  call MPI_BARRIER(MPI_COMM_WORLD,ier)
  if( ier /= 0 ) call exit_mpi(myrank,'error synchronize finishing simulation')

  ! stop all the MPI processes, and exit
  call MPI_FINALIZE(ier)

  end program xspecfem3D

