#=====================================================================
#
#          S p e c f e m 3 D  G l o b e  V e r s i o n  5 . 1
#          --------------------------------------------------
#
#          Main authors: Dimitri Komatitsch and Jeroen Tromp
#                        Princeton University, USA
#             and University of Pau / CNRS / INRIA, France
# (c) Princeton University / California Institute of Technology and University of Pau / CNRS / INRIA
#                            April 2011
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.
#
#=====================================================================

# @configure_input@

# CUDA
# with configure: ./configure --with-cuda CUDA_LIB=.. CUDA_INC=.. MPI_INC=..

# default cuda libraries
# runtime library -lcudart needed, others are optional -lcuda -lcublas
@COND_CUDA_TRUE@CUDA_LIBS = -lcudart
@COND_CUDA_FALSE@CUDA_LIBS = 

CUDA_LIB_LOCATION = @CUDA_LIB@
CUDA_LINK = $(CUDA_LIB_LOCATION) $(CUDA_LIBS)
CUDA_INC = @CUDA_INC@ -I../../setup -I../../
MPI_INC = @MPI_INC@

@COND_CUDA_TRUE@NVCC = nvcc
@COND_CUDA_FALSE@NVCC = g++

# GPU architecture
# Fermi: -gencode=arch=compute_10,code=sm_10 not supported
# Tesla (default): -gencode=arch=compute_20,code=sm_20
# Kepler: -gencode=arch=compute_30,code=sm_30
@COND_CUDA_TRUE@NVCC_FLAGS = $(CUDA_INC) $(MPI_INC) -DWITH_MPI -DCUDA -gencode=arch=compute_20,code=sm_20
@COND_CUDA_FALSE@NVCC_FLAGS = $(MPI_INC) -DWITH_MPI


FC = @FC@
FCFLAGS = #@FCFLAGS@
MPIFC = @MPIFC@
MPILIBS = @MPILIBS@
FLAGS_CHECK = @FLAGS_CHECK@
FLAGS_NO_CHECK = @FLAGS_NO_CHECK@
FCFLAGS_f90 = @FCFLAGS_f90@ -I../../setup -I../..

FCCOMPILE_CHECK =@FCENV@ ${FC} ${FCFLAGS} $(FLAGS_CHECK)
FCCOMPILE_NO_CHECK =@FCENV@ ${FC} ${FCFLAGS} $(FLAGS_NO_CHECK)
MPIFCCOMPILE_CHECK =@FCENV@ ${MPIFC} ${FCFLAGS} $(FLAGS_CHECK)
MPIFCCOMPILE_NO_CHECK =@FCENV@ ${MPIFC} ${FCFLAGS} $(FLAGS_NO_CHECK)

CC = @CC@
CFLAGS = @CFLAGS@
CPPFLAGS = -I../../setup @CPPFLAGS@

#AR = ar
#ARFLAGS = cru
#RANLIB = ranlib
AR = @AR@
ARFLAGS = @ARFLAGS@
RANLIB = @RANLIB@

## compilation directories
# E : executables directory
E = ../../bin
# O : objects directory
O = ../../obj
# SHARED : shared directoy
SHARED = ../shared
# S : source file directory
S = .
# root directory
S_TOP = ../..
## setup file directory
SETUP = ../../setup
## output file directory
OUTPUT = ../../OUTPUT_FILES
# CUDAD : cuda directory
CUDAD = ../cuda

#######################################

libspecfem_a_OBJECTS_SOLVER = \
	$O/assemble_MPI_scalar.mpicheckno.o \
	$O/assemble_MPI_vector.mpicheckno.o \
	$O/auto_ner.shared.o \
	$O/broadcast_compute_parameters.sharedmpi.o \
	$O/calendar.shared.o \
	$O/comp_source_spectrum.check.o \
	$O/comp_source_time_function.check.o \
	$O/compute_adj_source_frechet.check.o \
	$O/compute_arrays_source.check.o \
	$O/convert_time.check.o \
	$O/create_name_database.shared.o \
	$O/count_elements.shared.o \
	$O/count_number_of_sources.shared.o \
	$O/count_points.shared.o \
	$O/define_all_layers.shared.o \
	$O/define_derivation_matrices.check.o \
	$O/euler_angles.shared.o \
	$O/force_ftz.cc.o \
	$O/get_attenuation.check.o \
	$O/get_backazimuth.check.o \
	$O/get_cmt.check.o \
	$O/get_event_info.mpicheck.o \
	$O/get_model_parameters.shared.o \
	$O/get_timestep_and_layers.shared.o \
	$O/get_value_parameters.shared.o \
	$O/gll_library.shared.o \
	$O/hex_nodes.shared.o \
	$O/intgrl.shared.o \
	$O/lagrange_poly.shared.o \
	$O/locate_receivers.mpicheck.o \
	$O/locate_sources.mpicheck.o \
	$O/make_ellipticity.shared.o \
	$O/make_gravity.shared.o \
	$O/model_prem.shared.o \
	$O/model_topo_bathy.sharedmpi.o \
	$O/multiply_arrays_source.check.o \
	$O/param_reader.cc.o \
	$O/spline_routines.shared.o \
	$O/netlib_specfun_erf.check.o \
	$O/read_compute_parameters.shared.o \
	$O/read_parameter_file.shared.o \
	$O/read_value_parameters.shared.o \
	$O/recompute_jacobian.check.o \
	$O/reduce.shared.o \
	$O/rthetaphi_xyz.shared.o \
	$O/write_c_binary.cc.o \
	$O/write_seismograms.mpicheck.o \
	$O/write_output_ASCII.mpicheck.o \
	$O/write_output_SAC.mpicheck.o \
	$O/write_VTK_file.sharedmpi.o \
	$(EMPTY_MACRO)

# solver objects with statically allocated arrays; dependent upon
# values_from_mesher.h

SOLVER_ARRAY_OBJECTS = \
	$O/specfem3D_par.solver.o \
	$O/check_simulation_stability.mpisolver.o \
	$O/compute_add_sources.solver.o \
	$O/compute_boundary_kernel.solvercheck.o \
	$O/compute_coupling.solver.o \
	$O/compute_element.solver.o \
	$O/compute_forces_acoustic.solver.o \
	$O/compute_forces_elastic.solver.o \
	$O/compute_forces_crust_mantle.solver.o \
	$O/compute_forces_crust_mantle_Dev.solver.o \
	$O/compute_forces_inner_core.solver.o \
	$O/compute_forces_inner_core_Dev.solver.o \
	$O/compute_forces_outer_core.solver.o \
	$O/compute_forces_outer_core_Dev.solver.o \
	$O/compute_kernels.solver.o \
	$O/compute_seismograms.solver.o \
	$O/compute_stacey_crust_mantle.solver.o \
	$O/compute_stacey_outer_core.solver.o \
	$O/finalize_simulation.mpisolver.o \
	$O/initialize_simulation.solver.o \
	$O/iterate_time.mpisolver.o \
	$O/noise_tomography.mpisolver.o \
	$O/prepare_timerun.mpisolver.o \
	$O/read_arrays_solver.solver.o \
	$O/read_forward_arrays.solver.o \
	$O/read_mesh_databases.mpisolver.o \
	$O/read_topography_bathymetry.mpisolver.o \
	$O/save_forward_arrays.solver.o \
	$O/save_kernels.solver.o \
	$O/setup_GLL_points.mpisolver.o \
	$O/setup_sources_receivers.mpisolver.o \
	$O/specfem3D.mpisolver.o \
	$O/write_movie_output.mpisolver.o \
	$O/write_movie_volume.mpisolver.o \
	$O/write_movie_surface.mpisolver.o \
	$(EMPTY_MACRO)

CUDA_OBJECTS = \
  $O/assemble_MPI_scalar_cuda.cuda.o \
	$O/assemble_MPI_vector_cuda.cuda.o \
  $O/check_fields_cuda.cuda.o \
	$O/compute_add_sources_elastic_cuda.cuda.o \
	$O/compute_coupling_cuda.cuda.o \
	$O/compute_forces_crust_mantle_cuda.cuda.o \
	$O/compute_forces_inner_core_cuda.cuda.o \
	$O/compute_forces_outer_core_cuda.cuda.o \
	$O/compute_kernels_cuda.cuda.o \
	$O/compute_stacey_acoustic_cuda.cuda.o \
	$O/compute_stacey_elastic_cuda.cuda.o \
	$O/initialize_cuda.cuda.o \
	$O/it_update_displacement_cuda.cuda.o \
	$O/noise_tomography_cuda.cuda.o \
	$O/prepare_mesh_constants_cuda.cuda.o \
	$O/transfer_fields_cuda.cuda.o \
	$O/write_seismograms_cuda.cuda.o \
	$O/save_and_compare_cpu_vs_gpu.cudacc.o 

CUDA_STUBS = \
	$O/specfem3D_gpu_cuda_method_stubs.cudacc.o



LIBSPECFEM_SOLVER = $O/libspecfem_solver.a


#######################################

####
#### targets
####

# default targets
DEFAULT = \
	xspecfem3D \
	$(EMPTY_MACRO)

default: $(DEFAULT)

all: clean default

backup:
	mkdir -p bak
	cp *f90 *h Makefile bak

bak: backup

#######################################

####
#### rules for executables
####

# solver also depends on values from mesher
@COND_CUDA_TRUE@XSPECFEM_OBJECTS = $(SOLVER_ARRAY_OBJECTS) $O/exit_mpi.sharedmpi.o $(LIBSPECFEM_SOLVER) $(CUDA_OBJECTS)
@COND_CUDA_FALSE@XSPECFEM_OBJECTS = $(SOLVER_ARRAY_OBJECTS) $O/exit_mpi.sharedmpi.o $(LIBSPECFEM_SOLVER) $(CUDA_STUBS)


xspecfem3D: $(XSPECFEM_OBJECTS)
## use MPI here
	${MPIFCCOMPILE_NO_CHECK} -o ${E}/xspecfem3D $(XSPECFEM_OBJECTS) $(MPILIBS) $(CUDA_LINK)

reqheader:
	(cd ../create_header_file; make)


clean:
	rm -f $O/* *.o work.pc* *.mod ${E}/xspecfem3D  \
      PI*

#######################################

###
### rule for the archive library
###

$O/libspecfem_solver.a: $(libspecfem_a_OBJECTS_SOLVER)
	-rm -f $O/libspecfem_solver.a
	$(AR) $(ARFLAGS) $O/libspecfem_solver.a $(libspecfem_a_OBJECTS_SOLVER)
	$(RANLIB) $O/libspecfem_solver.a


#######################################

####
#### rule for each .o file below
####


##
## shared
##
$O/%.shared.o: ${SHARED}/%.f90 ${SETUP}/constants.h
	${FCCOMPILE_CHECK} ${FCFLAGS_f90} -c -o $@ $<

$O/%.sharedmpi.o: ${SHARED}/%.f90 ${SETUP}/constants.h
	${MPIFCCOMPILE_CHECK} ${FCFLAGS_f90} -c -o $@ $<

$O/%.cc.o: ${SHARED}/%.c ${SETUP}/config.h
	${CC} -c $(CPPFLAGS) $(CFLAGS) -o $@ $< 

#######################################

###
### specfem3D - optimized flags and dependence on values from mesher here
###
$O/%.solver.o: $S/%.f90 ${SETUP}/constants.h ${OUTPUT}/values_from_mesher.h
	${FCCOMPILE_NO_CHECK} ${FCFLAGS_f90} -c -o $@ $<

$O/%.solver.o: $S/%.F90 ${SETUP}/constants.h ${OUTPUT}/values_from_mesher.h
	${FCCOMPILE_NO_CHECK} ${FCFLAGS_f90} -c -o $@ $<

$O/%.solvercheck.o: $S/%.f90 ${SETUP}/constants.h ${OUTPUT}/values_from_mesher.h
	${FCCOMPILE_CHECK} ${FCFLAGS_f90} -c -o $@ $<

$O/%.mpisolver.o: $S/%.f90 ${SETUP}/constants.h ${OUTPUT}/values_from_mesher.h
	${MPIFCCOMPILE_NO_CHECK} ${FCFLAGS_f90} -c -o $@ $<

$O/%.mpisolver.o: $S/%.F90 ${SETUP}/constants.h ${OUTPUT}/values_from_mesher.h
	${MPIFCCOMPILE_NO_CHECK} ${FCFLAGS_f90} -c -o $@ $<

$O/%.mpisolvercheck.o: $S/%.f90 ${SETUP}/constants.h ${OUTPUT}/values_from_mesher.h
	${MPIFCCOMPILE_CHECK} ${FCFLAGS_f90} -c -o $@ $<

#######################################

##
## specfem3D - non-dependent on values from mesher here
##
$O/%.check.o: $S/%.f90 ${SETUP}/constants.h
	${FCCOMPILE_CHECK} ${FCFLAGS_f90} -c -o $@ $<

$O/%.mpicheckno.o: $S/%.f90 ${SETUP}/constants.h
	${MPIFCCOMPILE_NO_CHECK} ${FCFLAGS_f90} -c -o $@ $<

$O/%.mpicheck.o: %.f90 ${SETUP}/constants.h
	${MPIFCCOMPILE_CHECK} -c -o $@ ${FCFLAGS_f90} $<


#######################################

###
### CUDA compilation
###

$O/%.cuda.o: ${CUDAD}/%.cu ${SETUP}/config.h ${CUDAD}/mesh_constants_cuda.h ${CUDAD}/prepare_constants_cuda.h
	${NVCC} -c $< -o $@ $(NVCC_FLAGS)

$O/%.cudacc.o: ${CUDAD}/%.c ${SETUP}/config.h
	${CC} -c $(CPPFLAGS) $(CFLAGS) $(MPI_INC) -o $@ ${CUDAD}/$< 

#######################################

###
### rule for the header file
###

${OUTPUT}/values_from_mesher.h: reqheader
	(mkdir -p ${OUTPUT}; cd ${S_TOP}/; ./bin/xcreate_header_file)

